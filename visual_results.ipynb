{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch,torchvision\n",
    "import copy\n",
    "from mask2former.utils.misc import is_dist_avail_and_initialized, nested_tensor_from_tensor_list\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# y, _= nested_tensor_from_tensor_list(x).decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234556587"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(234556587)\n",
    "np.random.get_state()[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3433503404869388\n",
      "0.679400968035765\n",
      "0.039312044731126594\n",
      "0.02832006852528457\n",
      "0.8472388052647847\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(234556587)\n",
    "np.random.get_state()[1][0]\n",
    "for _ in range(5):\n",
    "    print(np.random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3433503404869388\n",
      "0.679400968035765\n",
      "0.039312044731126594\n",
      "0.02832006852528457\n",
      "0.8472388052647847\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(234556587)\n",
    "np.random.get_state()[1][0]\n",
    "for _ in range(5):\n",
    "    print(np.random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "# fig.subplots_adjust(top=0.85)\n",
    "\n",
    "# Set titles for the figure and the subplot respectively\n",
    "# fig.suptitle('bold figure suptitle', fontsize=14, fontweight='bold')\n",
    "# ax.set_title('axes title')\n",
    "\n",
    "ax.set_xlabel(r'$x$')\n",
    "ax.set_ylabel(r'$f(x)$')\n",
    "\n",
    "# Set both x- and y-axis limits to [0, 10] instead of default [0, 1]\n",
    "ax.axis([-4, 4, -4, 8])\n",
    "\n",
    "# ax.text(3, 8, 'boxed italics text in data coords', style='italic',\n",
    "#         bbox={'facecolor': 'red', 'alpha': 0.5, 'pad': 10})\n",
    "\n",
    "# ax.text(2, 6, r'an equation: $E=mc^2$', fontsize=15)\n",
    "\n",
    "# ax.text(3, 2, 'Unicode: Institut für Festkörperphysik')\n",
    "\n",
    "# ax.text(0.95, 0.01, 'colored text in axes coords',\n",
    "#         verticalalignment='bottom', horizontalalignment='right',\n",
    "#         transform=ax.transAxes,\n",
    "        # color='green', fontsize=15)\n",
    "x = np.arange(-4,4,0.1)\n",
    "y = (x**2)/2\n",
    "ax.plot(x,y, '--', x,x,'-')\n",
    "# ax.annotate('annotate', xy=(2, 1), xytext=(3, 4),\n",
    "#             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0757, -0.7272, -1.3130,  0.0838,  0.7196],\n",
      "        [-0.2034, -1.1972,  0.3110,  0.3514,  1.0811],\n",
      "        [ 0.0807, -0.9097,  1.3514, -0.5874,  0.4642]], requires_grad=True)\n",
      "tensor([3, 2, 3])\n",
      "tensor(1.9118, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.seed()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "print(input)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(target)\n",
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2169, 0.0972, 0.0541, 0.2187, 0.4130],\n",
       "        [0.1191, 0.0441, 0.1992, 0.2074, 0.4302],\n",
       "        [0.1446, 0.0537, 0.5153, 0.0741, 0.2122]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.softmax(input,dim=-1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9118, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum =0 \n",
    "for i,j in enumerate(target):\n",
    "    sum+= torch.log(s[i][j])\n",
    "-sum/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import io\n",
    "\n",
    "with open(\"./output/config.yaml\", 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaded['DATASETS']['TEST'] = ['Berkeley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('./output/config1.yaml', 'w', encoding='utf8') as outfile:\n",
    "    yaml.dump(data_loaded, outfile, default_flow_style=False, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 0.0, 0.0),\n",
       " (0.8000000000000007, 0.0, 1.0),\n",
       " (0.7999999999999998, 1.0, 0.0),\n",
       " (0.0, 0.40000000000000036, 1.0),\n",
       " (0.0, 1.0, 0.40000000000000036)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import colorsys\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "random_colors(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ceil(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_clicks_per_obj = [3,4,4,5,2]\n",
    "ious = [0.80, 0.81, 0,0, 0.89]\n",
    "max_cont_clicks = 5\n",
    "iou_threshold = 0.8\n",
    "all((iou>=iou_threshold or c >= max_cont_clicks) for iou,c in zip(ious,cont_clicks_per_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4624"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.4623729789492,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ones((5,5))\n",
    "y = np.zeros((5,5))\n",
    "z = x!=y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[7, 3, 1, 9, 6, 5, 8, 2, 0, 4]\n",
      "[5, 1, 0, 8, 6, 7, 4, 2, 9, 3]\n",
      "[1, 2, 9, 7, 4, 6, 8, 3, 0, 5]\n",
      "1\n",
      "[2, 9, 0, 1, 8, 7, 4, 5, 3, 6]\n",
      "[3, 6, 2, 1, 9, 5, 4, 7, 0, 8]\n",
      "[4, 9, 2, 8, 0, 6, 7, 5, 3, 1]\n",
      "2\n",
      "[5, 1, 7, 9, 0, 6, 3, 4, 2, 8]\n",
      "[8, 4, 2, 6, 7, 1, 9, 3, 5, 0]\n",
      "[7, 0, 5, 3, 8, 6, 9, 1, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "x = list(range(10))\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    random.seed(123456+i)\n",
    "    random.shuffle(x)\n",
    "    print(x)\n",
    "    random.shuffle(x)\n",
    "    print(x)\n",
    "    random.shuffle(x)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = torch.zeros((0, 10, 10), dtype=torch.uint8)\n",
    "mask_areas = torch.sum(masks, (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_masks =  masks[sorted(range(len(mask_areas)),key=mask_areas.__getitem__,reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_masks = torch.zeros((0, 10, 10), dtype=torch.uint8)\n",
    "mask_areas = torch.sum(gt_masks, (1,2))\n",
    "gt_masks = gt_masks.to(dtype=torch.uint8)\n",
    "gt_masks =  gt_masks[sorted(range(len(mask_areas)),key=mask_areas.__getitem__,reverse=True)]\n",
    "\n",
    "instance_map = torch.zeros((gt_masks.shape[-2:]), dtype=torch.int16)\n",
    "num_objects = gt_masks.shape[0]\n",
    "instances_ids = np.arange(1, num_objects + 1)\n",
    "\n",
    "for _id, _m in enumerate(gt_masks):\n",
    "    instance_map[_m == 1] = _id+1\n",
    "    assert (_m != 0).sum() > 0\n",
    "\n",
    "new_gt_masks = []\n",
    "for _id in instances_ids:\n",
    "    _m = (instance_map == _id).to(dtype=torch.uint8)\n",
    "    if _m.sum() > 0:\n",
    "        new_gt_masks.append(_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if not len(new_gt_masks):\n",
    "    print(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_mval_images = os.listdir(\"datasets/COCO_MVal/img\")\n",
    "coco_mval_ids = [img_id.split(\"_\")[-1] for img_id in coco_mval_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cow08_000000061171.jpg',\n",
       " 'stop sign07_000000000724.jpg',\n",
       " 'apple08_000000113589.jpg',\n",
       " 'pizza00_000000197022.jpg',\n",
       " 'train04_000000546659.jpg',\n",
       " 'giraffe02_000000301981.jpg',\n",
       " 'microwave05_000000498463.jpg',\n",
       " 'cat03_000000115885.jpg',\n",
       " 'hot dog00_000000322574.jpg',\n",
       " 'broccoli07_000000296634.jpg']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_mval_images[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000061171.jpg',\n",
       " '000000000724.jpg',\n",
       " '000000113589.jpg',\n",
       " '000000197022.jpg',\n",
       " '000000546659.jpg',\n",
       " '000000301981.jpg',\n",
       " '000000498463.jpg',\n",
       " '000000115885.jpg',\n",
       " '000000322574.jpg',\n",
       " '000000296634.jpg']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_mval_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoval17 = os.listdir(\"datasets/coco/val2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DatasetCatalog.get(\"coco_2017_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = []\n",
    "for i in range(len(d)): \n",
    "    val_ids.append(str(d[i][\"file_name\"]).split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000217219.jpg',\n",
       " '000000405972.jpg',\n",
       " '000000047010.jpg',\n",
       " '000000085823.jpg',\n",
       " '000000225184.jpg',\n",
       " '000000578871.jpg',\n",
       " '000000129113.jpg',\n",
       " '000000344100.jpg',\n",
       " '000000409475.jpg',\n",
       " '000000534605.jpg']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocoval17[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "out = []\n",
    "for id in coco_mval_ids :\n",
    "    out.append(val_ids.index(id))\n",
    "    c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 7, 4]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indexes.insert(4,7)\n",
    "random_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 2, 1]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indexes = list(range(5))\n",
    "random.shuffle(random_indexes)\n",
    "random_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 2, 4, 0]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(random_indexes)\n",
    "random_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "assert k==5, \"K should be 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "model = models.resnet18().cuda()\n",
    "inputs = torch.randn(5, 3, 224, 224).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        for i in range(5):\n",
    "           x = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trace.json\") as f:\n",
    "    p = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['schemaVersion', 'deviceProperties', 'traceEvents'])"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-instance tau v/s mean IOU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_IOU(summary_stats):\n",
    "    ious_objects_per_interaction = summary_stats[\"ious_objects_per_interaction\"]\n",
    "    # Avg_IOU = 0.0\n",
    "    total_images = len(list(ious_objects_per_interaction.keys()))\n",
    "    # total_num_instances = 0\n",
    "    iou_per_tau = np.zeros(20)\n",
    "    for _image_id in ious_objects_per_interaction.keys():\n",
    "        n = len(ious_objects_per_interaction[_image_id][0])\n",
    "        i=0\n",
    "        j=0\n",
    "        while(i<len(ious_objects_per_interaction[_image_id])):\n",
    "            final_ious = ious_objects_per_interaction[_image_id][i]\n",
    "            # print(final_ious)\n",
    "            Avg_IOU = sum(final_ious)/len(final_ious)\n",
    "            iou_per_tau[j] += Avg_IOU\n",
    "            i+=n\n",
    "            j+=1\n",
    "    # Avg_IOU/=total_images\n",
    "    print(total_images)\n",
    "    iou_per_tau/=total_images\n",
    "    return iou_per_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_root_dir = os.path.join(os.getcwd(), \"output/evaluation/final/summary/davis_2017_val/tau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mq_mit_b0_fusion_pf_uni_time_pe_bs128_ep50_random_seed_1_20.pickle\n",
      "1999\n",
      "[0.90125141 0.90125141 0.90125141 0.90125141 0.90125141 0.90125141\n",
      " 0.90125141 0.90125141 0.90125141 0.90125141 0.90125141 0.90125141\n",
      " 0.90125141 0.90125141 0.90125141 0.90125141 0.90125141 0.90125141\n",
      " 0.90125141 0.90125141]\n",
      "mq_mit_b0_fusion_pf_uni_time_pe_bs128_ep50_random_seed_2_20.pickle\n",
      "1999\n",
      "[0.90091243 0.90091243 0.90091243 0.90091243 0.90091243 0.90091243\n",
      " 0.90091243 0.90091243 0.90091243 0.90091243 0.90091243 0.90091243\n",
      " 0.90091243 0.90091243 0.90091243 0.90091243 0.90091243 0.90091243\n",
      " 0.90091243 0.90091243]\n",
      "mq_swin_tiny_fusion_pf_uni_time_pe_bs128_ep50_random_seed_2_20.pickle\n",
      "1999\n",
      "[0.90304692 0.90304692 0.90304692 0.90304692 0.90304692 0.90304692\n",
      " 0.90304692 0.90304692 0.90304692 0.90304692 0.90304692 0.90304692\n",
      " 0.90304692 0.90304692 0.90304692 0.90304692 0.90304692 0.90304692\n",
      " 0.90304692 0.90304692]\n"
     ]
    }
   ],
   "source": [
    "model_names = []\n",
    "iou_list_per_model = []\n",
    "min_iou = 1.0\n",
    "max_iou= -1.0\n",
    "for f in os.listdir(_root_dir):\n",
    "    # print(model)\n",
    "    # pkl_files_path = os.path.join(_root_dir,f)\n",
    "    # pkl_files = os.listdir(pkl_files_path)\n",
    "    # model_names.append(model)\n",
    "    print(f)\n",
    "    # iou_per_tau = []\n",
    "    # for (i,f) in enumerate(pkl_files):\n",
    "    #     if i>=7:\n",
    "    #         continue\n",
    "    pickle_path = os.path.join(_root_dir, f)\n",
    "    with open(pickle_path, 'rb') as handle:\n",
    "        summary_stats= pickle.load(handle)\n",
    "    iou_per_tau= get_mean_IOU(summary_stats)\n",
    "    print(iou_per_tau)\n",
    "    # iou_per_tau.append(iou)\n",
    "    min_iou = min(min(iou_per_tau),min_iou)\n",
    "    max_iou = max(max(iou_per_tau),max_iou)\n",
    "    iou_list_per_model.append(iou_per_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"Swin-T\", \"Segformer-B0\"]\n",
    "colors = [\"red\", \"blue\", \"green\", \"orange\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10)) \n",
    "n = min(20,len(iou_list_per_model[0]))\n",
    "for i in range(len(model_names)):\n",
    "    # if i==4 or i==5 or i==1:\n",
    "    plt.plot(range(1,n+1), iou_list_per_model[i][:n], colors[i],label=model_names[i], linewidth=3) #linestyle='dashed')\n",
    "plt.title(\"DAVIS\")\n",
    "plt.xlabel(\"Tau\")\n",
    "plt.ylabel(\"mean IOU\")\n",
    "plt.legend()\n",
    "plt.xlim(0,n+1)\n",
    "plt.yticks(np.arange(round(min_iou.item(),2), max_iou+0.01, 0.01))\n",
    "plt.xticks(np.arange(1,n+1,1))\n",
    "# plt.ylim(min(iou_per_click)-0.01, max(iou_per_click)+0.01)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"tau_iou.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mq_swin_tiny_fusion_pf_uni_time_pe_bs128_ep50_random_seed_1_20.pickle\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/home/rana/Thesis/DynaMITe/output/evaluation/final/summary/sbd_multi_insts/tau/mq_swin_tiny_fusion_pf_uni_time_pe_bs128_ep50_random_seed_1_20.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/home/rana/Thesis/DynaMITe/visual_results.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rana/Thesis/DynaMITe/visual_results.ipynb#ch0000221?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rana/Thesis/DynaMITe/visual_results.ipynb#ch0000221?line=6'>7</a>\u001b[0m pkl_files_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(_root_dir,model)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rana/Thesis/DynaMITe/visual_results.ipynb#ch0000221?line=7'>8</a>\u001b[0m pkl_files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(pkl_files_path)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rana/Thesis/DynaMITe/visual_results.ipynb#ch0000221?line=8'>9</a>\u001b[0m model_names\u001b[39m.\u001b[39mappend(model)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rana/Thesis/DynaMITe/visual_results.ipynb#ch0000221?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(pkl_files)\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/home/rana/Thesis/DynaMITe/output/evaluation/final/summary/sbd_multi_insts/tau/mq_swin_tiny_fusion_pf_uni_time_pe_bs128_ep50_random_seed_1_20.pickle'"
     ]
    }
   ],
   "source": [
    "model_names = []\n",
    "iou_list_per_model = []\n",
    "min_iou = 1.0\n",
    "max_iou= -1.0\n",
    "for model in os.listdir(_root_dir):\n",
    "    print(model)\n",
    "    pkl_files_path = os.path.join(_root_dir,model)\n",
    "    pkl_files = os.listdir(pkl_files_path)\n",
    "    model_names.append(model)\n",
    "    print(pkl_files)\n",
    "    iou_per_tau = []\n",
    "    for (i,f) in enumerate(pkl_files):\n",
    "        if i>=7:\n",
    "            continue\n",
    "        pickle_path = os.path.join(pkl_files_path, f)\n",
    "        with open(pickle_path, 'rb') as handle:\n",
    "            summary_stats= pickle.load(handle)\n",
    "        iou= get_mean_IOU(summary_stats)\n",
    "        iou_per_tau.append(iou)\n",
    "        min_iou = min(iou,min_iou)\n",
    "        max_iou = max(iou,max_iou)\n",
    "    iou_list_per_model.append(iou_per_tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarising single-instance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_root_dir = os.path.join(os.getcwd(), \"output/evaluation/iccv_final/final/summary\")\n",
    "datasets = [\"GrabCut\", \"Berkeley\", \"davis_single_inst\",\"coco_Mval\",\"sbd_single_inst\"]\n",
    "focal_dir = \"/home/mahadevan/vision/external_algorithms/ClickSEG/experiments/iccv/segformer_multi\"\n",
    "f_datasets = [\"GrabCut\", \"Berkeley\", \"DAVIS\",\"COCO_MVal\",\"SBD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [ \"Resnet-50\", \"Swin-T\", \"Segformer-B0\", \"hrnet32\"]\n",
    "colors = [\"b\", \"y\", \"g\", \"r\", \"black\", \"orange\"]\n",
    "for j,d in enumerate(datasets):\n",
    "    print(d)\n",
    "    folder_path = os.path.join(_root_dir,d)\n",
    "    pkl_files = os.listdir(folder_path)\n",
    "    iou_list_per_model = []\n",
    "    min_iou = 1.0\n",
    "    max_iou = -1.0 \n",
    "    for f in pkl_files:\n",
    "        if \"json\" in f or \"_100\" in f:\n",
    "            continue\n",
    "        print(f)\n",
    "        pickle_path = os.path.join(folder_path, f)\n",
    "        with open(pickle_path, 'rb') as handle:\n",
    "            summary_stats= pickle.load(handle)\n",
    "        total_images = len(summary_stats.keys())\n",
    "        iou_per_click = np.zeros(20)\n",
    "        for _image_id in summary_stats.keys():\n",
    "            iou_per_click+=summary_stats[_image_id]\n",
    "        iou_per_click/=total_images\n",
    "        min_iou = min(min_iou,min(iou_per_click))\n",
    "        max_iou = max(max_iou, max(iou_per_click))\n",
    "        iou_list_per_model.append(iou_per_click)\n",
    "    \n",
    "    # json_path = os.path.join(focal_dir, f_datasets[j], \"others/segformer_b0\")\n",
    "    # files_others = os.listdir(json_path)\n",
    "    # for f in files_others:\n",
    "    #     if \".json\" in f:\n",
    "    #         print(f)\n",
    "    #         json_file = os.path.join(json_path,f)\n",
    "    #         break\n",
    "    # with open(json_file) as f:\n",
    "    #     focalclick = json.load(f)\n",
    "    # f_ious = list(focalclick['per_click_iou'].values())\n",
    "    # iou_list_per_model.append(f_ious)\n",
    "    # min_iou = min(min_iou, min(f_ious))\n",
    "    # max_iou = max(max_iou, max(f_ious))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    plt.figure(figsize=(15,10)) \n",
    "    n=20\n",
    "    for i in range(len(model_names)):\n",
    "        # if i==4 or i==5 or i==1:\n",
    "        plt.plot(range(1,n+1), iou_list_per_model[i][:n], colors[i],label=model_names[i], linewidth=3) #linestyle='dashed')\n",
    "    plt.title(f\"{f_datasets[j]}\",fontweight=\"bold\")\n",
    "    plt.xlabel(\"Number of clicks\")\n",
    "    plt.ylabel(\"mean IOU\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.xlim(0,21)\n",
    "    plt.yticks(np.arange(round(min_iou,2), max_iou+0.01, 0.01))\n",
    "    plt.xticks(np.arange(1,n+1,1))\n",
    "    # plt.ylim(min(iou_per_click)-0.01, max(iou_per_click)+0.01)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"noc_iou_{f_datasets[j]}.jpg\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "_root_dir = os.path.join(os.getcwd(), \"output/evaluation/final/summary/davis_single_inst\")\n",
    "pkl_file = \"mq_swin_tiny_fusion_pf_uni_time_pe_bs128_ep50_final_S1_argmax_100.pickle\"\n",
    "json_file = \"DAVIS_cvpr_FocalClick_20_single_instance_raw.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(_root_dir, json_file)) as f:\n",
    "    focalclick = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ious = list(focalclick['per_click_iou'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mq_swin_tiny_fusion_pf_uni_time_pe_bs128_ep50_final_S1_argmax_100.pickle', 'mq_mit_b0_fusion_pf_uni_time_pe_bs128_ep50_final_S1_argmax_100.pickle', 'mq_R50_fusion_pf_uni_time_pe_bs128_ep50_final_S1_argmax_100.pickle', 'mq_hrnet32_fusion_pf_uni_time_pe_bs128_ep50_final_S1_argmax_100.pickle', 'mq_mit_b3_fusion_pf_uni_time_pe_bs128_ep50_final_S1_argmax_100.pickle', 'DAVIS_cvpr_FocalClick_20_single_instance_raw.json', 'mq_swin_large_fusion_pf_uni_time_pe_bs32_ep100_0269999_S1_argmax_20.pickle', 'mq_swin_tiny_fusion_pf_uni_time_pe_bs128_ep50_final_S1_argmax_20.pickle', 'mq_R50_fusion_pf_uni_time_pe_bs128_ep50_final_S1_argmax_20.pickle', 'mq_mit_b0_fusion_pf_uni_time_pe_bs128_ep50_final_S1_argmax_20.pickle']\n"
     ]
    }
   ],
   "source": [
    "pkl_files = os.listdir(_root_dir)\n",
    "print(pkl_files)\n",
    "iou_list_per_model = []\n",
    "min_iou = 1.0\n",
    "max_iou = -1.0 \n",
    "for f in pkl_files:\n",
    "    if \"json\" in f or \"_20\" in f:\n",
    "        continue\n",
    "    pickle_path = os.path.join(_root_dir, f)\n",
    "    with open(pickle_path, 'rb') as handle:\n",
    "        summary_stats= pickle.load(handle)\n",
    "    total_images = len(summary_stats.keys())\n",
    "    iou_per_click = np.zeros(100)\n",
    "    for _image_id in summary_stats.keys():\n",
    "        iou_per_click+=summary_stats[_image_id]\n",
    "    iou_per_click/=total_images\n",
    "    min_iou = min(min_iou,min(iou_per_click))\n",
    "    max_iou = max(max_iou, max(iou_per_click))\n",
    "    iou_list_per_model.append(iou_per_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"swin-tiny\", \"mit-b0\", \"R50\", \"hrnet32\", \"mit-b3\",\"fclick-b0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"b\", \"r\", \"g\", \"y\", \"black\", \"orange\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = os.path.join(_root_dir, pkl_file)\n",
    "with open(pickle_path, 'rb') as handle:\n",
    "    summary_stats= pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summary_stats['272_0'])\n",
    "total_images = len(summary_stats.keys())\n",
    "iou_per_click = np.zeros(100)\n",
    "for _image_id in summary_stats.keys():\n",
    "    iou_per_click+=summary_stats[_image_id]\n",
    "iou_per_click/=total_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iou_per_click = np.round(iou_per_click,decimals=2)\n",
    "iou_list_per_model.append(f_ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_iou = min(min_iou, min(f_ious))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10)) \n",
    "n=20\n",
    "for i in range(len(model_names)):\n",
    "    # if i==4 or i==5 or i==1:\n",
    "    plt.plot(range(1,n+1), iou_list_per_model[i][:n], colors[i],label=model_names[i], linewidth=3) #linestyle='dashed')\n",
    "plt.title(\"DAVIS\")\n",
    "plt.xlabel(\"Number of clicks\")\n",
    "plt.ylabel(\"mean IOU\")\n",
    "plt.legend()\n",
    "plt.xlim(0,21)\n",
    "plt.yticks(np.arange(round(min_iou,2), max_iou+0.01, 0.01))\n",
    "plt.xticks(np.arange(1,n+1,1))\n",
    "# plt.ylim(min(iou_per_click)-0.01, max(iou_per_click)+0.01)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"noc_iou.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarising multi-instance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "_root_dir = os.path.join(os.getcwd(), \"output/evaluation/iccv_final/final/summary/sbd_multi_insts\")\n",
    "pkl_file = \"mq_swin_tiny_fusion_pf_stuff_concat_xyt_bs32_ep50_random_V1_seed_0_10.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = os.path.join(_root_dir, pkl_file)\n",
    "with open(pickle_path, 'rb') as handle:\n",
    "    summary_stats= pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious_objects_per_interaction = summary_stats[\"ious_objects_per_interaction\"]\n",
    "object_areas_per_image = summary_stats['object_areas_per_image']\n",
    "iou_threshold = summary_stats[\"iou_threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_area_bins = [0]*1001\n",
    "all_area_bins = [0]*1001\n",
    "for _image_id in ious_objects_per_interaction.keys():\n",
    "    final_ious = ious_objects_per_interaction[_image_id][-1]\n",
    "    obj_areas = object_areas_per_image[_image_id]\n",
    "    for i, iou in enumerate(final_ious):\n",
    "        indx = int(obj_areas[i]*1000)\n",
    "        if iou<iou_threshold:\n",
    "            failed_area_bins[indx] += 1\n",
    "        all_area_bins[indx]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(failed_area_bins))\n",
    "failed_area_bins[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(all_area_bins))\n",
    "all_area_bins[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_area_bins = np.asarray(all_area_bins) - np.asarray(failed_area_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "d = 1\n",
    "i=0\n",
    "while(i<100):\n",
    "    x.append(sum(failed_area_bins[i:i+d]))\n",
    "    y.append(sum(diff_area_bins[i:i+d]))\n",
    "    i+=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.append(sum(failed_area_bins[i:]))\n",
    "y.append(sum(diff_area_bins[i:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(failed_area_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,20,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2582"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAFzCAYAAAD16yU4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzW0lEQVR4nO3de7xVZZ348c+XI0KmoqmTKCpqWnlBMn6OjommeWl+pmkXYyo1M6RIzRpHx0yG6TI0k9200aEk1DGzvDT+zCk1LXXKhouIiJldwCBQMgXRIsDv74+9Dh4PZx8Oh7VvZ3/er9d+sdeznrX2dz9n78P3POtZzxOZiSRJkqRNN6jRAUiSJEkDhcm1JEmSVBKTa0mSJKkkJteSJElSSUyuJUmSpJKYXEuSJEkl2azRAWyK7bffPkeOHNnoMCRJkjQAzJo1izcO77nvedaSF/+QmTts6BwtnVyPHDmSmTNnNjoMSZIkDQARwczxW/a8b/KKhX05h8NCJEmSpJKYXEuSJEklMbmWJEmSStLSY677a+SI4SxcvHS98t123pEFi5Y0ICJJ9bB69WoWLVrEn//850aHogYbOnQoI0aMYPDgwY0ORdIA05bJ9cLFS8lJW69XHpPXT7glDRyLFi1iq622YuTIkUREo8NRg2QmTz/9NIsWLWL33XdvdDiSBhiHhUhqG3/+85/ZbrvtTKzbXESw3XbbeQVDUk2YXEtqKybWAj8HkmrH5FqS6qijo4PRo0eveyxYsKBq3b/5m78BYMGCBey3334b9Tqnn346N954Y5/rH3HEET2uG3DrrbcyZcqUjXrtTp/73Of6dZwktbK2HHMtSQDDR+zK0sW/K+18O+68C0sWPdFrnVe84hXMmTOnT+f76U9/WkJUm+aEE07ghBNO6Nexn/vc57joootKjkiSmpvJtaS2tXTx79jtgttKO9/Czx+/0cesXLmSE088kWeeeYbVq1fzmc98hhNPPBGALbfckpUrV76s/tq1a7nwwgv58Y9/zKpVq5g4cSJnnXUWmcnZZ5/NnXfeyS677MLmm2/e4+vNmTOHCRMm8MILL7Dnnnsybdo0tt12WwCuvfZazjzzTNasWcO0adM46KCDmD59OjNnzuTyyy9n2bJlTJgwgSeeqPwB8eUvf5lDDz2UlStXcvbZZzNz5kwigkmTJjFjxgz+9Kc/MXr0aPbdd1+mTp3Ku9/9bhYtWsTatWv51Kc+xSmnnLLR7SVJzc7kWpLqqDPhBNh999357ne/yy233MLWW2/NH/7wBw4++GBOOOGEqmOCr7rqKoYNG8aMGTNYtWoVhx56KMcccwwPPvggjz32GPPnz+fJJ59kn3324Ywzzljv+FNPPZXLLruMww8/nEsuuYTJkyfz5S9/GYAXXniBOXPmcO+993LGGWcwb968lx177rnnct555/GmN72JJ554gmOPPZZHH32UT3/60wwbNoyHH34YgGeeeYZ3vOMdXH755et66W+66SZ22mknvv/97wOwfPnyElpTkpqPybUk1VH3YSGrV6/moosu4t5772XQoEEsXryYJ598kh133LHH4++44w7mzp27bjz18uXLefzxx7n33nsZN24cHR0d7LTTThx55JHrHbt8+XKeffZZDj/8cABOO+003vWud63bP27cOADGjh3LihUrePbZZ192/F133cX8+fPXba9YsYKVK1dy11138e1vf3tdeWdPeFf7778/n/jEJ7jgggs4/vjjOeywwzbQUpLUmmqWXEfENOB44KnM3K8ouwF4bVFlG+DZzBwdESOBR4HHin0PZOaEWsUmSc3iuuuuY9myZcyaNYvBgwczcuTIXqeIy0wuu+wyjj322JeV33777ZscS/fe8u7bL774Ig888ABDhw7d6HPvvffezJ49m9tvv52LL76Yo446iksuuWST4pWkZlTL2UKmA8d1LcjMUzJzdGaOBm4Cbu6y+9ed+0ysJbWL5cuX81d/9VcMHjyYe+65h4ULF/Za/9hjj+WKK65g9erVAPzyl7/k+eefZ+zYsdxwww2sXbuWJUuWcM8996x37LBhw9h222257777gMoY685ebIAbbrgBgPvvv59hw4YxbNiwlx1/zDHHcNlll63b7uyBP/roo/na1762rvyZZ54BYPDgwevi/P3vf88WW2zB+973Ps4//3xmz57dp/aRpFZTs57rzLy36JFeT1S6Q94NrH/dUpLayHvf+17e9ra3sf/++zNmzBhe97rX9Vr/zDPPZMGCBRx44IFkJjvssAPf+973OOmkk7j77rvZZ5992HXXXTnkkEN6PP7qq69ed0PjHnvswTe/+c11+4YOHcob3vAGVq9ezbRp09aVd/Zgf/WrX2XixImMGjWKNWvWMHbsWK688kouvvhiJk6cyH777UdHRweTJk3i5JNPZvz48YwaNYoDDzyQU089lfPPP59BgwYxePBgrrjiihJaT5KaT2Rm7U5eSa5v6xwW0qV8LPDFzBzTpd4jwC+BFcDFmXlflXOOB8YD7Lrrrm/cUC9PlXNUWf58BbVsD0mN9eijj/L6179+3XYjpuJrNZdeeikrVqxg8uTJjQ6ldN0/D5JULUcEiMkrZnXmrr1p1A2N44Dru2wvAXbNzKcj4o3A9yJi38xc0f3AzJwKTAUYM2aMmbCkfhtoiXDZrrzySqZPn87NN9+84cqSJKABKzRGxGbAycANnWWZuSozny6ezwJ+Dexd79gkSS+ZMGECDz/8MHvttVejQ5GkltGI5c/fAvwiMxd1FkTEDhHRUTzfA9gL+E0DYpMkSZL6rWbJdURcD/wMeG1ELIqIDxa73sPLh4QAjAXmRsQc4EZgQmb+sVaxSZIkSbVQy9lCxlUpP72HspuoTM0nSZIktaxGDAuRJEmSBiSTa0mqo89+9rPsu+++jBo1itGjR/Pzn/+80SG9zIIFC/jWt7610cedfvrp65Zk74sjjjiCmTNnrld+6623MmXKlI1+fYDPfe5z/TpOkspkci2pbY0cMZyIKO0xcsTwXl/vZz/7GbfddhuzZ89m7ty53HXXXeyyyy51erd909/kuiwnnHACF154Yb+ONbmW1AwaNc+1JDXcwsVLqy4W0B8xeWmv+5csWcL222/PkCFDANh+++3X7Zs1axYf//jHWblyJdtvvz3Tp09n+PDhzJgxgw9+8IMMGjSIo48+mv/+7/9m3rx5TJ8+ne9973s8//zzPP744/z93/89f/nLX7j22msZMmQIt99+O6961av49a9/zcSJE1m2bBlbbLEFX//613nd617H6aefztZbb83MmTNZunQp//qv/8o73/lOLrzwQh599FFGjx7NaaedxjnnnMOFF17Ij3/8Y1atWsXEiRM566yzyEzOPvts7rzzTnbZZRc233zzHt/znDlz1q0IueeeezJt2jS23XZboLL8+plnnsmaNWuYNm0aBx10ENOnT2fmzJlcfvnlLFu2jAkTJvDEE5X5yL/85S9z6KGHsnLlSs4++2xmzpxJRDBp0iRmzJjBn/70J0aPHs2+++7L1KlTefe7382iRYtYu3Ytn/rUpzjllFPK+DFLUq/suZakOjnmmGP43e9+x957781HPvIRfvKTnwCwevVqzj77bG688UZmzZrFGWecwSc/+UkAPvCBD/Af//EfzJkzh46Ojpedb968edx8883MmDGDT37yk2yxxRY8+OCDHHLIIVxzzTUAjB8/nssuu4xZs2bxhS98gY985CPrjl+yZAn3338/t91227re4ilTpnDYYYcxZ84czjvvPK666iqGDRvGjBkzmDFjBl//+tf57W9/yy233MJjjz3G/Pnzueaaa/jpT3/a43s+9dRT+fznP8/cuXPZf//9X7bS4wsvvMCcOXP493//d84444z1jj333HM577zzmDFjBjfddBNnnnkmAJ/+9KcZNmwYDz/8MHPnzuXII49kypQpvOIVr2DOnDlcd911/OAHP2CnnXbioYceYt68eRx33HH9/bFJ0kYZsD3XI0cMZ+Hi3nuRJKmettxyS2bNmsV9993HPffcwymnnMKUKVMYM2YM8+bN4+ijjwZg7dq1DB8+nGeffZbnnnuOQw45BIC/+7u/47bbblt3vje/+c1stdVWbLXVVgwbNoy3ve1tAOy///7MnTuXlStX8tOf/pR3vetd645ZtWrVuudvf/vbGTRoEPvssw9PPvlkjzHfcccdzJ07d9146uXLl/P4449z7733Mm7cODo6Othpp5048sgj1zt2+fLlPPvssxx++OEAnHbaaS+LZdy4yqRSY8eOZcWKFTz77LMvO/6uu+5i/vz567ZXrFjBypUrueuuu/j2t7+9rryzJ7yr/fffn0984hNccMEFHH/88Rx22GE9vj9JKtuATa57u9wbk9dbVV2S6qKjo4MjjjiCI444gv3335+rr76aN77xjey777787Gc/e1nd7slmd53DSwAGDRq0bnvQoEGsWbOGF198kW222YY5c+Zs8PjM7LFOZnLZZZdx7LHHvqz89ttv7zW2voiIXrdffPFFHnjgAYYOHbrR5957772ZPXs2t99+OxdffDFHHXUUl1xyySbFK0l94bAQSaqTxx57jMcff3zd9pw5c9htt9147Wtfy7Jly9Yl16tXr+aRRx5hm222Yauttlo3o0jX3tq+2Hrrrdl999357ne/C1QS5YceeqjXY7baaiuee+65ddvHHnssV1xxBatXrwbgl7/8Jc8//zxjx47lhhtuYO3atSxZsoR77rlnvXMNGzaMbbfdlvvuuw+ojLHu7MUGuOGGGwC4//77GTZsGMOGDXvZ8ccccwyXXXbZuu3OPxKOPvpovva1r60rf+aZZwAYPHjwujh///vfs8UWW/C+972P888/n9mzZ/f6viWpLAO251qSmk3njXjPPvssm222Ga95zWuYOnUqm2++OTfeeCPnnHMOy5cvZ82aNXzsYx9j33335aqrruJDH/oQgwYN4vDDD18vAd2Q6667jg9/+MN85jOfYfXq1bznPe/hgAMOqFp/1KhRdHR0cMABB3D66adz7rnnsmDBAg488EAykx122IHvfe97nHTSSdx9993ss88+7LrrruuGrnR39dVXr7uhcY899uCb3/zmun1Dhw7lDW94A6tXr2batGnryjt7sL/61a8yceJERo0axZo1axg7dixXXnklF198MRMnTmS//fajo6ODSZMmcfLJJzN+/HhGjRrFgQceyKmnnsr555/PoEGDGDx4MFdcccVGtZsk9VdUuxTYCsaMGZM9zZMKlV/OvQ0L6WlfTF5R9dKopNb36KOP8vrXv37ddtn3Zuy2844sWLSktPNBJSHfcsstgcrNhkuWLOErX/lKqa/RTC699FJWrFjxshsfa6X750GSNpA/zsrMMRs6hz3XktpW2YlwLXz/+9/nX/7lX1izZg277bYb06dPb3RINXPllVcyffp0br755kaHIkn9ZnItSU3slFNOaZv5mSdMmMCECRMaHYYkbRJvaJQkSZJKYnItqa14X4XAz4Gk2jG5ltQ2hg4dytNPP21i1eYyk6effrpf82dL0oY45lpS2xgxYgSLFi1i2bJljQ5FDTZ06FBGjBjR6DAkDUAm15LaxuDBg9l9990bHYYkaQBzWIgkSZJUEpNrSZIkqSQm15IkSVJJTK4lSZKkkphcS5IkSSUxuZYkSZJKYnItSZIklcTkWpIkSSqJybUkSZJUEpNrSZIkqSQm15IkSVJJTK4lSZKkkphcS5IkSSUxuZYkSZJKYnItSZIklcTkWpIkSSqJybUkSZJUEpNrSZIkqSQ1S64jYlpEPBUR87qU/VNELI6IOcXjb7vs+8eI+FVEPBYRx9YqLkmSJKlWatlzPR04rofyL2Xm6OJxO0BE7AO8B9i3OObfI6KjhrFJkiRJpatZcp2Z9wJ/7GP1E4FvZ+aqzPwt8CvgoFrFJkmSJNVCI8ZcfzQi5hbDRrYtynYGftelzqKibD0RMT4iZkbEzGXLltU6VkmSJKnP6p1cXwHsCYwGlgCXbuwJMnNqZo7JzDE77LBDyeFJkiRJ/VfX5Dozn8zMtZn5IvB1Xhr6sRjYpUvVEUVZXQ3pgIjo8TFyxPAejxk5YvhGHyNJkqSBabN6vlhEDM/MJcXmSUDnTCK3At+KiC8COwF7Af9bz9gAVq2FnLR1j/ti8tIeyxcuXrrRx0iSJGlgqllyHRHXA0cA20fEImAScEREjAYSWACcBZCZj0TEd4D5wBpgYmaurVVskiRJUi3ULLnOzHE9FF/VS/3PAp+tVTySJElSrblCoyRJklQSk2tJkiSpJCbXkiRJUklMriVJkqSSmFxLkiRJJTG5liRJkkpici1JkiSVxORakiRJKonJtSRJklQSk2tJkiSpJCbXkiRJUklMriVJkqSSmFxLkiRJJTG5liRJkkpici1JkiSVxORakiRJKslmjQ6gVQzpgIhodBiSJElqYibXfbRqLeSkrdcrj8krGhCNJEmSmpHDQiRJkqSSmFxLkiRJJTG5liRJkkpici1JkiSVxORakiRJKonJtSRJklQSk2tJkiSpJCbXkiRJUklMriVJkqSSmFxLkiRJJTG5liRJkkpici1JkiSVxORakiRJKonJtSRJklQSk2tJkiSpJCbXkiRJUklMriVJkqSS1Cy5johpEfFURMzrUvZvEfGLiJgbEbdExDZF+ciI+FNEzCkeV9YqLkmSJKlWatlzPR04rlvZncB+mTkK+CXwj132/TozRxePCTWMS5IkSaqJmiXXmXkv8MduZXdk5ppi8wFgRK1eX5IkSaq3Ro65PgP47y7bu0fEgxHxk4g4rNpBETE+ImZGxMxly5bVPkpJkiSpjxqSXEfEJ4E1wHVF0RJg18x8A/Bx4FsRsXVPx2bm1Mwck5ljdthhh/oELEmSJPVB3ZPriDgdOB54b2YmQGauysyni+ezgF8De9c7NkmSJGlT1DW5jojjgH8ATsjMF7qU7xARHcXzPYC9gN/UMzZJkiRpU21WqxNHxPXAEcD2EbEImERldpAhwJ0RAfBAMTPIWOCfI2I18CIwITP/2OOJJUmSpCZVs+Q6M8f1UHxVlbo3ATfVKhZJkiSpHlyhUZIkSSpJzXqu6+HhuQ9RDC+RJEmSGq6lk+u/rF5DTupxxj5i8oo6RyNJkqR257AQSZIkqSQm15IkSVJJTK4lSZKkkphcS5IkSSUxuZYkSZJKYnItSZIklcTkWpIkSSqJyXUNDemAiOjxMXLE8EaHJ0mSpJK19CIyzW7VWnpZ5GZpnaORJElSrdlzLUmSJJXE5FqSJEkqicm1JEmSVBKTa0mSJKkkJteSJElSSUyuJUmSpJKYXEuSJEklMbmWJEmSSmJyLUmSJJXE5FqSJEkqicm1JEmSVBKT6yYzcsRwIqLHx8gRwxsdniRJknqxWaMD0MstXLyUnLR1j/ti8tI6RyNJkqSNYc+1JEmSVJIB23M9pANi8opGhyFJkqQ2MmCT61VrYbcLbutx38LPH1/naCRJktQOHBYiSZIklcTkWpIkSSpJSw8LGRTVx1UP6ahzMJIkSWp7LZ1cv5iOq5YkSVLz2OCwkIjYMyKGFM+PiIhzImKbmkcmSZIktZi+jLm+CVgbEa8BpgK7AN+qaVSSJElSC+pLcv1iZq4BTgIuy8zzAdfhliRJkrrpS3K9OiLGAacBnQOcB/fl5BExLSKeioh5XcpeFRF3RsTjxb/bFuUREV+NiF9FxNyIOHBj30w7GzliOBGx3mPkCP8OkiRJqpe+3ND4AWAC8NnM/G1E7A5c28fzTwcuB67pUnYh8KPMnBIRFxbbFwBvBfYqHn8NXFH8qz5YuHgpOWnr9cpj8tIGRCNJktSe+tJzfXRmnpOZ1wNk5m+BP/fl5Jl5L/DHbsUnAlcXz68G3t6l/JqseADYJiLsdpUkSVLL6EtyfVoPZadvwmu+OjOXFM+XAq8unu8M/K5LvUVF2ctExPiImBkRMzchBkmSJKl0VYeFFOOs/w7YPSJu7bJrK9bvje6XzMyIyI08ZiqVWUvY2GMlSZKkWuptzPVPgSXA9sClXcqfA+Zuwms+GRHDM3NJMezjqaJ8MZVp/jqNKMokSZKkllB1WEhmLszMHwPvBX6emT/JzJ8Aj1JJfPvrVl4aanIa8F9dyk8tZg05GFjeZfiIJEmS1PT6Mub6O8CLXbbXAt/ty8kj4nrgZ8BrI2JRRHwQmAIcHRGPA28ptgFuB34D/Ar4OvCRPr0DSZIkqUn0ZSq+zTLzL50bmfmXiNi8LyfPzHFVdh3VQ90EJvblvJIkSVIz6kvP9bKIOKFzIyJOBP5Qu5BUzZAOelwoJiIaHZokSZLoW8/1BOC6iPgakFSmyDu1plGpR6vW0uNCMQAxeUWdo5EkSVJ3G0yuM/PXwMERsWWxvbLmUUmSJEktaIPDQiLi1RFxFfDdzFwZEfsUNyZKkiRJ6qIvY66nAz8Ediq2fwl8rEbxSJIkSS2rL8n19pm5bjq+zFxDZTo+SZIkSV30Jbl+PiK2o3IzI50LvNQ0KkmSJKkF9WW2kI9TWT1xz4j4H2AH4J01jUqSJElqQX2ZLWR2RBwOvBYI4LHMXF3zyCRJkqQWUzW5jogjM/PuiDi52669IyKBPwL3Z6bjr/uhc0EYSZIkDRy99VwfDtwNvK3K/u2Ai4Gjyw6qHVRbEMbFYCRJklpX1eQ6MycV/36gWp1i/mtJkiRJ9G0Rme0i4qsRMTsiZkXEV4rZQ8hMF5ORJEmSCn2Ziu/bwDLgHVRmCVkG3FDLoCRJkqRW1Jep+IZn5qe7bH8mIk6pVUCSJElSq+pLz/UdEfGeiBhUPN5NZTl0SZIkSV30NhXfc1RWZQzgY8B/FrsGASuBv691cJIkSVIr6W22kK3qGYgkSZLU6nodcx0RmwPvBfYtih4BrsvMv9Q6MEmSJKnVVB1zHRH7APOBI4AniscRwPyI2LfacZIkSVK76q3n+jLgw5l5Z9fCiHgLcDnw5loGJkmSJLWa3mYL2bl7Yg2QmXcBO9YuJEmSJKk19ZZcD4qIId0LI2IofZsfW5IkSWorvSXX1wA3RcRunQURMRL4DnBtjeOSJEmSWk5vU/F9JiI+CtwXEVsUxc8DX8jMy+oSnSRJktRCeh3ekZmXA5dHxFbF9nN1iUqSJElqQRtc/jwiLs7M5zLzuZ7GYEuSJEmq6G2e6wsi4hDgnV2Kf1b7kCRJkqTW1NuwkF8A7wL2iIj7iu3tIuK1mflYXaKTJEmSWkhvw0KeBS4CfkVlZcavFOUXRsRPaxuWJEmS1Hp667k+FrgE2BP4IjAXeD4zP1CPwCRJkqRWU7XnOjMvysyjgAVU5rXuAHaIiPsj4v/VKT5JkiSpZfRlpcUfZuZMYGZEfDgz3xQR29c6MEmSJKnVbHAqvsz8hy6bpxdlf6hVQJIkSVKr2mBy3VVmPlSrQCRJkqRW15dhIaWKiNcCN3Qp2oPKjZPbAB8ClhXlF2Xm7fWNTpIkSeq/uifXxRzZowEiogNYDNwCfAD4UmZ+od4xSZIkSWXYqGEhNXAU8OvMXNjgOAasIR0QET0+Ro4Y3ujwJEmSBpS691x38x7g+i7bH42IU4GZwCcy85nGhDVwrFoLOWnrHvfF5KV1jkaSJGlga1jPdURsDpwAfLcouoLKgjWjgSXApVWOGx8RMyNiZj3ilCRJkvqqkcNC3grMzswnATLzycxcm5kvAl8HDurpoMycmpljMnNMHWOVJEmSNqiRyfU4ugwJiYiuA4BPAubVPSJJkiRpEzRkzHVEvBI4GjirS/G/RsRoIKksuX7W+kdKkiRJzashyXVmPg9s163s/Y2IRZIkSSpLo6fikyRJkgYMk2tJkiSpJCbXkiRJUklMriVJkqSSmFxLkiRJJTG5bmNDOiAieny8ckhHj+UjRwzf8IklSZLaVEOm4lNzWLUWctLWPe6LySt63BeTl9Y6LEmSpJZlz7UkSZJUEpNrSZIkqSRtOSxkyGaVYQ+SJElSmdoyuV61Bna74Lb1yhd+/vgGRNNaOm+C7MluO+/IgkVL6hyRJElS82jL5Fr91/tNkN7sKEmS2ptjriVJkqSSmFxLkiRJJTG5VtMaOWK4C9lIkqSW4phrNa2Fi5e6kI0kSWop9lxLkiRJJTG5liRJkkpici1JkiSVxORakiRJKonJtSRJklQSk2tJkiSpJCbXkiRJUklMriVJkqSSmFxLkiRJJTG5Vs1VW8a8FkuZ1/O1JEmSunP5c9VctWXMofylzPvzWiNHDGfh4p737bbzjixYtKS0+CRJ0sBmcq22V8/kX5IkDWwm12o5QzogIhodhiRJ0npMrtVyVq2ll57mFXWORpIk6SXe0ChJkiSVxORakiRJKonDQlSa/oyFdvy0JEkaSEyuVZpqY6F7Gwft+GlJkjSQOCxEkiRJKknDeq4jYgHwHLAWWJOZYyLiVcANwEhgAfDuzHymUTFKkiRJG6PRPddvzszRmTmm2L4Q+FFm7gX8qNiWJEmSWkKjk+vuTgSuLp5fDby9caFIkiRJG6eRyXUCd0TErIgYX5S9OjOXFM+XAq9uTGiSJEnSxmvkbCFvyszFEfFXwJ0R8YuuOzMzIyK7H1Qk4uO7l0uSJEmN1rCe68xcXPz7FHALcBDwZEQMByj+faqH46Zm5pgu47SlpjJyxHAiosfHyBHDSztGkiQ1n4b0XEfEK4FBmflc8fwY4J+BW4HTgCnFv//ViPikTbFw8dJe5u5eWtoxkiSp+TRqWMirgVuKlfk2A76VmT+IiBnAdyLig8BC4N0Nik8Cqq8gudvOO7Jg0ZIejpAkSe2sIcl1Zv4GOKCH8qeBo+ofkdSz6qtO2pssSZLW12xT8UmSJEkty+RakiRJKonJtdQPnWOxe3o0u2ozkzgriSRJm66R81xLLavaWGyAmLyiztFsnGozkzTLOPKRI4azcPH6sXgTqSSpFZhcS2oqzZ78S5LUG4eFSJIkSSUxuZYkSZJKYnItSZIklcTkWpIkSSqJybUkSZJUEpNrSZIkqSQm15IkSVJJTK6lJtfbapCvHNLhaouSJDURF5GRmtyGVoN0wRVJkpqHPdeSNmjkiOFVe8/tJZck6SX2XEvaoGpLkoO95JIkdWXPtdpGtbHL7RaDWl+1KwleRZCkxrPnWm2j2tjlmLyirWJQ66t2JcGrCJLUePZcS5IkSSUxuZYGoN6m72tVvb0nh0NIkpqFw0KkAWhD0/e1ot7fk8MhJEnNwZ5rSZIkqSQm15IkSVJJHBbSxZDNWveSuSRJkhrP5LqLVWtgtwtu63Hfws8fX+doJEmS1GocFiJJkiSVxORa0iapNkVePafH6880fdVWOWzlqf2crlCSGs9hIZI2SfVVJ+s3PV5/pumrtsphb8c0O6crlKTGs+daUk3Yi/qSar3kvbVDbz3rkqTmZc+1pJqwF/Ul1XrJe2uH3nvWndVIkpqVPdeSJElSSUyuJUmSpJKYXEsCeh8j3W6aYQaUZtefceRlvo4/D0nNyjHXfeTqjRroeh8j3V6f/WaYAaXZ9WcceZmvU4vXUmsYOWI4Cxev/7PfbecdWbBoSQMikl7O5LqPqq3e6MqNkiTVT73+sJP6q+7DQiJil4i4JyLmR8QjEXFuUf5PEbE4IuYUj7+td2yS1BunF1QZHOqi7uo1zEr10Yie6zXAJzJzdkRsBcyKiDuLfV/KzC80ICZJ2iCnF1QZHOqi7uyNH1jq3nOdmUsyc3bx/DngUWDneschSWUaiDeEupCNJG28ho65joiRwBuAnwOHAh+NiFOBmVR6t59pYHiS1GcD8YZQF7KRpI3XsKn4ImJL4CbgY5m5ArgC2BMYDSwBLq1y3PiImBkRM+sVq6RyDcReXkmSoEE91xExmEpifV1m3gyQmU922f91YP2pOSr1pgJTi3pZ+2h75xR90sYbiL28/dH5R0a7qDaFGvRvGrVq7dfbucqOQbXR289JanZ1T66j8pvwKuDRzPxil/Lhmdn5W+0kYF69Y+uPalP0gdP0Sepdu/2RUfaNfP2Zj9ybCVuDQ5LUyhrRc30o8H7g4YiYU5RdBIyLiNFAAguAsxoQmySpAdqtF1/SwFX35Doz7wd6+g16e71jkSQ1h+q90PZSSmotrtAoSVI/NcMY7maIQRootti8Y5P/qDe5liSpn5phDHczxCANFC/8Ze0m30vXsKn4JEkDj9Mstr5WXZ69t89eM8fdX636c+qvVloi3p5rSVJp2m0GlIGoVXvCe//sNW/c/dWqP6f+aqUl4u25lqQ2UK1Xrxl7fZpNf5eBr9bmzaDs99TKn6NW6hGtpXbrCa8le64lqQ30Z07oVlX2tH79nXO5mWdAKf89te7nqJV6RPuqPwsstVtPeC2ZXEuSBhSHpqjdDcQ/glqJw0IkDWjNfGm+GXgDYnPp7efxyiEdLflzcrhB86jn973Zf+7V4hvSsenntuda0oDWzJfmm4G9vM1lQz+PVvwsO9ygedTz+97sP/fqw4E2vR3suZYkSZuk2a+ANEOPbX96a5u9XZtBf6721Lr97LmWJEmbpNmvgDRDj21/emubvV2bQX+u9nTuqxV7riVJkrppt0VpejMQp2CsJXuuJUkaoMqelrCdtNuiNL1x9pGNY3ItSdIA5Q29Uv05LESSJJy2sRHaqc29OfElA32YiT3XkiRhL28jtFObe3PiSwb6MBOT6xoasln7fWEkSRroHMuu3phc19CqNbDbBbf1uG/h54+vczSSJKkM9kKrN465liRJkkpiz7UkSZIabqAMtzG5liRJUsMNlOE2JtcN4s2OkiRJA4/JdYNUu9nRGx0lSZJalzc0SpIkSSUxuZYkSZJK4rCQJtPfsdhDOno+bqhjuyVJUg0MlNk9ymZy3WT6u/DMqrXVx3CXuZBNtSRekiS1l4Eyu0fZTK61Uaol8eDNmJIkSSbXLaS3ISNDOkp+rSo91GW/jiRJ0kBict1C+jtkpF+v1cswE0mSJPXM5FqlcWEcSZLU7kyuVRoXxpEkSe3O5LqN1WsMdz17tJ3NRJIkNZLJdRur1xjuZhgrXovXkiRJ6s7kWqoje9YlSdp4rfT/Z9Ml1xFxHPAVoAP4RmZOaXBIqqFmuAmyty9stRUu+7vyZbWe9aWXHl/qypytekyzKDv2Vm4LSa1nIP7OaaVZzJoquY6IDuBrwNHAImBGRNyamfMbG5lqpZ5DRqrGsIGhJPVY+bIWK3PW45jejmvlITpl/xJvpf8UJLU+f+c0VlMl18BBwK8y8zcAEfFt4ETA5LoNld2rXe18pS/AU8fFfsqMoRni7k1/rjCUHkMvr9NbDP1pv7Lfb7P3ZFWLrxneazN89nqLo7cY6hlfNV75ah79/R3Wr9dq4naotWZLrncGftdlexHw1w2KRQ1W9tR+9ZoqsCl64/sRQzPE3Zv+XGHo3FdaDBtoo1KvZvTzisrGnq8ZfrbQe3yNvmrSDJ+93uLYUAyN/rl75auiGeJupt9hA1lkZqNjWCci3gkcl5lnFtvvB/46Mz/apc54YHyxuR8wr+6BNqftgT80OogmYDtU2A4vsS0qbIcK26HCdniJbVFhO1T01g67ZeYOGzpBs/VcLwZ26bI9oihbJzOnAlMBImJmZo6pX3jNy7aosB0qbIeX2BYVtkOF7VBhO7zEtqiwHSrKaIdBZQVTkhnAXhGxe0RsDrwHuLXBMUmSJEl90lQ915m5JiI+CvyQylR80zLzkQaHJUmSJPVJUyXXAJl5O3B7H6tPrWUsLca2qLAdKmyHl9gWFbZDhe1QYTu8xLaosB0qNrkdmuqGRkmSJKmVNduYa0mSJKlltURyHRHHRcRjEfGriLiwh/1DIuKGYv/PI2JkA8KsuYiYFhFPRUSP0w9GxVeLdpgbEQfWO8Z6iIhdIuKeiJgfEY9ExLk91BnwbRERQyPifyPioaIdJvdQpy2+G1BZ4TUiHoyI9SZWbbN2WBARD0fEnIiY2cP+Af/dAIiIbSLixoj4RUQ8GhGHdNs/4NshIl5bfA46Hysi4mPd6gz4dgCIiPOK35PzIuL6iBjabX87/Y44t2iHR7p/Hor9bfGZ6ElEfLR43xkR23cp36g2afrkOl5aEv2twD7AuIjYp1u1DwLPZOZrgC8Bn69vlHUzHTiul/1vBfYqHuOBK+oQUyOsAT6RmfsABwMTe/hMtENbrAKOzMwDgNHAcRFxcLc67fLdADgXeLTKvnZqB4A3Z+boKtNJtcN3A+ArwA8y83XAAaz/2Rjw7ZCZjxWfg9HAG4EXgFu6VRvw7RAROwPnAGMycz8qEya8p1u1tvgdERH7AR+isiL2AcDxEfGabtUG7GciIrbdQJX/Ad4CLOxWvlFt0vTJNV2WRM/MvwCdS6J3dSJwdfH8RuCoiIg6xlgXmXkv8MdeqpwIXJMVDwDbRMTw+kRXP5m5JDNnF8+fo/Kf5s7dqg34tije28pic3Dx6H4TRVt8NyJiBPB/gW9UqdIW7dBHA/67ERHDgLHAVQCZ+ZfMfLZbtQHfDt0cBfw6M7snDe3SDpsBr4iIzYAtgN93298uvyNeD/w8M1/IzDXAT4CTu9UZyJ+JmRFxXUQc2dPPNzMfzMwFPRy3UW3SCsl1T0uid0+k1tUpPizLge3qEl1z6UtbDSjFpbs3AD/vtqst2qIYCjEHeAq4MzOrtsMA/258GfgH4MUq+9ulHaDyB9YdETErKivadtcO343dgWXAN4uhQt+IiFd2q9MO7dDVe4Dreygf8O2QmYuBLwBPAEuA5Zl5R7dq7fI7Yh5wWERsFxFbAH/Lyxfvg4H9mdibyvfgo8D8iLgoInbqw3Eb1SatkFxLPYqILYGbgI9l5opGx9MImbm2uOQ7AjiouOTXViLieOCpzJzV6FiaxJsy80AqlzEnRsTYRgfUAJsBBwJXZOYbgOeB9e7XaRdRWZTtBOC7jY6lEYqhACdS+aNrJ+CVEfG+xkbVGJn5KJUhL3cAPwDmAGsbGVM9Ff9n3paZJ1O5urUH8EREHFTm67RCcr3BJdG71iku+QwDnq5LdM2lL201IETEYCqJ9XWZeXMPVdqmLQCKS973sP6Y/Hb4bhwKnBARC6gMGzsyIv6zW512aAdgXS8dmfkUlfG13f/TaIfvxiJgUZcrOTdSSba7aod26PRWYHZmPtnDvnZoh7cAv83MZZm5GrgZ+Jtuddrpd8RVmfnGzBwLPAP8sluVAf2ZiIhhEXEWlRXA9wLOAOZu4LCNapNWSK77siT6rcBpxfN3Andne07gfStwanFX68FULn0taXRQZSvGSV0FPJqZX6xSbcC3RUTsEBHbFM9fARwN/KJbtQH/3cjMf8zMEZk5ksrvh7szs3uv1IBvB4CIeGVEbNX5HDiGymXgrgb8dyMzlwK/i4jXFkVHAfO7VRvw7dDFOHoeEgLt0Q5PAAdHxBbF/x9Hsf4Nrm3xOwIgIv6q+HdXKuOtv9WtyoD9TBQdL7OpXMU4NTMPz8xrMvPPGzh0o9qk6VZo7C6rLIkeEf8MzMzMW6kkWtdGxK+o3PDX/S7gASEirgeOALaPiEXAJCo3sZGZV1JZ2fJvgV9RuSv8A42JtOYOBd4PPFyMNwa4CNgV2qothgNXFzPqDAK+k5m3teN3oydt2g6vBm4p7tPZDPhWZv4gIiZAW303AM4Gris6ZX4DfKAd26H4I+to4KwuZW3VDpn584i4kUpStQZ4EJjapr8jAG6KiO2A1cDEzHy2jT4T3wFOL8bVrycizqFy/86OwNyIuD0zz2Qj28QVGiVJkqSStMKwEEmSJKklmFxLkiRJJTG5liRJkkpici1JkiSVxORakiRJKonJtaS2ERFvj4iMiNc1OpZ6iogFEbF9D+Ura/BaP46IMT2UnxAR/VolMSIu6mXf2oiYExE7RcSQiPhBRMyLiI90qTM1Ig7ssn1eRDwREZf3Jx5J6o3JtaR2Mg64v/h3PcXKbC2hlWIFyMxbM3NKPw+vmlwDf8rM0Zn5e+BYKj/fUVTmwiciDgA6MnN2l1i+BFzSz1gkqVcm15LaQkRsCbwJ+CBdFoiIiCMi4r6IuBWYHxEdEfFvETEjIuYWy+QSEVtGxI8iYnZEPBwRJ1Z5neOKOg9FxI+KsldFxPeK8z0QEaMiYlDRo7xNl2Mfj4hXF6tv3lTEMCMiDi32/1NEXBsR/0NlwYtq9baLiDsi4pGI+AYQvbTLl4p6PyrOt2dEzO6yf6+u213KRxfvZW5E3BIR23bZ/f6iN3leRBxU1D+9s6e4l7i3jIhvFu07NyLeERFTgFcU57uulx8xVBbF2ILK4lqd7/nTwKc2cJwklcbkWlK7OBH4QWb+Eng6It7YZd+BwLmZuTeV5Ht5Zv4f4P8AH4qI3YE/Aydl5oHAm4FLo1gKsVNE7AB8HXhHZh4AvKvYNRl4MDNHUemFvSYzXwT+CzipOPavgYWZ+STwFeBLRQzvAL7R5WX2Ad6SmeN6qTcJuD8z9wVuoVi9tAevpLJC3b7AT4BJmflrYHlEjC7qfAD4Zg/HXgNcULynh4vX7LRFZo4GPgJM6+HYanF/ikrb71+c9+7MvJCXeqffW+V9dLoTGAk8AHw1Ik4AZhe92pJUFy11WVGSNkFnMgrw7WJ7VrH9v5n52+L5McCoiHhnsT0M2AtYBHwuIsYCLwI7U1lufGmX1zgYuLfzXJn5x6L8TVSSSDLz7qJneWvgBirDE75JpTf9hqL+W4B9uuTuWxc97wC3ZuafNlBvLHBy8Xrfj4hnqrTJi11e8z+Bm4vn36CyXPjHgVOAg7oeFBHDgG0y8ydF0dXAd7tUub547XsjYuuuvfMbiPstdLmqkJnV4u5RsaTx3xUxDgZ+CJwYEV+k8gfGNcVS15JUMybXkga8iHgVcCSwf0Qk0AFkRJxfVHm+a3Xg7Mz8YbdznA7sALwxM1dHxAJg6CaG9jPgNUWP99uBzxTlg4CDM/PP3WLoHmtv9foji39votITfTcwKzOf7ud5qm2XHXdPPkKld/1gYDmVPxLuBkyuJdWUw0IktYN3Atdm5m6ZOTIzdwF+CxzWQ90fAh8uej6JiL0j4pVUerCfKhLrNwO79XDsA8DYYhhJZ1IPcB/w3qLsCOAPmbkiM5PKsI0vAo92SWLvAM7uPGmXIRrdVat3Ly/14L4V2Ha9IysGUWkbivr3AxRJ7w+BK+hhSEhmLgeeiYjO9ns/lWElnU4pXvtNVIZ5LO9j3HcCE7uUd8a9uvPn0RfFccdTSa63oNJDn8Ar+noOSeovk2tJ7WAclSS2q5voedaQbwDzgdkRMQ/4DypX+a4DxkTEw8CpwC+6H5iZy4DxwM0R8RAvDbn4J+CNETEXmAKc1uWwG4D3dakLcE7xWnMjYj4wocr7qlZvMpUk/xEqw0OeqHL888BBxfs8EvjnLvuuo5KU3lHl2NOAfyve0+hux/45Ih4ErqQyhr1TZw92tbg/A2xb3Aj5EJWx7QBTgbl9uKGx0yXAZ4tx7T+k8kfUw8C1fTxekvotKh0nkiS9JCL+HhiWmaXMtBERnwC2zsxJG6y8ceddmZlbbrjmesedDozJzI+WGY8k2XMtSXqZiLiFSu/8VzZUt4/nmwCcTuWmybKtKKbp22kj4jkP+EdgRQ3ikdTm7LmWJEmSSmLPtSRJklQSk2tJkiSpJCbXkiRJUklMriVJkqSSmFxLkiRJJTG5liRJkkry/wE3/HfYsALGEwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = len(x)\n",
    " \n",
    "# boys = (20, 35, 30, 35, 27)\n",
    "# girls = (25, 32, 34, 20, 25)\n",
    "# boyStd = (2, 3, 4, 1, 2)\n",
    "# girlStd = (3, 5, 2, 3, 3)\n",
    "ind = np.arange(N)  \n",
    "width =1.0\n",
    "# ticks = (f\"{(i+1)*d/10}\" for i in list(range(0,N)) \n",
    "fig = plt.subplots(figsize =(12, 6))\n",
    "p1 = plt.bar(ind, x, width,edgecolor='black',align='edge')\n",
    "p2 = plt.bar(ind, y, width,align='edge',\n",
    "             bottom = x,edgecolor='black')\n",
    "\n",
    "for (rect1, rect2) in zip(p1,p2):\n",
    "    height = rect1.get_height() + rect2.get_height()\n",
    "    perc =  round((rect2.get_height()/height)*100,ndigits=2)\n",
    "    # plt.text(rect1.get_x() + rect1.get_width() / 2.0, height, f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.ylabel('#Objects ')\n",
    "# plt.title('Failed object areas visualization')\n",
    "plt.xlabel(\"Area covered by object [%]\")\n",
    "plt.xticks(range(0,101,10), ('0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0', '9.0', '>10'))\n",
    "# plt.xticks(range(N), ticks)\n",
    "# plt.yticks(np.arange(0, 1000,100))\n",
    "plt.ylim(0,185)\n",
    "plt.xlim(0,101)\n",
    "plt.legend((p1[0], p2[0]), ('Failed objects', 'Segmented objects'))\n",
    "import tikzplotlib\n",
    "\n",
    "tikzplotlib.save(\"test.tex\")\n",
    "plt.savefig(\"a.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "# Bring some raw data.\n",
    "frequencies = x\n",
    "# In my original code I create a series and run on that,\n",
    "# so for consistency I create a series from the list.\n",
    "freq_series = pd.Series(frequencies)\n",
    "\n",
    "x_labels = [f\"{i+1}\" for i in range(len(x)-1)]\n",
    "x_labels.append(\">25\")\n",
    "\n",
    "# Plot the figure.\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = freq_series.plot(kind=\"bar\")\n",
    "# ax.set_title(\"Failed Object Areas Distribution\")\n",
    "\n",
    "ax.set_xlabel(\"% of Image Covered by Object\")\n",
    "ax.set_ylabel(\"#Failed Objects\")\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set_ylim(0,825)\n",
    "ax.set_xlim(-1,26)\n",
    "rects = ax.patches\n",
    "\n",
    "# Make some labels.\n",
    "labels = [f\"{x[i]}\" for i in range(len(rects))]\n",
    "\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(\n",
    "        rect.get_x() + rect.get_width() / 2, height + 5, label, ha=\"center\", va=\"bottom\"\n",
    "    )\n",
    "plt.savefig(\"a.jpg\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ious_objects_per_interaction', 'model', 'dataset', 'iou_threshold'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['ious_objects_per_interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: sbd_multi_insts\n",
      "iou_threshold: 0.85\n",
      "NOC: 6.02\n",
      "NCI: 4.056120028223635\n",
      "NFO: 1747\n",
      "failed_images_counts: 847\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset: {b['dataset']}\")\n",
    "print(f\"iou_threshold: {b['iou_threshold']}\")\n",
    "print(f\"NOC: {b['Avg_NOC']}\")\n",
    "print(f\"NCI: {b['avg_over_total_images']}\")\n",
    "print(f\"NFO: {b['num_failed_objects']}\")\n",
    "print(f\"failed_images_counts: {b['failed_images_counts']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2008_000003_0',\n",
       " '2008_000007_1',\n",
       " '2008_000009_2',\n",
       " '2008_000027_3',\n",
       " '2008_000043_4',\n",
       " '2008_000051_5',\n",
       " '2008_000059_6',\n",
       " '2008_000067_7',\n",
       " '2008_000073_8',\n",
       " '2008_000075_9']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = list(b[\"ious_objects_per_interaction\"].keys())\n",
    "ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor(0.8549), tensor(0.9158)],\n",
       " [tensor(0.8549), tensor(0.9158)],\n",
       " [tensor(0.8549), tensor(0.9158)],\n",
       " [tensor(0.8549), tensor(0.9158)],\n",
       " [tensor(0.8549), tensor(0.9158)]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"ious_objects_per_interaction\"]['2008_000067_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[True, True, True],\n",
       " [True, False, False],\n",
       " [False, False, True],\n",
       " [True, False, False],\n",
       " [False, False, True]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"clicked_objects_per_interaction\"]['2008_000067_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = [torch.tensor(0.8549), torch.tensor(0.9158)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times_point_smapled_false = 0\n",
    "while True:\n",
    "    if all(iou >= 0.85 for iou in ious) or num_times_point_smapled_false >= 2:\n",
    "        break\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(b[\"ious_objects_per_interaction\"].keys())\n",
    "total_iou_change = 0\n",
    "count = 0\n",
    "bins = 101\n",
    "neg_iou_change = [0]*bins\n",
    "pos_iou_change = [0]*bins\n",
    "\n",
    "neg_iou_change_bg = [0]*bins\n",
    "pos_iou_change_bg = [0]*bins\n",
    "bg_clicks = 0\n",
    "fg_clicks = 0\n",
    "for key in ids:\n",
    "    ious = np.asarray(b[\"ious_objects_per_interaction\"][key])\n",
    "    clicked = b[\"clicked_objects_per_interaction\"][key]\n",
    "    indices = [sum(i)>=1 for i in clicked]\n",
    "    clicked = np.asarray(clicked)[indices] \n",
    "    if len(indices)<len(ious):\n",
    "        indices.append(False)\n",
    "    \n",
    "    ious = ious[indices]\n",
    "    assert len(ious) == len(clicked)\n",
    "    \n",
    "    for i in range(1,len(clicked)):\n",
    "        if len(ious[i])==1:\n",
    "            continue\n",
    "        diff = (ious[i]-ious[i-1])*100\n",
    "        t = np.where(clicked[i]==True)[0][0]\n",
    "        if t== len(clicked[i])-1: #bg_click\n",
    "            bg_clicks+=1\n",
    "            for d in diff:\n",
    "                if d>0:\n",
    "                   pos_iou_change_bg[int(abs(d))]+=1\n",
    "                elif d<0:\n",
    "                   neg_iou_change_bg[int(abs(d))]+=1 \n",
    "        else:\n",
    "            # diff[t] = 0\n",
    "            fg_clicks+=1\n",
    "            for (i, d) in enumerate(diff):\n",
    "                if i!=t:\n",
    "                    if d>0:\n",
    "                        pos_iou_change[int(abs(d))]+=1\n",
    "                    elif d<0:\n",
    "                        neg_iou_change[int(abs(d))]+=1 \n",
    "\n",
    "        # # print(diff)\n",
    "        # total_iou_change += (sum(diff)*100/(len(diff)-1))\n",
    "        # count+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_clicks: 26738\n",
      "\n",
      "negative iou change(>=3%) : 0\n",
      "\n",
      "positive iou change(>=3%) : 0\n",
      "\n",
      "bg_clicks: 5659\n",
      "\n",
      "negative iou change bg(>=3%) : 0\n",
      "\n",
      "positive iou change bg(>=3%) : 0\n"
     ]
    }
   ],
   "source": [
    "print(f'fg_clicks: {fg_clicks}\\n')\n",
    "print(f'negative iou change(>=3%) : {sum(neg_iou_change[3:])}\\n')\n",
    "print(f'positive iou change(>=3%) : {sum(pos_iou_change[3:])}\\n')\n",
    "\n",
    "print(f'bg_clicks: {bg_clicks}\\n')\n",
    "print(f'negative iou change bg(>=3%) : {sum(neg_iou_change_bg[3:])}\\n')\n",
    "print(f'positive iou change bg(>=3%) : {sum(pos_iou_change_bg[3:])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(neg_iou_change)\n",
    "sum(neg_iou_change[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    print(\"x_g\",x)\n",
    "    x+=1\n",
    "    print(\"x_g_\",x)\n",
    "\n",
    "def f(x):\n",
    "\n",
    "    for i in range(5):\n",
    "        g(x)\n",
    "        x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_g 0\n",
      "x_g_ 1\n",
      "x_g 1\n",
      "x_g_ 2\n",
      "x_g 2\n",
      "x_g_ 3\n",
      "x_g 3\n",
      "x_g_ 4\n",
      "x_g 4\n",
      "x_g_ 5\n"
     ]
    }
   ],
   "source": [
    "f(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"weights/segformer/mit_b0_trans.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = [5,3,2,10]\n",
    "# max_from_last= [0]*len(price)\n",
    "# max_from_last[-1] = price[-1]\n",
    "_max = price[-1]\n",
    "profit = 0\n",
    "for i in range(len(price)-2,-1,-1):\n",
    "    _max= max(price[i], _max)\n",
    "    profit += (_max-price[i])\n",
    "profit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \" backbone.bottom_up.patch_embed1.proj.{bias, weight}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backbone.patch_embed1.proj.{bias, weight}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.lstrip(' ').replace(\".bottom_up\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "a = torch.ones((1024,1024)).to(dtype=torch.float)\n",
    "sys.getsizeof(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1024])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.projects.point_rend.point_features import (\n",
    "    get_uncertain_point_coords_with_randomness,\n",
    "    point_sample,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "a = torch.zeros((10,10))\n",
    "a[0:6,0:3] = 1\n",
    "a[4:7,4:7] = 1\n",
    "# a[0:5, 7:] =1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 2.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 2.],\n",
       "        [2., 0.],\n",
       "        [2., 1.],\n",
       "        [2., 2.],\n",
       "        [3., 0.],\n",
       "        [3., 1.],\n",
       "        [3., 2.],\n",
       "        [4., 0.],\n",
       "        [4., 1.],\n",
       "        [4., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 5.],\n",
       "        [4., 6.],\n",
       "        [5., 0.],\n",
       "        [5., 1.],\n",
       "        [5., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 5.],\n",
       "        [5., 6.],\n",
       "        [6., 4.],\n",
       "        [6., 5.],\n",
       "        [6., 6.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.stack(torch.where(a), dim=1).to(torch.float)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.stack(torch.where(a), dim=1).to(torch.float)\n",
    "p[:,0]/=float(1024)\n",
    "p[:,1]/=float(1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((1,5,3))\n",
    "x.mean(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rana/anaconda3/envs/m2f/lib/python3.8/site-packages/torch/nn/functional.py:3981: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y = point_sample(x, p.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 0], [1, 2, 0], [1, 2, 0]],\n",
       " [[4, 5, 0], [4, 5, 0], [4, 5, 0], [4, 5, 0]],\n",
       " [[6, 6, 1], [6, 6, 1], [6, 6, 1], [6, 6, 1], [6, 6, 1]]]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[[1,2,0]]*3, [[4,5,0]]*4, [[6,6,1]]*5]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 0],\n",
       " [1, 2, 0],\n",
       " [1, 2, 0],\n",
       " [4, 5, 0],\n",
       " [4, 5, 0],\n",
       " [4, 5, 0],\n",
       " [4, 5, 0],\n",
       " [6, 6, 1],\n",
       " [6, 6, 1],\n",
       " [6, 6, 1],\n",
       " [6, 6, 1],\n",
       " [6, 6, 1]]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = copy.deepcopy(a[0])\n",
    "for t in a[1:]:\n",
    "    y.extend(t)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(y)[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [4, 5],\n",
       "        [4, 5],\n",
       "        [4, 5],\n",
       "        [4, 5],\n",
       "        [6, 6],\n",
       "        [6, 6],\n",
       "        [6, 6],\n",
       "        [6, 6],\n",
       "        [6, 6]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 0], [1, 2, 0], [1, 2, 0]],\n",
       " [[4, 5, 0], [4, 5, 0], [4, 5, 0], [4, 5, 0]],\n",
       " [[6, 6, 1], [6, 6, 1], [6, 6, 1], [6, 6, 1], [6, 6, 1]]]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41, 2])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.zeros((len(torch.where(a)[0]),2))\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = F.interpolate(a.unsqueeze(0).unsqueeze(0), size=(128,128), mode=\"bilinear\", align_corners=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.,  7.],\n",
       "       [ 8.,  9., 10., 11.],\n",
       "       [12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "a = np.arange(16.).reshape((4, 4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  4.,  8., 12.],\n",
       "       [ 1.,  5.,  9., 13.],\n",
       "       [ 2.,  6., 10., 14.],\n",
       "       [ 3.,  7., 11., 15.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.5, 5. ])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndimage.map_coordinates(a, [[1], [0.5, 1]], order=1, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17552/3095995108.py:1: DeprecationWarning: Please use `map_coordinates` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import map_coordinates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "# from mpl_toolkits.basemap import interp\n",
    "import numpy\n",
    "\n",
    "in_data = numpy.array([[ 25.89125824,  25.88840675],[ 25.90930748,  25.90640068]], dtype=numpy.float32)\n",
    "\n",
    "in_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.8, 7.5])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_coordinates(a, [[1.7,1.5], [1,1.5]], order=1, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "num_labels, labels_im = cv2.connectedComponents(a.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 0, 0, 2, 2, 2],\n",
       "       [1, 1, 1, 0, 0, 0, 0, 2, 2, 2],\n",
       "       [1, 1, 1, 0, 0, 0, 0, 2, 2, 2],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 2, 2],\n",
       "       [0, 0, 0, 0, 3, 3, 0, 2, 2, 2],\n",
       "       [0, 0, 0, 0, 3, 3, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72,  9, 15,  4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(labels_im.flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_im == np.argmax(np.bincount(labels_im.flat)[1:]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask2former.data.dataset_mappers.eval.davis17_sbd_mq_evaluation_clicks_mapper import DAVIS17SBDEvalMQClicksDatasetMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask2former.data.datasets.register_coco_lvis import *\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "_root = os.getcwd()\n",
    "_root = os.path.join(_root, \"datasets/\")\n",
    "# _root = os.getenv(\"DETECTRON2_DATASETS\", \"datasets\")\n",
    "# print(_root)\n",
    "# register_all_coco_lvis_2017(_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DatasetCatalog.get(\"coco_lvis_2017_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.array([.76,.78,.80,.82,.85,.87,.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = ious>=.80\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now = 2023-02-08 10:36:37.880132\n",
      "date and time = 08_02_2023_10_36_37s\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    " \n",
    "print(\"now =\", now)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "print(\"date and time =\", dt_string +\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5,-1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "10 in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 1, 1],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [1, 1, 1, 0, 1],\n",
       "        [1, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((2,5,5))\n",
    "torch.argmax(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2960,  0.8196, -1.1057, -0.7486,  0.0711, -1.1511, -0.5144, -0.5536,\n",
      "         1.3287, -0.3221], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, dtype=torch.float32, requires_grad=True)\n",
    "print(x)\n",
    "y = x.repeat(5, 1)\n",
    "z = (y**2).sum()\n",
    "# z.backward()\n",
    "torch.autograd.backward([z], inputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD([x], lr=0.01)\n",
    "print(x)        # tensor([1., 2.], requires_grad=True)\n",
    "optim.step()\n",
    "print(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0929,  1.6599,  0.0832,  0.5620],\n",
      "        [-0.3079,  2.0893, -1.9158,  1.1371],\n",
      "        [-0.5511, -0.2064,  0.6665,  0.4380]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4, requires_grad=True)\n",
    "print(x)\n",
    "# def test_repeat(x):\n",
    "y = x.repeat(2, 2, 2, 2)\n",
    "out = y.sum()\n",
    "out.backward()\n",
    "\n",
    "# test_repeat(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0929,  1.6599,  0.0832,  0.5620],\n",
      "        [-0.3079,  2.0893, -1.9158,  1.1371],\n",
      "        [-0.5511, -0.2064,  0.6665,  0.4380]], requires_grad=True)\n",
      "tensor([[-0.1089,  1.6439,  0.0672,  0.5460],\n",
      "        [-0.3239,  2.0733, -1.9318,  1.1211],\n",
      "        [-0.5671, -0.2224,  0.6505,  0.4220]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.SGD([x], lr=0.001)\n",
    "print(x)        # tensor([1., 2.], requires_grad=True)\n",
    "optim.step()\n",
    "print(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ones((5,5),dtype=np.bool_)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.ones((5,5))\n",
    "y[2:4,1:4] =0\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.argwhere(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "indices = random.sample(range(s.shape[0]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 3, 16, 8, 10]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "@lru_cache(maxsize=None)\n",
    "def generate_probs(max_num_points, gamma):\n",
    "    probs = []\n",
    "    last_value = 1\n",
    "    for i in range(max_num_points):\n",
    "        probs.append(last_value)\n",
    "        last_value *= gamma\n",
    "\n",
    "    probs = np.array(probs)\n",
    "    probs /= probs.sum()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36060726, 0.25242508, 0.17669756, 0.12368829, 0.0865818 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_probs = generate_probs(5,gamma=0.7)\n",
    "pos_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,2,0], [2,3]]\n",
    "y = []\n",
    "y.append(x[1].append(0))\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "use_timestamp=False\n",
    "def gen_sineembed_for_position(pos_tensor):\n",
    "    # n_query, bs, _ = pos_tensor.size()\n",
    "    # sineembed_tensor = torch.zeros(n_query, bs, 256)\n",
    "    import math\n",
    "    scale = 2 * math.pi\n",
    "    dim_t = torch.arange(128, dtype=torch.float32, device=pos_tensor.device)\n",
    "    dim_t = 10000 ** (2 * torch.div(dim_t, 2, rounding_mode='floor') / 128)\n",
    "    x_embed = pos_tensor[:, :, 0] * scale\n",
    "    y_embed = pos_tensor[:, :, 1] * scale\n",
    "    if use_timestamp:\n",
    "        t_embed = pos_tensor[:, :, 2] * scale\n",
    "        y_embed += t_embed\n",
    "        x_embed += x_embed\n",
    "    pos_x = x_embed[:, :, None] / dim_t\n",
    "    pos_y = y_embed[:, :, None] / dim_t\n",
    "    pos_x[:, :, 0::2][torch.where(pos_x[:, :, 0::2] < 0)] = 0.0\n",
    "    pos_x[:, :, 1::2][torch.where(pos_x[:, :, 1::2] < 0)] = (0.5 * math.pi)\n",
    "    pos_y[:, :, 0::2][torch.where(pos_y[:, :, 0::2] < 0)] = 0.0\n",
    "    pos_y[:, :, 1::2][torch.where(pos_y[:, :, 1::2] < 0)] = (0.5 * math.pi)\n",
    "    pos_x = torch.stack((pos_x[:, :, 0::2].sin(), pos_x[:, :, 1::2].cos()), dim=3).flatten(2)\n",
    "    pos_y = torch.stack((pos_y[:, :, 0::2].sin(), pos_y[:, :, 1::2].cos()), dim=3).flatten(2)\n",
    "    pos = torch.cat((pos_y, pos_x), dim=2)\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tensor_coords(batched_fg_coords_list, batched_bg_coords_list, num_queries, height, width, device):\n",
    "\n",
    "    #batched_fg_coords_list: batch x (list of list of fg coords) [y,x,t]\n",
    "\n",
    "    # return\n",
    "    # points: Bs x num_queries x 3 \n",
    "    B = len(batched_fg_coords_list)\n",
    "    \n",
    "    pos_tensor = []\n",
    "    \n",
    "    for i, fg_coords_per_image in enumerate(batched_fg_coords_list):\n",
    "        coords_per_image  = []\n",
    "        for fg_coords_per_mask in fg_coords_per_image:\n",
    "            for coords in fg_coords_per_mask:\n",
    "                coords_per_image.append([coords[0]/width, coords[1]/height, coords[2]])\n",
    "        if batched_bg_coords_list[i] is not None:\n",
    "            for coords in batched_bg_coords_list[i]:\n",
    "                coords_per_image.append([coords[0]/width, coords[1]/height, coords[2]])\n",
    "        coords_per_image.extend([[-1.0,-1.0,-1.0]] * (num_queries-len(coords_per_image)))\n",
    "        pos_tensor.append(torch.tensor(coords_per_image,device=device))\n",
    "    # pos_tensor = torch.tensor(pos_tensor,device=device)\n",
    "    pos_tensor = torch.stack(pos_tensor)\n",
    "    return pos_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [y,x,t]\n",
    "batched_fg_coords_list = [[[[2,3,0],[3,5,0]], [[5,6,0], [6,7,0]]], [[[2,3,0],[3,5,0]], [[5,6,0], [6,7,0]]]]\n",
    "batched_bg_coords_list = [[[6,7,0]],None]\n",
    "num_queries = 11\n",
    "height = width = 50\n",
    "device = 'cpu'\n",
    "\n",
    "pos_tensor = get_pos_tensor_coords(batched_fg_coords_list, batched_bg_coords_list, num_queries, height, width, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 3])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0400,  0.0600,  0.0000],\n",
       "         [ 0.0600,  0.1000,  0.0000],\n",
       "         [ 0.1000,  0.1200,  0.0000],\n",
       "         [ 0.1200,  0.1400,  0.0000],\n",
       "         [ 0.1200,  0.1400,  0.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000]],\n",
       "\n",
       "        [[ 0.0400,  0.0600,  0.0000],\n",
       "         [ 0.0600,  0.1000,  0.0000],\n",
       "         [ 0.1000,  0.1200,  0.0000],\n",
       "         [ 0.1200,  0.1400,  0.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 2 * math.pi\n",
    "dim_t = torch.arange(128, dtype=torch.float32, device=pos_tensor.device)\n",
    "dim_t = 10000 ** (2 * torch.div(dim_t, 2, rounding_mode='floor') / 128)\n",
    "x_embed = pos_tensor[:, :, 0] * scale\n",
    "y_embed = pos_tensor[:, :, 1] * scale\n",
    "# if use_timestamp:\n",
    "#     t_embed = pos_tensor[:, :, 2] * scale\n",
    "#     y_embed += t_embed\n",
    "#     x_embed += x_embed\n",
    "pos_x = x_embed[:, :, None] / dim_t\n",
    "pos_y = y_embed[:, :, None] / dim_t\n",
    "pos_x = torch.stack((pos_x[:, :, 0::2].sin(), pos_x[:, :, 1::2].cos()), dim=3).flatten(2)\n",
    "pos_y = torch.stack((pos_y[:, :, 0::2].sin(), pos_y[:, :, 1::2].cos()), dim=3).flatten(2)\n",
    "pos = torch.cat((pos_y, pos_x), dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 128])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_x = x_embed[:, :, None] / dim_t\n",
    "pos_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_x[:, :, 0::2][torch.where(pos_x[:, :, 0::2] < 0)] = 0.0\n",
    "pos_x[:, :, 1::2][torch.where(pos_x[:, :, 1::2] < 0)] = math.pi * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9.6858e-01,  9.7641e-01,  9.8229e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 9.2978e-01,  9.4718e-01,  9.6030e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 8.0902e-01,  8.5559e-01,  8.9104e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         ...,\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08],\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08],\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08]],\n",
       "\n",
       "        [[ 9.6858e-01,  9.7641e-01,  9.8229e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 9.2978e-01,  9.4718e-01,  9.6030e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 8.0902e-01,  8.5559e-01,  8.9104e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         ...,\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08],\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08],\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_x[:, :, 1::2].cos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t = gen_sineembed_for_position(pos_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.6812e-01,  9.2978e-01,  3.2069e-01,  ...,  1.0000e+00,\n",
       "           2.9023e-05,  1.0000e+00],\n",
       "         [ 5.8779e-01,  8.0902e-01,  5.1765e-01,  ...,  1.0000e+00,\n",
       "           4.3534e-05,  1.0000e+00],\n",
       "         [ 6.8455e-01,  7.2897e-01,  6.0751e-01,  ...,  1.0000e+00,\n",
       "           7.2557e-05,  1.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08],\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08],\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08]],\n",
       "\n",
       "        [[ 3.6812e-01,  9.2978e-01,  3.2069e-01,  ...,  1.0000e+00,\n",
       "           2.9023e-05,  1.0000e+00],\n",
       "         [ 5.8779e-01,  8.0902e-01,  5.1765e-01,  ...,  1.0000e+00,\n",
       "           4.3534e-05,  1.0000e+00],\n",
       "         [ 6.8455e-01,  7.2897e-01,  6.0751e-01,  ...,  1.0000e+00,\n",
       "           7.2557e-05,  1.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08],\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08],\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.123233995736766e-17"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.cos(math.pi/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[0,0,0]]*5\n",
    "x = torch.tensor(x)\n",
    "torch.stack((x,x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "def visualization(batched_inputs, prev_output, batched_fg_coords_list,batched_bg_coords_list,\n",
    "                  alpha_blend=0.6, num_iter = 0):\n",
    "    image = np.asarray(batched_inputs[0]['image'].permute(1,2,0))\n",
    "\n",
    "    visualizer = Visualizer(image, metadata=None)\n",
    "    if prev_output is not None:\n",
    "        pred_masks = F.resize(prev_output.pred_masks.to(dtype=torch.uint8), image.shape[:2])\n",
    "    else:\n",
    "        pred_masks = batched_inputs[0]['instances'].gt_masks\n",
    "    c = []\n",
    "    for i in range(pred_masks.shape[0]):\n",
    "        # c.append(color_map[2*(i)+2]/255.0)\n",
    "        c.append(color_map[i]/255.0)\n",
    "    # pred_masks = np.asarray(pred_masks).astype(np.bool_)\n",
    "    vis = visualizer.overlay_instances(masks = pred_masks, assigned_colors=c, alpha=alpha_blend)\n",
    "    # [Optional] prepare labels\n",
    "\n",
    "    image = vis.get_image()\n",
    "    # # Laminate your image!\n",
    "    total_colors = len(color_map)-1\n",
    "    \n",
    "    h,w = image.shape[:2]\n",
    "    for fg_coords_per_mask in batched_fg_coords_list[0]:\n",
    "        for i, coords in enumerate(fg_coords_per_mask):\n",
    "            color = np.array(color_map[total_colors-5*i-4], dtype=np.uint8)\n",
    "            if i==0:\n",
    "                image = cv2.circle(image, (int(coords[1]), int(coords[0])), 8, color, -1)\n",
    "            else:\n",
    "                image = cv2.circle(image, (int(coords[1]), int(coords[0])), 3, color, -1)\n",
    "    \n",
    "    if batched_bg_coords_list[0]:\n",
    "         for i, coords in enumerate(batched_bg_coords_list[0]):\n",
    "            color = np.array([255,0,0], dtype=np.uint8)\n",
    "            image = cv2.circle(image, (int(coords[1]), int(coords[0])), 3, color, -1)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    # image = cv2.resize(image, (inputs[\"width\"],inputs[\"height\"]))\n",
    "    save_dir = os.path.join(\"./train_vis/\", str(batched_inputs[0]['image_id']))\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(save_dir, f\"iter_{num_iter}.jpg\"), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True],\n",
       "        [True, True, True, True, True],\n",
       "        [True, True, True, True, True],\n",
       "        [True, True, True, True, True],\n",
       "        [True, True, True, True, True]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((5,5),dtype=torch.bool)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to(torch.uint8)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"datasets/lvis/coco_lvis_combined_panoptic_1half.pickle\", 'rb') as f:\n",
    "    dataset_dicts = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/lvis/coco_lvis_combined_panoptic_2half.pickle\", 'rb') as f:\n",
    "    dataset_dicts1 = pickle.load(f)\n",
    "\n",
    "dataset_dicts.extend(dataset_dicts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/lvis/coco_lvis_combined_panoptic.pickle\", 'wb') as handle:\n",
    "    pickle.dump(dataset_dicts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99354"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"output/GrabCut_points_dict_16_02_2023_14_38_32_.pickle\", 'rb') as f:\n",
    "    pt_sampled_dict = pickle.load(f)\n",
    "\n",
    "with open(\"output/GrabCut_points_dict_16_02_2023_14_39_07_.pickle\", 'rb') as f:\n",
    "    pt_sampled_dict1 = pickle.load(f)\n",
    "\n",
    "# with open(\"output/features_dicts1_GrabCut.pickle\", 'rb') as f:\n",
    "#     features_dict1 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pt_sampled_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sampled_dict1.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.66"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_p = 0\n",
    "for k,v in pt_sampled_dict.items():\n",
    "    sum_p+= len(v)\n",
    "sum_p/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.66"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_p = 0\n",
    "for k,v in pt_sampled_dict1.items():\n",
    "    sum_p+= len(v)\n",
    "sum_p/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in pt_sampled_dict.keys():\n",
    "    for k1 in pt_sampled_dict1.keys():\n",
    "        if k==k1 and pt_sampled_dict[k]!=pt_sampled_dict1[k1]:\n",
    "            print(k)\n",
    "            print(pt_sampled_dict1[k1])\n",
    "            print(pt_sampled_dict[k]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/GrabCut_features_dict_16_02_2023_14_51_57_.pickle\", 'rb') as f:\n",
    "    features_dict = pickle.load(f)\n",
    "\n",
    "with open(\"output/GrabCut_features_dict_16_02_2023_14_53_59_.pickle\", 'rb') as f:\n",
    "    features_dict1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for k in features_dict.keys():\n",
    "    for k1 in features_dict1.keys():\n",
    "        if (k==k1):\n",
    "            print(torch.all(features_dict[k]['first_mask_before_resize']==features_dict1[k1]['first_mask_before_resize']))\n",
    "            # print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bool', 'grave', '326038', 'banana1', 'book', 'memorial', 'banana2', 'bush', 'doll', 'person6', '86016', 'person3', 'person2', '227092', '209070', '21077', 'scissors', 'teddy', '65019', '271008', 'flower', 'person5', '189080', 'person8', 'sheep', '388016', '69020', 'person7', 'banana3', '37073', 'person1', '124080', '153077', 'music', '106024', 'cross', 'fullmoon', 'tennis', 'elefant', 'stone1', 'llama', '208001', 'stone2', '304074', '153093', 'ceramic', '24077', 'person4', '376043', '181079'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sem_seg_head.predictor.query_embed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/rana/claix_work/DynaMITe/visual_results.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rana/claix_work/DynaMITe/visual_results.ipynb#ch0000023?line=0'>1</a>\u001b[0m features_dict[\u001b[39m'\u001b[39;49m\u001b[39mbush\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39msem_seg_head.predictor.query_embed\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sem_seg_head.predictor.query_embed'"
     ]
    }
   ],
   "source": [
    "features_dict['bush']['sem_seg_head.predictor.query_embed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.all(features_dict['bush']['sem_seg_head.predictor.query_embed']==features_dict['bool']['sem_seg_head.predictor.query_embed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "query_embed = nn.Parameter(torch.zeros(256), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-6.4749e-01, -9.4622e-01,  9.9136e-01, -2.8006e-01, -1.1464e+00,\n",
       "         2.3682e+00, -1.9174e+00,  4.9042e-01, -1.7973e+00, -8.8009e-02,\n",
       "         2.9536e-01, -1.1632e+00,  7.8763e-01,  9.7209e-02, -4.6051e-01,\n",
       "        -1.3793e+00, -1.3135e+00, -8.6194e-01, -2.2053e+00,  1.6569e+00,\n",
       "         5.3033e-01,  2.0219e+00,  1.4238e+00, -2.7438e-01, -2.9316e-01,\n",
       "         5.7328e-01, -4.8293e-01,  4.7248e-01, -4.7783e-01, -9.5518e-01,\n",
       "         3.4036e-02,  6.3088e-01, -1.7732e-03,  3.7992e-01, -1.1083e+00,\n",
       "        -2.0908e+00, -5.4316e-01,  3.8153e-01, -2.4660e+00, -7.5894e-01,\n",
       "         1.7062e-01, -6.1475e-01,  1.0703e+00,  3.5325e-01,  2.6061e-01,\n",
       "        -3.5651e-01,  4.8227e-01,  7.7621e-01,  9.3742e-01, -1.3908e+00,\n",
       "         1.1140e+00,  7.4399e-01, -4.4368e-01,  1.0445e+00, -1.4251e+00,\n",
       "         1.7776e-01, -5.6139e-01,  1.3463e+00,  1.2909e+00,  1.0224e+00,\n",
       "         1.0126e-02, -3.6532e-01,  3.0054e-01, -1.0427e+00, -2.5550e+00,\n",
       "         1.3792e+00, -3.0180e+00, -9.9011e-01, -5.7959e-01,  1.0527e+00,\n",
       "         3.8878e-02, -1.0803e-01, -5.9967e-01,  4.4868e-02,  1.1858e+00,\n",
       "         2.9113e-01, -1.0857e+00, -2.0949e+00, -7.9009e-01,  2.5124e-01,\n",
       "         7.6897e-01, -9.9976e-01,  1.0557e+00,  3.8981e-01,  2.1673e-01,\n",
       "         9.7767e-01,  6.8974e-02,  2.2309e+00, -1.5021e+00,  7.7536e-01,\n",
       "         3.9605e-01, -4.7302e-01, -3.6076e-02,  4.3843e-01,  1.4999e+00,\n",
       "         1.2663e+00,  1.2796e+00, -1.2030e-01, -3.6931e-01,  5.8684e-01,\n",
       "         6.7701e-01, -5.1989e-01,  5.6786e-01, -1.1889e+00, -1.0553e+00,\n",
       "         3.7751e-02, -1.9447e+00, -4.7964e-02, -2.0589e+00,  2.7592e-03,\n",
       "         5.5593e-01,  1.0265e+00,  1.3137e+00, -1.1642e+00,  1.1399e+00,\n",
       "        -1.5409e-02, -7.5154e-01,  1.5284e-02,  2.7918e+00,  4.6044e-01,\n",
       "         2.9290e-01, -1.2645e+00,  6.3408e-01, -4.7565e-02,  1.4135e+00,\n",
       "         2.4492e+00, -2.5464e+00,  6.6724e-01,  6.1609e-01, -4.9666e-01,\n",
       "        -1.7132e+00, -2.5013e-01, -1.6909e+00, -1.3032e+00,  9.4466e-01,\n",
       "        -1.2466e+00, -8.8447e-01,  7.7599e-01,  5.4487e-02, -5.9656e-01,\n",
       "         2.1227e+00, -2.1781e+00,  6.3330e-01,  7.1862e-01, -1.4283e-01,\n",
       "        -3.6911e-01,  8.7073e-01, -4.0721e-01, -1.7535e+00,  4.6955e-01,\n",
       "         1.0997e-01,  7.2473e-01,  5.2788e-01, -1.3986e+00, -8.5391e-03,\n",
       "        -6.9298e-01, -4.5402e-01, -1.2027e+00,  4.8955e-01,  7.2693e-01,\n",
       "        -5.8987e-01,  2.2842e+00, -8.5941e-01, -1.8679e-01, -6.2337e-01,\n",
       "        -1.3894e+00, -5.0438e-01, -1.1180e+00, -3.8329e-01, -1.1887e+00,\n",
       "         1.4751e+00, -3.1120e-01, -1.0112e-01,  2.0425e+00, -7.3740e-01,\n",
       "         6.8982e-02, -7.7067e-01, -6.3257e-01,  2.4467e+00, -6.6894e-01,\n",
       "         2.7258e-01,  2.7284e-01,  1.0076e+00,  1.4912e-01,  8.3674e-01,\n",
       "        -7.1490e-01,  9.0045e-01,  5.7044e-01,  3.9995e-01, -5.0511e-01,\n",
       "        -7.8044e-01,  1.2110e-01,  1.0546e+00,  7.1148e-01, -3.9047e-01,\n",
       "        -3.1581e-01,  1.2579e+00,  7.5340e-01, -1.8266e+00, -1.5195e+00,\n",
       "        -1.1493e+00, -6.0186e-01,  4.5245e-01, -6.4823e-01, -8.3427e-01,\n",
       "        -1.2665e+00,  5.3608e-01,  1.7869e-01,  2.9538e-01,  1.9509e+00,\n",
       "         2.0131e-01, -1.1664e+00, -4.7805e-01, -1.2348e-01,  3.7494e-01,\n",
       "        -1.5411e-01,  1.9286e-01,  5.3970e-01,  1.0906e+00,  1.4679e+00,\n",
       "        -1.1615e+00,  1.3955e-01,  9.5172e-01, -1.7147e-01,  1.2186e+00,\n",
       "         3.3679e+00,  5.3101e-01,  2.0939e-01,  3.9060e-01, -1.9350e+00,\n",
       "         9.4561e-01, -8.3802e-01,  1.4816e+00,  4.4207e-01,  9.6252e-02,\n",
       "        -2.0045e+00, -5.4523e-01,  3.9278e-01, -1.8980e-01, -1.1358e+00,\n",
       "         1.4776e-01, -1.1891e+00, -5.2493e-01, -1.3490e+00,  1.8121e+00,\n",
       "         4.8696e-01,  1.7120e+00, -2.2816e+00,  1.9390e+00, -4.1819e-01,\n",
       "        -4.1695e-01,  3.4997e-02,  1.3171e+00, -4.9327e-01,  6.0657e-01,\n",
       "        -5.1419e-01], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.normal_(query_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = features_dict1['bool']['sem_seg_head.predictor.query_embed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.4440e-01, -3.9581e-01,  1.4902e+00,  5.7210e-01,  1.4115e+00,\n",
       "         1.1782e+00,  1.7427e-01,  7.7683e-01,  1.3897e+00,  1.3905e-01,\n",
       "         1.0957e-01, -1.4464e-01, -1.5933e+00,  1.4587e+00, -1.1386e+00,\n",
       "         4.5302e-01,  5.3029e-01,  1.9542e-01,  1.1081e+00, -7.5916e-01,\n",
       "         9.3200e-01, -4.5756e-01, -1.4237e+00,  4.0218e-01, -9.7000e-01,\n",
       "         8.2498e-01,  4.8588e-01, -7.4774e-01, -5.4895e-01,  1.4943e+00,\n",
       "         1.6388e+00, -1.4993e+00,  9.8590e-01, -3.4655e-01, -5.1271e-01,\n",
       "         2.0943e-01, -1.9139e+00, -8.3778e-02,  6.0873e-01, -1.1971e+00,\n",
       "        -1.0011e+00,  7.8411e-01,  1.2188e+00, -6.9305e-01, -1.8274e-02,\n",
       "         7.3414e-01,  6.8789e-03,  2.3990e-02,  5.2682e-01,  7.5319e-01,\n",
       "         4.7599e-02, -4.8743e-01,  1.9112e-01, -7.5404e-01,  1.4807e+00,\n",
       "        -2.0128e+00, -1.5868e+00,  1.2303e+00,  1.5168e-01, -1.4823e+00,\n",
       "        -3.3540e-01, -5.1541e-01,  1.8677e-01, -1.3345e+00,  1.0651e+00,\n",
       "         1.5484e-01,  2.3708e-01,  9.4255e-01, -8.8311e-01,  1.4929e+00,\n",
       "         1.4355e+00, -1.2682e+00,  1.0203e+00,  1.3870e-02,  1.4823e+00,\n",
       "         7.7098e-01,  9.7230e-01,  3.8899e-01, -5.8867e-02,  2.5647e-01,\n",
       "        -4.6752e-01,  2.6700e-01,  9.0024e-01, -7.0883e-01,  3.8818e-01,\n",
       "         1.2056e+00,  1.5854e-01, -9.8617e-01,  1.7885e+00, -1.7943e+00,\n",
       "         1.2156e-01, -3.6817e-01,  2.4244e-01, -7.7437e-01,  1.3706e+00,\n",
       "        -1.4406e+00, -9.5404e-01, -2.5857e+00,  6.5134e-02, -1.3723e+00,\n",
       "        -1.3688e+00,  1.4804e+00,  2.0009e+00, -2.3979e-04,  8.2576e-01,\n",
       "         8.5650e-03,  1.3519e+00, -8.6264e-02, -7.5535e-01, -7.5569e-01,\n",
       "        -6.3938e-01,  2.5007e+00,  5.1795e-01,  3.5287e-01,  4.9800e-01,\n",
       "         5.9263e-01,  1.1400e+00, -4.4381e-01, -1.5946e+00,  6.9854e-02,\n",
       "        -4.1151e-01, -1.6355e+00, -1.3183e+00, -3.0206e+00, -1.1612e+00,\n",
       "         1.1963e+00, -7.8520e-01,  2.3013e+00, -9.0768e-01, -3.0319e-01,\n",
       "         4.7949e-01,  1.4885e+00, -3.2447e-01, -2.9942e-01, -6.9012e-02,\n",
       "        -1.1887e+00,  2.2945e+00,  2.1841e-01, -1.4820e+00, -7.2050e-01,\n",
       "        -2.5777e+00, -6.6547e-01, -8.5194e-02, -9.4252e-01, -3.3302e-01,\n",
       "         2.3797e+00, -1.2646e+00, -1.1028e+00, -1.3858e+00, -1.1228e-01,\n",
       "        -9.0071e-01,  9.3493e-01, -7.5831e-01,  4.6151e-01,  1.1208e+00,\n",
       "         6.7885e-01,  2.1138e-01,  1.3974e+00, -1.0667e+00,  1.0704e+00,\n",
       "         3.1742e-01, -7.2320e-02,  3.2800e-01,  8.7610e-01, -3.7569e-01,\n",
       "        -1.4012e+00, -1.0194e+00,  2.3109e-01,  3.9590e-01, -7.8975e-01,\n",
       "         1.9139e+00, -1.3154e-01, -5.8103e-01,  5.6205e-02, -3.2848e-01,\n",
       "        -9.1075e-01,  1.3370e+00, -6.4396e-01,  8.6809e-01, -4.7063e-01,\n",
       "        -9.4010e-01, -1.4561e-01,  9.8667e-02,  1.0744e+00,  9.5792e-01,\n",
       "         4.3059e-01,  1.8471e+00, -1.2264e+00, -2.4309e-01,  6.9404e-01,\n",
       "         3.6977e-01, -1.7577e+00, -3.3670e-02,  1.4564e-01,  1.0042e+00,\n",
       "         1.9548e-01,  7.1057e-01, -8.9447e-01, -1.0284e-01, -1.2298e+00,\n",
       "        -1.1382e-01,  1.2467e+00, -6.5633e-01,  2.1445e-01,  5.3322e-01,\n",
       "        -5.8614e-01,  1.0801e+00, -6.1095e-02, -5.6686e-01, -1.7162e+00,\n",
       "         1.6804e-01, -1.4027e-01, -4.0935e-02, -9.0276e-01,  1.1298e+00,\n",
       "         2.4249e-01, -4.4163e-03,  5.5411e-01,  4.3701e-01, -1.1128e+00,\n",
       "        -2.8587e-01,  2.6027e-01, -1.6711e+00,  3.0665e-01,  1.1804e+00,\n",
       "         3.6873e-01,  1.9183e+00,  1.3402e+00, -3.7538e-01,  1.3554e+00,\n",
       "        -1.1683e+00,  7.8752e-01,  1.3382e-01, -8.4096e-02, -1.5031e+00,\n",
       "         1.2738e-01,  1.5781e-01,  9.2643e-01,  2.8784e-01, -1.0348e+00,\n",
       "         4.0055e-01, -5.1450e-01,  1.2278e+00,  2.3003e-01, -5.0176e-01,\n",
       "        -7.2641e-01, -1.1508e+00,  2.8688e-01, -8.6050e-01, -1.0303e-01,\n",
       "         7.5071e-02, -4.6012e-01, -1.3635e-01, -8.2944e-01, -9.8331e-01,\n",
       "        -3.6355e+00], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rana/claix_work/DynaMITe/visual_results.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvision-veltins/home/rana/claix_work/DynaMITe/visual_results.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m nn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mnormal_(q)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "nn.init.normal_(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.where(features_dict['bush']['first_mask_before_resize']!=features_dict1['bush']['first_mask_before_resize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rana/anaconda3/envs/m2f/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GaussianModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GaussianModel, self).__init__()\n",
    "\n",
    "        self.register_parameter('mean', nn.Parameter(torch.zeros(1),True))\n",
    "        \n",
    "        # self.pdf = torch.distributions.Normal(self.mean,\n",
    "                                            #   torch.tensor([1.0]))\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.normal_(self.mean)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pdf = torch.distributions.Normal(self.mean,\n",
    "                                              torch.tensor([1.0]))\n",
    "        return -pdf.log_prob(x)\n",
    "\n",
    "model = GaussianModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :  0.7252676486968994  - Negative Loglikelihood :  3.51652193069458\n",
      "mean :  0.7298170924186707  - Negative Loglikelihood :  3.5061421394348145\n",
      "mean :  0.734357476234436  - Negative Loglikelihood :  3.4958038330078125\n",
      "mean :  0.7388887405395508  - Negative Loglikelihood :  3.485507011413574\n",
      "mean :  0.7434109449386597  - Negative Loglikelihood :  3.475250720977783\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.002)\n",
    "for _ in range(5):\n",
    "  optimizer.zero_grad()\n",
    "  nll = model(torch.tensor([3.0], requires_grad=True))\n",
    "  nll.backward()\n",
    "  optimizer.step()\n",
    "  print('mean : ', model.mean.item(),\n",
    "                 ' - Negative Loglikelihood : ', nll.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'gauss.pth')\n",
    "torch.save(model.state_dict(), 'gauss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('gauss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['mean'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('mean', tensor([-0.0619]))])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('gauss.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('mean', tensor([0.7434]))])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from iterative_train_net import Trainer\n",
    "from mask2former import COCOMultiInstStuffMultiQueriesClicksDatasetMapper, add_maskformer2_config, COCOLVISMultiInstMQClicksDatasetMapper\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "from mask2former.utils.equal_num_instances_batch import build_detection_train_loader_equal\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "cfg = get_cfg()\n",
    "add_deeplab_config(cfg)\n",
    "add_maskformer2_config(cfg)\n",
    "# cfg.merge_from_file(\"mycfg.yaml\")\n",
    "# /home/rana/claix_work/DynaMITe/configs/coco_lvis/resnet/multi_queries_stufff_clicks_R50_bs32_ep50.yaml\n",
    "cfg.merge_from_file(\"output/mq_coco_swin_tiny_bs32_ep50/config.yaml\")\n",
    "\n",
    "model_path = \"output/single_inst_mq_per_obj_coco_swin_tiny_bs32_ep50/model_final.pth\"\n",
    "model = Trainer.build_model(cfg)\n",
    "\n",
    "# DetectionCheckpointer(model, save_dir=\"output/\").resume_or_load(\n",
    "#             model_path, resume=False\n",
    "#         )\n",
    "\n",
    "# model = model['model']\n",
    "# model.eval()\n",
    "model.load_state_dict(torch.load(cfg.MODEL.WEIGHTS)[\"model\"])\n",
    "# model = torch.load(cfg.MODEL.WEIGHTS)['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0491,  0.1466, -0.5566, -0.8277,  0.0337, -0.4834,  0.6618, -0.2049,\n",
       "        -0.0588,  0.2471,  0.4428,  0.5744,  0.2546,  0.5237,  1.0650,  1.2559,\n",
       "        -0.5063, -0.7054, -0.5026,  0.3244,  0.3879,  0.5603, -0.3371, -0.9213,\n",
       "         1.0746,  0.7930, -0.1447, -0.2350, -0.5455, -0.3754, -0.5877,  0.8867,\n",
       "        -0.2563,  0.5760,  0.0996, -0.7674,  0.7588,  0.2343, -0.5574, -0.9866,\n",
       "        -0.7541,  0.3442,  0.3891, -0.1894,  0.2952,  0.0716, -0.2876, -0.3046,\n",
       "         0.4605, -0.6726,  0.1304, -0.2660,  0.0327,  0.4801,  0.3427,  1.3805,\n",
       "         0.5639, -0.4341,  0.7380,  0.4367, -0.4625, -0.5704, -0.1120, -0.1216,\n",
       "         0.0056, -0.2250, -0.6623, -0.0103, -0.4091,  0.3360, -0.1978,  0.8804,\n",
       "         0.1445, -0.0618,  0.5945,  0.0445, -0.9692, -0.4574, -1.4822, -0.0275,\n",
       "        -1.5009, -0.3918, -0.6106,  1.2462,  0.3436,  0.2367, -0.8787, -0.2510,\n",
       "         0.2018, -0.1357,  0.1206,  1.1781, -0.1904, -0.2060, -0.2927, -0.1783,\n",
       "        -0.8082,  0.3542, -0.7496, -0.5594, -0.5036,  0.2973,  0.9794, -0.7616,\n",
       "        -0.9670, -0.3619,  0.1316, -0.1408,  0.0124, -0.3508,  0.3076, -0.7279,\n",
       "        -0.5960, -0.0512, -0.2206,  0.0231,  0.5908,  0.0771,  0.5641,  0.0025,\n",
       "        -0.1892, -0.1062, -1.5548,  0.0180,  1.0107, -0.5504,  0.0212, -0.3012,\n",
       "        -0.2961, -0.6698,  0.1198, -0.3376,  0.0928, -0.1746, -0.3822,  0.4136,\n",
       "        -0.5350, -0.5528,  1.3145, -0.1414, -0.2508, -0.8146, -1.7619,  0.0855,\n",
       "        -1.7505, -0.5249,  0.0593,  0.2707,  0.7366, -0.3458,  0.4238, -1.0587,\n",
       "         0.8384,  0.1506,  0.1359, -0.2754, -0.3174,  0.1458,  0.9129, -0.0356,\n",
       "        -0.3392, -0.5592, -0.1120,  1.1771,  0.1355, -0.4128, -0.2637,  0.0935,\n",
       "        -0.2876, -0.1052, -0.9104, -0.0018,  0.2318, -0.2834,  0.7288,  0.1785,\n",
       "        -0.1834,  0.7977,  0.5601, -0.7843,  0.0619, -1.1479,  0.2386, -0.3135,\n",
       "        -0.2815, -0.4749,  0.4074, -0.0889, -0.5069, -0.3932, -0.3774,  0.9057,\n",
       "         0.3874, -1.1192,  0.2161, -0.1715, -1.2351,  0.3351,  0.3138,  0.6554,\n",
       "        -0.0724, -0.8190, -0.7770, -0.3699, -0.3917,  0.3799,  0.1707, -0.4845,\n",
       "         0.0495, -0.8615, -0.0571, -1.3715, -1.0206, -0.5041,  0.1699,  1.4668,\n",
       "        -0.9389, -0.1412, -0.3052,  0.5333, -0.4710, -0.6022,  0.3173,  1.1631,\n",
       "        -0.8497,  0.8452, -0.7277, -0.0048,  0.4470,  0.4975, -0.0906, -0.5240,\n",
       "         0.3093,  0.1874,  1.2814,  0.3164,  0.0683,  0.5711, -0.0165, -0.1119,\n",
       "         1.0660, -0.6707,  0.2927,  0.2574,  1.1957,  1.0638, -0.0379,  0.3329,\n",
       "        -0.0135, -0.3643, -0.7451, -0.1613,  1.0831, -0.3235,  0.1457, -0.2359],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['model'][\"sem_seg_head.predictor.query_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_objs = 0\n",
    "num_objs = []\n",
    "for d in dataset_dicts:\n",
    "    max_objs = max(max_objs, len(d['annotations']))\n",
    "    num_objs.append(len(d['annotations']))\n",
    "# len(dataset_dicts[0]['annotations'])\n",
    "max_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/lvis/coco_lvis_combined_panoptic.pickle\", 'wb') as handle:\n",
    "    pickle.dump(dataset_dicts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99354"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"datasets/lvis/coco_lvis_combined_panoptic.pickle\", 'rb') as f:\n",
    "    dataset_dicts = pickle.load(f)\n",
    "\n",
    "len(dataset_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pickle file:datasets/lvis/coco_lvis_combined_panoptic.pickle\n"
     ]
    }
   ],
   "source": [
    "from mask2former import COCOMultiInstStuffMultiQueriesClicksDatasetMapper, add_maskformer2_config, COCOLVISMultiInstMQClicksDatasetMapper\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "from mask2former.utils.equal_num_instances_batch import build_detection_train_loader_equal\n",
    "cfg = get_cfg()\n",
    "add_deeplab_config(cfg)\n",
    "add_maskformer2_config(cfg)\n",
    "# cfg.merge_from_file(\"mycfg.yaml\")\n",
    "# /home/rana/claix_work/DynaMITe/configs/coco_lvis/resnet/multi_queries_stufff_clicks_R50_bs32_ep50.yaml\n",
    "cfg.merge_from_file(\"configs/coco_lvis/resnet/multi_queries_stufff_clicks_R50_bs32_ep50.yaml\")\n",
    "\n",
    "mapper = COCOLVISMultiInstMQClicksDatasetMapper(cfg,True)\n",
    "data_loader =  build_detection_train_loader_equal(cfg, mapper=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask2former.utils.vis import get_visualization\n",
    "x = batch[14]\n",
    "get_visualization(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([True,True,False])\n",
    "x =torch.stack([x,x])\n",
    "print(x.shape)\n",
    "y = torch.tensor([0.4,-0.5,1])\n",
    "torch.stack([y],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "x = nn.Parameter(torch.zeros(2,5), True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9249,  0.0939, -0.0056, -0.2211,  0.0067],\n",
       "        [-0.8090,  0.0233, -0.8762, -0.4058,  0.8678]], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.xavier_uniform_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9249,  0.0939, -0.0056, -0.2211,  0.0067],\n",
       "        [-0.8090,  0.0233, -0.8762, -0.4058,  0.8678]], requires_grad=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros((5,5))\n",
    "mask[0:4,1:5]=1\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1.]\n",
      " [0. 1. 2. 2. 1.]\n",
      " [0. 1. 2. 2. 1.]\n",
      " [0. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "mask = np.pad(mask, ((1, 1), (1, 1)), 'constant')\n",
    "dt = cv2.distanceTransform(mask.astype(np.uint8), cv2.DIST_L2, 0)[1:-1, 1:-1]\n",
    "print(dt)\n",
    "max_dist = np.max(dt)\n",
    "coords_y, coords_x = np.where(dt == max_dist)\n",
    "print(coords_y[0], coords_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1243456)\n",
    "indices = random.sample(range(candidates.shape[0]),1)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(x['padding_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]['instances'].gt_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = np.asarray(x[\"image\"].permute(1,2,0))\n",
    "cv2.imshow(\"img_window\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.asarray(x[\"instances\"].gt_masks[0])\n",
    "cv2.imshow(\"img_window\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"instances\"].gt_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "x=1\n",
    "while(True):\n",
    "    if x==1:\n",
    "        break\n",
    "    i+=1\n",
    "    x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rana/anaconda3/envs/m2f/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20, 25])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.zeros((10,20,20))\n",
    "b = torch.zeros((10,20,5))\n",
    "torch.cat((a,b),dim=2).shape                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5] [6, 6]\n"
     ]
    }
   ],
   "source": [
    "def fun(x,y):\n",
    "    x.append(5)\n",
    "    y.append(6)\n",
    "    return x,y\n",
    "a = [4]\n",
    "b = [6]\n",
    "(a,\n",
    "b) = fun(a,b)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,1.0,0], dtype=np.bool_)\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.5000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.,2.], requires_grad=True)\n",
    "b = torch.tensor([2.,3.], requires_grad=True)  \n",
    "ab = torch.cat((a,b), dim=0) # ab  = tensor([1., 2., 2., 3.], grad_fn=<CatBackward>)\n",
    "z = ab**2 # z = tensor([1., 4., 4., 9.], grad_fn=<PowBackward0>)\n",
    "out = z.mean() # out = tensor(4.5000, grad_fn=<MeanBackward0>)\n",
    "out.backward()\n",
    "print(a.grad) # tensor([1.5000, 2.5000])\n",
    "b.grad # tensor([1.5000, 2.5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import inference_on_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_path = \"all_data/evaluations/sbd_multi_insts/dynamite_swin_tiny_1024_bs64_10_max_click_th_final_updated_time_summary.pickle\"\n",
    "\n",
    "with open(file_path, 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ['dataset', 'model', 'iou_threshold', 'failed_images_counts', 'avg_over_total_images', 'Avg_NOC', 'Avg_IOU', 'num_failed_objects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.48"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['Avg_NOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.334966748337417"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6671/2857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = b['time_per_image_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14331715965665856"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6641665849995062"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = b['time_per_image_annotation']\n",
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038640099109417216"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = b['time_per_intreaction_tranformer_decoder']\n",
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5366592"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.038*2.33*4.48 + 0.14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"num interactions\", \"NCI\", \"NOC\", \"NFO\", \"NFI\"]\n",
    "for i in range(6):\n",
    "    file_path = f\"all_data/evaluations/sbd_multi_insts/ablation_iter_{i}_10_max_click_th_final_updated_time_summary.pickle\"\n",
    "\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    \n",
    "    x.add_row([i, np.round(b['avg_over_total_images'],2), b['Avg_NOC'], b['num_failed_objects'], b['failed_images_counts']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+------+------+-----+\n",
      "| num interactions | NCI  | NOC  | NFO  | NFI |\n",
      "+------------------+------+------+------+-----+\n",
      "|        0         | 3.94 | 5.24 | 2024 | 928 |\n",
      "|        1         | 3.87 | 5.16 | 1854 | 884 |\n",
      "|        2         | 3.67 | 4.9  | 1682 | 825 |\n",
      "|        3         | 3.63 | 4.8  | 1566 | 778 |\n",
      "|        4         | 3.51 | 4.69 | 1566 | 776 |\n",
      "|        5         | 3.58 | 4.76 | 1576 | 784 |\n",
      "+------------------+------+------+------+-----+\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_palette(num_cls):\n",
    "    palette = np.zeros(3 * num_cls, dtype=np.int32)\n",
    "\n",
    "    for j in range(0, num_cls):\n",
    "        lab = j\n",
    "        i = 0\n",
    "\n",
    "        while lab > 0:\n",
    "            palette[j*3 + 0] |= (((lab >> 0) & 1) << (7-i))\n",
    "            palette[j*3 + 1] |= (((lab >> 1) & 1) << (7-i))\n",
    "            palette[j*3 + 2] |= (((lab >> 2) & 1) << (7-i))\n",
    "            i = i + 1\n",
    "            lab >>= 3\n",
    "\n",
    "    return palette.reshape((-1, 3))\n",
    "c = get_palette(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask2former.data.scribble.tamed_robot import TamedRobot\n",
    "t=TamedRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 10]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= []\n",
    "a.insert(0,5)\n",
    "a.append(None)\n",
    "a[-1] = 10\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "areas = b['failed_objects_areas']\n",
    "bin_size=2\n",
    "bins  = [sum(areas[i:i+bin_size]) for i in range(0,len(areas)-bin_size, bin_size)] \n",
    "print(len(areas))\n",
    "while(bins[-1] ==0):\n",
    "    bins.pop()\n",
    "# print(bins)\n",
    "# sns.distplot(np.arange(len(bins)), \n",
    "#     hist_kws={\n",
    "#         \"weights\": bins\n",
    "#     },\n",
    "# )\n",
    "\n",
    "import copy\n",
    "t = sum(bins[25:])\n",
    "bins1 = copy.deepcopy(bins[:25])\n",
    "bins1 = bins1.append(t)\n",
    "x = bins[:25]\n",
    "x.append(sum(bins[25:]))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "# Bring some raw data.\n",
    "frequencies = x\n",
    "# In my original code I create a series and run on that,\n",
    "# so for consistency I create a series from the list.\n",
    "freq_series = pd.Series(frequencies)\n",
    "\n",
    "x_labels = [f\"{i+1}\" for i in range(len(x)-1)]\n",
    "x_labels.append(\">25\")\n",
    "\n",
    "# Plot the figure.\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = freq_series.plot(kind=\"bar\")\n",
    "# ax.set_title(\"Failed Object Areas Distribution\")\n",
    "\n",
    "ax.set_xlabel(\"% of Image Covered by Object\")\n",
    "ax.set_ylabel(\"#Failed Objects\")\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set_ylim(0,825)\n",
    "ax.set_xlim(-1,26)\n",
    "rects = ax.patches\n",
    "\n",
    "# Make some labels.\n",
    "labels = [f\"{x[i]}\" for i in range(len(rects))]\n",
    "\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(\n",
    "        rect.get_x() + rect.get_width() / 2, height + 5, label, ha=\"center\", va=\"bottom\"\n",
    "    )\n",
    "plt.savefig(\"a.jpg\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_with_sizes(x):\n",
    "    obj_sizes = np.bincount(x.flatten())\n",
    "    labels = np.nonzero(obj_sizes)[0].tolist()\n",
    "    labels = [x for x in labels if x != 0]\n",
    "    return labels, obj_sizes[labels].tolist()\n",
    "def get_palette(num_cls):\n",
    "    palette = np.zeros(3 * num_cls, dtype=np.int32)\n",
    "\n",
    "    for j in range(0, num_cls):\n",
    "        lab = j\n",
    "        i = 0\n",
    "\n",
    "        while lab > 0:\n",
    "            palette[j*3 + 0] |= (((lab >> 0) & 1) << (7-i))\n",
    "            palette[j*3 + 1] |= (((lab >> 1) & 1) << (7-i))\n",
    "            palette[j*3 + 2] |= (((lab >> 2) & 1) << (7-i))\n",
    "            i = i + 1\n",
    "            lab >>= 3\n",
    "\n",
    "    return palette.reshape((-1, 3))\n",
    "color_map = get_palette(80)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 500, 3)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 375, 500])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from detectron2.utils.colormap import colormap\n",
    "# color_map = colormap(rgb=True, maximum=1)\n",
    "\n",
    "sbd_path = \"datasets/sbd/dataset/\"\n",
    "# print(os.path.exists(sbd_path + \"img/2008_000051.jpg\"))\n",
    "image_id = \"2008_000383\"\n",
    "image = cv2.imread(sbd_path + f\"img/{image_id}.jpg\")\n",
    "print(image.shape)\n",
    "# cv2.imshow(\"image\", image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "from scipy.io import loadmat\n",
    "instances_mask = loadmat(str(sbd_path + f\"inst/{image_id}.mat\"))['GTinst'][0][0][0].astype(np.int32)\n",
    "labels, _ = get_labels_with_sizes(instances_mask)\n",
    "print(np.unique(instances_mask))\n",
    "masks = []\n",
    "import copy\n",
    "print(labels)\n",
    "for label in labels:\n",
    "    \n",
    "    temp_masks = copy.deepcopy(instances_mask)\n",
    "    temp_masks[temp_masks != label] = 0\n",
    "    temp_masks[temp_masks > 0] = 1\n",
    "    # m = instances_mask == label\n",
    "    masks.append(np.asarray(temp_masks, dtype =np.uint8))\n",
    "masks = torch.from_numpy(np.stack(masks)).to(dtype = torch.uint8)\n",
    "masks.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import Visualizer\n",
    "image = cv2.imread(sbd_path + f\"img/{image_id}.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "visualizer = Visualizer(image, metadata=None)\n",
    "# pred_masks = F.resize(result_masks_for_vis.to(dtype=torch.uint8), image.shape[:2])\n",
    "c = []\n",
    "for i in range(masks.shape[0]):\n",
    "    c.append(color_map[i]/255.0)\n",
    "# pred_masks = np.asarray(pred_masks).astype(np.bool_)\n",
    "vis = visualizer.overlay_instances(masks = masks, assigned_colors=c, alpha=0.70)\n",
    "# [Optional] prepare labels\n",
    "\n",
    "image = vis.get_image()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f\"output/visual_results/{image_id}.png\"\n",
    "# im = cv2.cvtColor(image,  cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(filename, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 854, 3)\n",
      "[0 1]\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 480, 854])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "davis_path = \"datasets/DAVIS/DAVIS-2017-trainval/JPEGImages/480p/\"\n",
    "ann_path = \"datasets/DAVIS/DAVIS-2017-trainval/Annotations/480p/\"\n",
    "image_id = \"flamingo/00012\"\n",
    "image = cv2.imread(davis_path + f\"{image_id}.jpg\")\n",
    "print(image.shape)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# from scipy.io import loadmat\n",
    "# instances_mask = loadmat(str(sbd_path + f\"inst/{image_id}.mat\"))['GTinst'][0][0][0].astype(np.int32)\n",
    "instances_mask = np.array(Image.open(ann_path+f\"{image_id}.png\").convert(\"P\")).astype(np.uint8)\n",
    "labels, _ = get_labels_with_sizes(instances_mask)\n",
    "print(np.unique(instances_mask))\n",
    "masks = []\n",
    "import copy\n",
    "print(labels)\n",
    "for label in labels:\n",
    "    \n",
    "    temp_masks = copy.deepcopy(instances_mask)\n",
    "    temp_masks[temp_masks != label] = 0\n",
    "    temp_masks[temp_masks > 0] = 1\n",
    "    # m = instances_mask == label\n",
    "    masks.append(np.asarray(temp_masks, dtype =np.uint8))\n",
    "masks = torch.from_numpy(np.stack(masks)).to(dtype = torch.uint8)\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import Visualizer\n",
    "image = cv2.imread(davis_path + f\"{image_id}.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "visualizer = Visualizer(image, metadata=None)\n",
    "# pred_masks = F.resize(result_masks_for_vis.to(dtype=torch.uint8), image.shape[:2])\n",
    "c = []\n",
    "for i in range(masks.shape[0]):\n",
    "    c.append(color_map[2*(i)+2])\n",
    "# pred_masks = np.asarray(pred_masks).astype(np.bool_)\n",
    "vis = visualizer.overlay_instances(masks = masks, assigned_colors=c, alpha=0.65)\n",
    "# [Optional] prepare labels\n",
    "\n",
    "image = vis.get_image()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f\"output/visual_results/lindy-hop.png\"\n",
    "# im = cv2.cvtColor(image,  cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(filename, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "image =  cv2.imread(\"failed_v0.png\", cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501, 737, 3)\n",
      "(334, 491, 3)\n"
     ]
    }
   ],
   "source": [
    "h, w, _ = image.shape\n",
    "print(image.shape)\n",
    "h_new = int((2*h)/3)\n",
    "w_new = int((2*w)/3)\n",
    "im = cv2.resize(image,(w_new,h_new))\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# im = cv2.cvtColor(im,  cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(\"new_failed_v0.png\", im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eec4856e9527ee4049f7304c395b2145937ffdaa8a3f2aebdeedd97affd38c5c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('m2f')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
