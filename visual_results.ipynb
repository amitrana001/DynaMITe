{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of mask2former.modeling.transformer_decoder.spatio_temp_m2f_mq_transformer_decoder failed: Traceback (most recent call last):\n",
      "  File \"/home/rana/anaconda3/envs/m2f/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/rana/anaconda3/envs/m2f/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/rana/anaconda3/envs/m2f/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/rana/Thesis/DynaMITe/mask2former/modeling/transformer_decoder/spatio_temp_m2f_mq_transformer_decoder.py\", line 236, in <module>\n",
      "    class SpatioTempM2FTransformerDecoderMQ(nn.Module):\n",
      "  File \"/home/rana/anaconda3/envs/m2f/lib/python3.8/site-packages/fvcore/common/registry.py\", line 59, in deco\n",
      "    self._do_register(name, func_or_class)\n",
      "  File \"/home/rana/anaconda3/envs/m2f/lib/python3.8/site-packages/fvcore/common/registry.py\", line 43, in _do_register\n",
      "    assert (\n",
      "AssertionError: An object named 'SpatioTempM2FTransformerDecoderMQ' was already registered in 'TRANSFORMER_MODULE' registry!\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch,torchvision\n",
    "import copy\n",
    "from mask2former.utils.misc import is_dist_avail_and_initialized, nested_tensor_from_tensor_list\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# y, _= nested_tensor_from_tensor_list(x).decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = torch.zeros((0, 10, 10), dtype=torch.uint8)\n",
    "mask_areas = torch.sum(masks, (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_masks =  masks[sorted(range(len(mask_areas)),key=mask_areas.__getitem__,reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_masks = torch.zeros((0, 10, 10), dtype=torch.uint8)\n",
    "mask_areas = torch.sum(gt_masks, (1,2))\n",
    "gt_masks = gt_masks.to(dtype=torch.uint8)\n",
    "gt_masks =  gt_masks[sorted(range(len(mask_areas)),key=mask_areas.__getitem__,reverse=True)]\n",
    "\n",
    "instance_map = torch.zeros((gt_masks.shape[-2:]), dtype=torch.int16)\n",
    "num_objects = gt_masks.shape[0]\n",
    "instances_ids = np.arange(1, num_objects + 1)\n",
    "\n",
    "for _id, _m in enumerate(gt_masks):\n",
    "    instance_map[_m == 1] = _id+1\n",
    "    assert (_m != 0).sum() > 0\n",
    "\n",
    "new_gt_masks = []\n",
    "for _id in instances_ids:\n",
    "    _m = (instance_map == _id).to(dtype=torch.uint8)\n",
    "    if _m.sum() > 0:\n",
    "        new_gt_masks.append(_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if not len(new_gt_masks):\n",
    "    print(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_mval_images = os.listdir(\"datasets/COCO_MVal/img\")\n",
    "coco_mval_ids = [img_id.split(\"_\")[-1] for img_id in coco_mval_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cow08_000000061171.jpg',\n",
       " 'stop sign07_000000000724.jpg',\n",
       " 'apple08_000000113589.jpg',\n",
       " 'pizza00_000000197022.jpg',\n",
       " 'train04_000000546659.jpg',\n",
       " 'giraffe02_000000301981.jpg',\n",
       " 'microwave05_000000498463.jpg',\n",
       " 'cat03_000000115885.jpg',\n",
       " 'hot dog00_000000322574.jpg',\n",
       " 'broccoli07_000000296634.jpg']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_mval_images[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000061171.jpg',\n",
       " '000000000724.jpg',\n",
       " '000000113589.jpg',\n",
       " '000000197022.jpg',\n",
       " '000000546659.jpg',\n",
       " '000000301981.jpg',\n",
       " '000000498463.jpg',\n",
       " '000000115885.jpg',\n",
       " '000000322574.jpg',\n",
       " '000000296634.jpg']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_mval_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cocoval17 = os.listdir(\"datasets/coco/val2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DatasetCatalog.get(\"coco_2017_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = []\n",
    "for i in range(len(d)): \n",
    "    val_ids.append(str(d[i][\"file_name\"]).split(\"/\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000000217219.jpg',\n",
       " '000000405972.jpg',\n",
       " '000000047010.jpg',\n",
       " '000000085823.jpg',\n",
       " '000000225184.jpg',\n",
       " '000000578871.jpg',\n",
       " '000000129113.jpg',\n",
       " '000000344100.jpg',\n",
       " '000000409475.jpg',\n",
       " '000000534605.jpg']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocoval17[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "out = []\n",
    "for id in coco_mval_ids :\n",
    "    out.append(val_ids.index(id))\n",
    "    c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 7, 4]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indexes.insert(4,7)\n",
    "random_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 2, 1]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_indexes = list(range(5))\n",
    "random.shuffle(random_indexes)\n",
    "random_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 2, 4, 0]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(random_indexes)\n",
    "random_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "assert k==5, \"K should be 5\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarising multi-instance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "_root_dir = os.path.join(os.getcwd(), \"output/evaluation/final/summary/davis_2017_val\")\n",
    "pkl_file = \"mq_swin_tiny_fusion_pf_uni_time_pe_bs128_ep50_random_08_03_2023_18_16_55__10.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = os.path.join(_root_dir, pkl_file)\n",
    "with open(pickle_path, 'rb') as handle:\n",
    "    summary_stats= pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious_objects_per_interaction = summary_stats[\"ious_objects_per_interaction\"]\n",
    "object_areas_per_image = summary_stats['object_areas_per_image']\n",
    "iou_threshold = summary_stats[\"iou_threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_area_bins = [0]*1001\n",
    "all_area_bins = [0]*1001\n",
    "for _image_id in ious_objects_per_interaction.keys():\n",
    "    final_ious = ious_objects_per_interaction[_image_id][-1]\n",
    "    obj_areas = object_areas_per_image[_image_id]\n",
    "    for i, iou in enumerate(final_ious):\n",
    "        indx = int(obj_areas[i]*1000)\n",
    "        if iou<iou_threshold:\n",
    "            failed_area_bins[indx] += 1\n",
    "        all_area_bins[indx]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(failed_area_bins))\n",
    "failed_area_bins[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(all_area_bins))\n",
    "all_area_bins[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_area_bins = np.asarray(all_area_bins) - np.asarray(failed_area_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "d = 1\n",
    "i=0\n",
    "while(i<100):\n",
    "    x.append(sum(failed_area_bins[i:i+d]))\n",
    "    y.append(sum(diff_area_bins[i:i+d]))\n",
    "    i+=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.append(sum(failed_area_bins[i:]))\n",
    "y.append(sum(diff_area_bins[i:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(0,20,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = len(x)\n",
    " \n",
    "# boys = (20, 35, 30, 35, 27)\n",
    "# girls = (25, 32, 34, 20, 25)\n",
    "# boyStd = (2, 3, 4, 1, 2)\n",
    "# girlStd = (3, 5, 2, 3, 3)\n",
    "ind = np.arange(N)  \n",
    "width =1.0\n",
    "# ticks = (f\"{(i+1)*d/10}\" for i in list(range(0,N)) \n",
    "fig = plt.subplots(figsize =(12, 6))\n",
    "p1 = plt.bar(ind, x, width,edgecolor='black',align='edge')\n",
    "p2 = plt.bar(ind, y, width,align='edge',\n",
    "             bottom = x,edgecolor='black')\n",
    "\n",
    "for (rect1, rect2) in zip(p1,p2):\n",
    "    height = rect1.get_height() + rect2.get_height()\n",
    "    perc =  round((rect2.get_height()/height)*100,ndigits=2)\n",
    "    # plt.text(rect1.get_x() + rect1.get_width() / 2.0, height, f'{height:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.ylabel('#Objects ')\n",
    "# plt.title('Failed object areas visualization')\n",
    "plt.xlabel(\"Area covered by object [%]\")\n",
    "plt.xticks(range(0,101,10), ('0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0', '8.0', '9.0', '>10'))\n",
    "# plt.xticks(range(N), ticks)\n",
    "# plt.yticks(np.arange(0, 1000,100))\n",
    "plt.ylim(0,120)\n",
    "plt.xlim(0,101)\n",
    "plt.legend((p1[0], p2[0]), ('Failed objects', 'Segmented objects'))\n",
    "import tikzplotlib\n",
    "\n",
    "tikzplotlib.save(\"test.tex\")\n",
    "plt.savefig(\"a.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "# Bring some raw data.\n",
    "frequencies = x\n",
    "# In my original code I create a series and run on that,\n",
    "# so for consistency I create a series from the list.\n",
    "freq_series = pd.Series(frequencies)\n",
    "\n",
    "x_labels = [f\"{i+1}\" for i in range(len(x)-1)]\n",
    "x_labels.append(\">25\")\n",
    "\n",
    "# Plot the figure.\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = freq_series.plot(kind=\"bar\")\n",
    "# ax.set_title(\"Failed Object Areas Distribution\")\n",
    "\n",
    "ax.set_xlabel(\"% of Image Covered by Object\")\n",
    "ax.set_ylabel(\"#Failed Objects\")\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set_ylim(0,825)\n",
    "ax.set_xlim(-1,26)\n",
    "rects = ax.patches\n",
    "\n",
    "# Make some labels.\n",
    "labels = [f\"{x[i]}\" for i in range(len(rects))]\n",
    "\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(\n",
    "        rect.get_x() + rect.get_width() / 2, height + 5, label, ha=\"center\", va=\"bottom\"\n",
    "    )\n",
    "plt.savefig(\"a.jpg\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ious_objects_per_interaction', 'model', 'dataset', 'iou_threshold'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b['ious_objects_per_interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: sbd_multi_insts\n",
      "iou_threshold: 0.85\n",
      "NOC: 6.02\n",
      "NCI: 4.056120028223635\n",
      "NFO: 1747\n",
      "failed_images_counts: 847\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset: {b['dataset']}\")\n",
    "print(f\"iou_threshold: {b['iou_threshold']}\")\n",
    "print(f\"NOC: {b['Avg_NOC']}\")\n",
    "print(f\"NCI: {b['avg_over_total_images']}\")\n",
    "print(f\"NFO: {b['num_failed_objects']}\")\n",
    "print(f\"failed_images_counts: {b['failed_images_counts']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2008_000003_0',\n",
       " '2008_000007_1',\n",
       " '2008_000009_2',\n",
       " '2008_000027_3',\n",
       " '2008_000043_4',\n",
       " '2008_000051_5',\n",
       " '2008_000059_6',\n",
       " '2008_000067_7',\n",
       " '2008_000073_8',\n",
       " '2008_000075_9']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = list(b[\"ious_objects_per_interaction\"].keys())\n",
    "ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor(0.8549), tensor(0.9158)],\n",
       " [tensor(0.8549), tensor(0.9158)],\n",
       " [tensor(0.8549), tensor(0.9158)],\n",
       " [tensor(0.8549), tensor(0.9158)],\n",
       " [tensor(0.8549), tensor(0.9158)]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"ious_objects_per_interaction\"]['2008_000067_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[True, True, True],\n",
       " [True, False, False],\n",
       " [False, False, True],\n",
       " [True, False, False],\n",
       " [False, False, True]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"clicked_objects_per_interaction\"]['2008_000067_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = [torch.tensor(0.8549), torch.tensor(0.9158)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times_point_smapled_false = 0\n",
    "while True:\n",
    "    if all(iou >= 0.85 for iou in ious) or num_times_point_smapled_false >= 2:\n",
    "        break\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(b[\"ious_objects_per_interaction\"].keys())\n",
    "total_iou_change = 0\n",
    "count = 0\n",
    "bins = 101\n",
    "neg_iou_change = [0]*bins\n",
    "pos_iou_change = [0]*bins\n",
    "\n",
    "neg_iou_change_bg = [0]*bins\n",
    "pos_iou_change_bg = [0]*bins\n",
    "bg_clicks = 0\n",
    "fg_clicks = 0\n",
    "for key in ids:\n",
    "    ious = np.asarray(b[\"ious_objects_per_interaction\"][key])\n",
    "    clicked = b[\"clicked_objects_per_interaction\"][key]\n",
    "    indices = [sum(i)>=1 for i in clicked]\n",
    "    clicked = np.asarray(clicked)[indices] \n",
    "    if len(indices)<len(ious):\n",
    "        indices.append(False)\n",
    "    \n",
    "    ious = ious[indices]\n",
    "    assert len(ious) == len(clicked)\n",
    "    \n",
    "    for i in range(1,len(clicked)):\n",
    "        if len(ious[i])==1:\n",
    "            continue\n",
    "        diff = (ious[i]-ious[i-1])*100\n",
    "        t = np.where(clicked[i]==True)[0][0]\n",
    "        if t== len(clicked[i])-1: #bg_click\n",
    "            bg_clicks+=1\n",
    "            for d in diff:\n",
    "                if d>0:\n",
    "                   pos_iou_change_bg[int(abs(d))]+=1\n",
    "                elif d<0:\n",
    "                   neg_iou_change_bg[int(abs(d))]+=1 \n",
    "        else:\n",
    "            # diff[t] = 0\n",
    "            fg_clicks+=1\n",
    "            for (i, d) in enumerate(diff):\n",
    "                if i!=t:\n",
    "                    if d>0:\n",
    "                        pos_iou_change[int(abs(d))]+=1\n",
    "                    elif d<0:\n",
    "                        neg_iou_change[int(abs(d))]+=1 \n",
    "\n",
    "        # # print(diff)\n",
    "        # total_iou_change += (sum(diff)*100/(len(diff)-1))\n",
    "        # count+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fg_clicks: 26738\n",
      "\n",
      "negative iou change(>=3%) : 0\n",
      "\n",
      "positive iou change(>=3%) : 0\n",
      "\n",
      "bg_clicks: 5659\n",
      "\n",
      "negative iou change bg(>=3%) : 0\n",
      "\n",
      "positive iou change bg(>=3%) : 0\n"
     ]
    }
   ],
   "source": [
    "print(f'fg_clicks: {fg_clicks}\\n')\n",
    "print(f'negative iou change(>=3%) : {sum(neg_iou_change[3:])}\\n')\n",
    "print(f'positive iou change(>=3%) : {sum(pos_iou_change[3:])}\\n')\n",
    "\n",
    "print(f'bg_clicks: {bg_clicks}\\n')\n",
    "print(f'negative iou change bg(>=3%) : {sum(neg_iou_change_bg[3:])}\\n')\n",
    "print(f'positive iou change bg(>=3%) : {sum(pos_iou_change_bg[3:])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(neg_iou_change)\n",
    "sum(neg_iou_change[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    print(\"x_g\",x)\n",
    "    x+=1\n",
    "    print(\"x_g_\",x)\n",
    "\n",
    "def f(x):\n",
    "\n",
    "    for i in range(5):\n",
    "        g(x)\n",
    "        x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_g 0\n",
      "x_g_ 1\n",
      "x_g 1\n",
      "x_g_ 2\n",
      "x_g 2\n",
      "x_g_ 3\n",
      "x_g 3\n",
      "x_g_ 4\n",
      "x_g 4\n",
      "x_g_ 5\n"
     ]
    }
   ],
   "source": [
    "f(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"weights/segformer/mit_b0_trans.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = [5,3,2,10]\n",
    "# max_from_last= [0]*len(price)\n",
    "# max_from_last[-1] = price[-1]\n",
    "_max = price[-1]\n",
    "profit = 0\n",
    "for i in range(len(price)-2,-1,-1):\n",
    "    _max= max(price[i], _max)\n",
    "    profit += (_max-price[i])\n",
    "profit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \" backbone.bottom_up.patch_embed1.proj.{bias, weight}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backbone.patch_embed1.proj.{bias, weight}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.lstrip(' ').replace(\".bottom_up\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "a = torch.ones((1024,1024)).to(dtype=torch.float)\n",
    "sys.getsizeof(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1024])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.projects.point_rend.point_features import (\n",
    "    get_uncertain_point_coords_with_randomness,\n",
    "    point_sample,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "a = torch.zeros((10,10))\n",
    "a[0:6,0:3] = 1\n",
    "a[4:7,4:7] = 1\n",
    "# a[0:5, 7:] =1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 2.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 2.],\n",
       "        [2., 0.],\n",
       "        [2., 1.],\n",
       "        [2., 2.],\n",
       "        [3., 0.],\n",
       "        [3., 1.],\n",
       "        [3., 2.],\n",
       "        [4., 0.],\n",
       "        [4., 1.],\n",
       "        [4., 2.],\n",
       "        [4., 4.],\n",
       "        [4., 5.],\n",
       "        [4., 6.],\n",
       "        [5., 0.],\n",
       "        [5., 1.],\n",
       "        [5., 2.],\n",
       "        [5., 4.],\n",
       "        [5., 5.],\n",
       "        [5., 6.],\n",
       "        [6., 4.],\n",
       "        [6., 5.],\n",
       "        [6., 6.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.stack(torch.where(a), dim=1).to(torch.float)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.stack(torch.where(a), dim=1).to(torch.float)\n",
    "p[:,0]/=float(1024)\n",
    "p[:,1]/=float(1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((1,5,3))\n",
    "x.mean(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rana/anaconda3/envs/m2f/lib/python3.8/site-packages/torch/nn/functional.py:3981: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y = point_sample(x, p.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 0], [1, 2, 0], [1, 2, 0]],\n",
       " [[4, 5, 0], [4, 5, 0], [4, 5, 0], [4, 5, 0]],\n",
       " [[6, 6, 1], [6, 6, 1], [6, 6, 1], [6, 6, 1], [6, 6, 1]]]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[[1,2,0]]*3, [[4,5,0]]*4, [[6,6,1]]*5]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 0],\n",
       " [1, 2, 0],\n",
       " [1, 2, 0],\n",
       " [4, 5, 0],\n",
       " [4, 5, 0],\n",
       " [4, 5, 0],\n",
       " [4, 5, 0],\n",
       " [6, 6, 1],\n",
       " [6, 6, 1],\n",
       " [6, 6, 1],\n",
       " [6, 6, 1],\n",
       " [6, 6, 1]]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = copy.deepcopy(a[0])\n",
    "for t in a[1:]:\n",
    "    y.extend(t)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(y)[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [4, 5],\n",
       "        [4, 5],\n",
       "        [4, 5],\n",
       "        [4, 5],\n",
       "        [6, 6],\n",
       "        [6, 6],\n",
       "        [6, 6],\n",
       "        [6, 6],\n",
       "        [6, 6]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 0], [1, 2, 0], [1, 2, 0]],\n",
       " [[4, 5, 0], [4, 5, 0], [4, 5, 0], [4, 5, 0]],\n",
       " [[6, 6, 1], [6, 6, 1], [6, 6, 1], [6, 6, 1], [6, 6, 1]]]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41, 2])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.zeros((len(torch.where(a)[0]),2))\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = F.interpolate(a.unsqueeze(0).unsqueeze(0), size=(128,128), mode=\"bilinear\", align_corners=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.,  7.],\n",
       "       [ 8.,  9., 10., 11.],\n",
       "       [12., 13., 14., 15.]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "a = np.arange(16.).reshape((4, 4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  4.,  8., 12.],\n",
       "       [ 1.,  5.,  9., 13.],\n",
       "       [ 2.,  6., 10., 14.],\n",
       "       [ 3.,  7., 11., 15.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.5, 5. ])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndimage.map_coordinates(a, [[1], [0.5, 1]], order=1, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17552/3095995108.py:1: DeprecationWarning: Please use `map_coordinates` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
      "  from scipy.ndimage.interpolation import map_coordinates\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "# from mpl_toolkits.basemap import interp\n",
    "import numpy\n",
    "\n",
    "in_data = numpy.array([[ 25.89125824,  25.88840675],[ 25.90930748,  25.90640068]], dtype=numpy.float32)\n",
    "\n",
    "in_data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.8, 7.5])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_coordinates(a, [[1.7,1.5], [1,1.5]], order=1, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "num_labels, labels_im = cv2.connectedComponents(a.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 0, 0, 2, 2, 2],\n",
       "       [1, 1, 1, 0, 0, 0, 0, 2, 2, 2],\n",
       "       [1, 1, 1, 0, 0, 0, 0, 2, 2, 2],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 2, 2],\n",
       "       [0, 0, 0, 0, 3, 3, 0, 2, 2, 2],\n",
       "       [0, 0, 0, 0, 3, 3, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72,  9, 15,  4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(labels_im.flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_im == np.argmax(np.bincount(labels_im.flat)[1:]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask2former.data.dataset_mappers.eval.davis17_sbd_mq_evaluation_clicks_mapper import DAVIS17SBDEvalMQClicksDatasetMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask2former.data.datasets.register_coco_lvis import *\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "_root = os.getcwd()\n",
    "_root = os.path.join(_root, \"datasets/\")\n",
    "# _root = os.getenv(\"DETECTRON2_DATASETS\", \"datasets\")\n",
    "# print(_root)\n",
    "# register_all_coco_lvis_2017(_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DatasetCatalog.get(\"coco_lvis_2017_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = np.array([.76,.78,.80,.82,.85,.87,.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = ious>=.80\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now = 2023-02-08 10:36:37.880132\n",
      "date and time = 08_02_2023_10_36_37s\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    " \n",
    "print(\"now =\", now)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%d_%m_%Y_%H_%M_%S\")\n",
    "print(\"date and time =\", dt_string +\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5,-1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "10 in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 1, 1],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [1, 1, 1, 0, 1],\n",
       "        [1, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((2,5,5))\n",
    "torch.argmax(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2960,  0.8196, -1.1057, -0.7486,  0.0711, -1.1511, -0.5144, -0.5536,\n",
      "         1.3287, -0.3221], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, dtype=torch.float32, requires_grad=True)\n",
    "print(x)\n",
    "y = x.repeat(5, 1)\n",
    "z = (y**2).sum()\n",
    "# z.backward()\n",
    "torch.autograd.backward([z], inputs=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD([x], lr=0.01)\n",
    "print(x)        # tensor([1., 2.], requires_grad=True)\n",
    "optim.step()\n",
    "print(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0929,  1.6599,  0.0832,  0.5620],\n",
      "        [-0.3079,  2.0893, -1.9158,  1.1371],\n",
      "        [-0.5511, -0.2064,  0.6665,  0.4380]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4, requires_grad=True)\n",
    "print(x)\n",
    "# def test_repeat(x):\n",
    "y = x.repeat(2, 2, 2, 2)\n",
    "out = y.sum()\n",
    "out.backward()\n",
    "\n",
    "# test_repeat(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0929,  1.6599,  0.0832,  0.5620],\n",
      "        [-0.3079,  2.0893, -1.9158,  1.1371],\n",
      "        [-0.5511, -0.2064,  0.6665,  0.4380]], requires_grad=True)\n",
      "tensor([[-0.1089,  1.6439,  0.0672,  0.5460],\n",
      "        [-0.3239,  2.0733, -1.9318,  1.1211],\n",
      "        [-0.5671, -0.2224,  0.6505,  0.4220]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.SGD([x], lr=0.001)\n",
    "print(x)        # tensor([1., 2.], requires_grad=True)\n",
    "optim.step()\n",
    "print(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ones((5,5),dtype=np.bool_)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.ones((5,5))\n",
    "y[2:4,1:4] =0\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.argwhere(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "indices = random.sample(range(s.shape[0]),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 3, 16, 8, 10]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "@lru_cache(maxsize=None)\n",
    "def generate_probs(max_num_points, gamma):\n",
    "    probs = []\n",
    "    last_value = 1\n",
    "    for i in range(max_num_points):\n",
    "        probs.append(last_value)\n",
    "        last_value *= gamma\n",
    "\n",
    "    probs = np.array(probs)\n",
    "    probs /= probs.sum()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36060726, 0.25242508, 0.17669756, 0.12368829, 0.0865818 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_probs = generate_probs(5,gamma=0.7)\n",
    "pos_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[1,2,0], [2,3]]\n",
    "y = []\n",
    "y.append(x[1].append(0))\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "use_timestamp=False\n",
    "def gen_sineembed_for_position(pos_tensor):\n",
    "    # n_query, bs, _ = pos_tensor.size()\n",
    "    # sineembed_tensor = torch.zeros(n_query, bs, 256)\n",
    "    import math\n",
    "    scale = 2 * math.pi\n",
    "    dim_t = torch.arange(128, dtype=torch.float32, device=pos_tensor.device)\n",
    "    dim_t = 10000 ** (2 * torch.div(dim_t, 2, rounding_mode='floor') / 128)\n",
    "    x_embed = pos_tensor[:, :, 0] * scale\n",
    "    y_embed = pos_tensor[:, :, 1] * scale\n",
    "    if use_timestamp:\n",
    "        t_embed = pos_tensor[:, :, 2] * scale\n",
    "        y_embed += t_embed\n",
    "        x_embed += x_embed\n",
    "    pos_x = x_embed[:, :, None] / dim_t\n",
    "    pos_y = y_embed[:, :, None] / dim_t\n",
    "    pos_x[:, :, 0::2][torch.where(pos_x[:, :, 0::2] < 0)] = 0.0\n",
    "    pos_x[:, :, 1::2][torch.where(pos_x[:, :, 1::2] < 0)] = (0.5 * math.pi)\n",
    "    pos_y[:, :, 0::2][torch.where(pos_y[:, :, 0::2] < 0)] = 0.0\n",
    "    pos_y[:, :, 1::2][torch.where(pos_y[:, :, 1::2] < 0)] = (0.5 * math.pi)\n",
    "    pos_x = torch.stack((pos_x[:, :, 0::2].sin(), pos_x[:, :, 1::2].cos()), dim=3).flatten(2)\n",
    "    pos_y = torch.stack((pos_y[:, :, 0::2].sin(), pos_y[:, :, 1::2].cos()), dim=3).flatten(2)\n",
    "    pos = torch.cat((pos_y, pos_x), dim=2)\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tensor_coords(batched_fg_coords_list, batched_bg_coords_list, num_queries, height, width, device):\n",
    "\n",
    "    #batched_fg_coords_list: batch x (list of list of fg coords) [y,x,t]\n",
    "\n",
    "    # return\n",
    "    # points: Bs x num_queries x 3 \n",
    "    B = len(batched_fg_coords_list)\n",
    "    \n",
    "    pos_tensor = []\n",
    "    \n",
    "    for i, fg_coords_per_image in enumerate(batched_fg_coords_list):\n",
    "        coords_per_image  = []\n",
    "        for fg_coords_per_mask in fg_coords_per_image:\n",
    "            for coords in fg_coords_per_mask:\n",
    "                coords_per_image.append([coords[0]/width, coords[1]/height, coords[2]])\n",
    "        if batched_bg_coords_list[i] is not None:\n",
    "            for coords in batched_bg_coords_list[i]:\n",
    "                coords_per_image.append([coords[0]/width, coords[1]/height, coords[2]])\n",
    "        coords_per_image.extend([[-1.0,-1.0,-1.0]] * (num_queries-len(coords_per_image)))\n",
    "        pos_tensor.append(torch.tensor(coords_per_image,device=device))\n",
    "    # pos_tensor = torch.tensor(pos_tensor,device=device)\n",
    "    pos_tensor = torch.stack(pos_tensor)\n",
    "    return pos_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [y,x,t]\n",
    "batched_fg_coords_list = [[[[2,3,0],[3,5,0]], [[5,6,0], [6,7,0]]], [[[2,3,0],[3,5,0]], [[5,6,0], [6,7,0]]]]\n",
    "batched_bg_coords_list = [[[6,7,0]],None]\n",
    "num_queries = 11\n",
    "height = width = 50\n",
    "device = 'cpu'\n",
    "\n",
    "pos_tensor = get_pos_tensor_coords(batched_fg_coords_list, batched_bg_coords_list, num_queries, height, width, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 3])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0400,  0.0600,  0.0000],\n",
       "         [ 0.0600,  0.1000,  0.0000],\n",
       "         [ 0.1000,  0.1200,  0.0000],\n",
       "         [ 0.1200,  0.1400,  0.0000],\n",
       "         [ 0.1200,  0.1400,  0.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000]],\n",
       "\n",
       "        [[ 0.0400,  0.0600,  0.0000],\n",
       "         [ 0.0600,  0.1000,  0.0000],\n",
       "         [ 0.1000,  0.1200,  0.0000],\n",
       "         [ 0.1200,  0.1400,  0.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 2 * math.pi\n",
    "dim_t = torch.arange(128, dtype=torch.float32, device=pos_tensor.device)\n",
    "dim_t = 10000 ** (2 * torch.div(dim_t, 2, rounding_mode='floor') / 128)\n",
    "x_embed = pos_tensor[:, :, 0] * scale\n",
    "y_embed = pos_tensor[:, :, 1] * scale\n",
    "# if use_timestamp:\n",
    "#     t_embed = pos_tensor[:, :, 2] * scale\n",
    "#     y_embed += t_embed\n",
    "#     x_embed += x_embed\n",
    "pos_x = x_embed[:, :, None] / dim_t\n",
    "pos_y = y_embed[:, :, None] / dim_t\n",
    "pos_x = torch.stack((pos_x[:, :, 0::2].sin(), pos_x[:, :, 1::2].cos()), dim=3).flatten(2)\n",
    "pos_y = torch.stack((pos_y[:, :, 0::2].sin(), pos_y[:, :, 1::2].cos()), dim=3).flatten(2)\n",
    "pos = torch.cat((pos_y, pos_x), dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 128])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_x = x_embed[:, :, None] / dim_t\n",
    "pos_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_x[:, :, 0::2][torch.where(pos_x[:, :, 0::2] < 0)] = 0.0\n",
    "pos_x[:, :, 1::2][torch.where(pos_x[:, :, 1::2] < 0)] = math.pi * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9.6858e-01,  9.7641e-01,  9.8229e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 9.2978e-01,  9.4718e-01,  9.6030e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 8.0902e-01,  8.5559e-01,  8.9104e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         ...,\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08],\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08],\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08]],\n",
       "\n",
       "        [[ 9.6858e-01,  9.7641e-01,  9.8229e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 9.2978e-01,  9.4718e-01,  9.6030e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         [ 8.0902e-01,  8.5559e-01,  8.9104e-01,  ...,  1.0000e+00,\n",
       "           1.0000e+00,  1.0000e+00],\n",
       "         ...,\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08],\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08],\n",
       "         [-4.3711e-08, -4.3711e-08, -4.3711e-08,  ..., -4.3711e-08,\n",
       "          -4.3711e-08, -4.3711e-08]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_x[:, :, 1::2].cos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t = gen_sineembed_for_position(pos_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.6812e-01,  9.2978e-01,  3.2069e-01,  ...,  1.0000e+00,\n",
       "           2.9023e-05,  1.0000e+00],\n",
       "         [ 5.8779e-01,  8.0902e-01,  5.1765e-01,  ...,  1.0000e+00,\n",
       "           4.3534e-05,  1.0000e+00],\n",
       "         [ 6.8455e-01,  7.2897e-01,  6.0751e-01,  ...,  1.0000e+00,\n",
       "           7.2557e-05,  1.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08],\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08],\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08]],\n",
       "\n",
       "        [[ 3.6812e-01,  9.2978e-01,  3.2069e-01,  ...,  1.0000e+00,\n",
       "           2.9023e-05,  1.0000e+00],\n",
       "         [ 5.8779e-01,  8.0902e-01,  5.1765e-01,  ...,  1.0000e+00,\n",
       "           4.3534e-05,  1.0000e+00],\n",
       "         [ 6.8455e-01,  7.2897e-01,  6.0751e-01,  ...,  1.0000e+00,\n",
       "           7.2557e-05,  1.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08],\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08],\n",
       "         [ 0.0000e+00, -4.3711e-08,  0.0000e+00,  ..., -4.3711e-08,\n",
       "           0.0000e+00, -4.3711e-08]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.123233995736766e-17"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.cos(math.pi/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[0,0,0]]*5\n",
    "x = torch.tensor(x)\n",
    "torch.stack((x,x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "def visualization(batched_inputs, prev_output, batched_fg_coords_list,batched_bg_coords_list,\n",
    "                  alpha_blend=0.6, num_iter = 0):\n",
    "    image = np.asarray(batched_inputs[0]['image'].permute(1,2,0))\n",
    "\n",
    "    visualizer = Visualizer(image, metadata=None)\n",
    "    if prev_output is not None:\n",
    "        pred_masks = F.resize(prev_output.pred_masks.to(dtype=torch.uint8), image.shape[:2])\n",
    "    else:\n",
    "        pred_masks = batched_inputs[0]['instances'].gt_masks\n",
    "    c = []\n",
    "    for i in range(pred_masks.shape[0]):\n",
    "        # c.append(color_map[2*(i)+2]/255.0)\n",
    "        c.append(color_map[i]/255.0)\n",
    "    # pred_masks = np.asarray(pred_masks).astype(np.bool_)\n",
    "    vis = visualizer.overlay_instances(masks = pred_masks, assigned_colors=c, alpha=alpha_blend)\n",
    "    # [Optional] prepare labels\n",
    "\n",
    "    image = vis.get_image()\n",
    "    # # Laminate your image!\n",
    "    total_colors = len(color_map)-1\n",
    "    \n",
    "    h,w = image.shape[:2]\n",
    "    for fg_coords_per_mask in batched_fg_coords_list[0]:\n",
    "        for i, coords in enumerate(fg_coords_per_mask):\n",
    "            color = np.array(color_map[total_colors-5*i-4], dtype=np.uint8)\n",
    "            if i==0:\n",
    "                image = cv2.circle(image, (int(coords[1]), int(coords[0])), 8, color, -1)\n",
    "            else:\n",
    "                image = cv2.circle(image, (int(coords[1]), int(coords[0])), 3, color, -1)\n",
    "    \n",
    "    if batched_bg_coords_list[0]:\n",
    "         for i, coords in enumerate(batched_bg_coords_list[0]):\n",
    "            color = np.array([255,0,0], dtype=np.uint8)\n",
    "            image = cv2.circle(image, (int(coords[1]), int(coords[0])), 3, color, -1)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    # image = cv2.resize(image, (inputs[\"width\"],inputs[\"height\"]))\n",
    "    save_dir = os.path.join(\"./train_vis/\", str(batched_inputs[0]['image_id']))\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(save_dir, f\"iter_{num_iter}.jpg\"), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True],\n",
       "        [True, True, True, True, True],\n",
       "        [True, True, True, True, True],\n",
       "        [True, True, True, True, True],\n",
       "        [True, True, True, True, True]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((5,5),dtype=torch.bool)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to(torch.uint8)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"datasets/lvis/coco_lvis_combined_panoptic_1half.pickle\", 'rb') as f:\n",
    "    dataset_dicts = pickle.load(f)\n",
    "\n",
    "with open(\"datasets/lvis/coco_lvis_combined_panoptic_2half.pickle\", 'rb') as f:\n",
    "    dataset_dicts1 = pickle.load(f)\n",
    "\n",
    "dataset_dicts.extend(dataset_dicts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/lvis/coco_lvis_combined_panoptic.pickle\", 'wb') as handle:\n",
    "    pickle.dump(dataset_dicts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99354"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"output/GrabCut_points_dict_16_02_2023_14_38_32_.pickle\", 'rb') as f:\n",
    "    pt_sampled_dict = pickle.load(f)\n",
    "\n",
    "with open(\"output/GrabCut_points_dict_16_02_2023_14_39_07_.pickle\", 'rb') as f:\n",
    "    pt_sampled_dict1 = pickle.load(f)\n",
    "\n",
    "# with open(\"output/features_dicts1_GrabCut.pickle\", 'rb') as f:\n",
    "#     features_dict1 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pt_sampled_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sampled_dict1.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.66"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_p = 0\n",
    "for k,v in pt_sampled_dict.items():\n",
    "    sum_p+= len(v)\n",
    "sum_p/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.66"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_p = 0\n",
    "for k,v in pt_sampled_dict1.items():\n",
    "    sum_p+= len(v)\n",
    "sum_p/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in pt_sampled_dict.keys():\n",
    "    for k1 in pt_sampled_dict1.keys():\n",
    "        if k==k1 and pt_sampled_dict[k]!=pt_sampled_dict1[k1]:\n",
    "            print(k)\n",
    "            print(pt_sampled_dict1[k1])\n",
    "            print(pt_sampled_dict[k]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output/GrabCut_features_dict_16_02_2023_14_51_57_.pickle\", 'rb') as f:\n",
    "    features_dict = pickle.load(f)\n",
    "\n",
    "with open(\"output/GrabCut_features_dict_16_02_2023_14_53_59_.pickle\", 'rb') as f:\n",
    "    features_dict1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for k in features_dict.keys():\n",
    "    for k1 in features_dict1.keys():\n",
    "        if (k==k1):\n",
    "            print(torch.all(features_dict[k]['first_mask_before_resize']==features_dict1[k1]['first_mask_before_resize']))\n",
    "            # print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bool', 'grave', '326038', 'banana1', 'book', 'memorial', 'banana2', 'bush', 'doll', 'person6', '86016', 'person3', 'person2', '227092', '209070', '21077', 'scissors', 'teddy', '65019', '271008', 'flower', 'person5', '189080', 'person8', 'sheep', '388016', '69020', 'person7', 'banana3', '37073', 'person1', '124080', '153077', 'music', '106024', 'cross', 'fullmoon', 'tennis', 'elefant', 'stone1', 'llama', '208001', 'stone2', '304074', '153093', 'ceramic', '24077', 'person4', '376043', '181079'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sem_seg_head.predictor.query_embed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/rana/claix_work/DynaMITe/visual_results.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rana/claix_work/DynaMITe/visual_results.ipynb#ch0000023?line=0'>1</a>\u001b[0m features_dict[\u001b[39m'\u001b[39;49m\u001b[39mbush\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39msem_seg_head.predictor.query_embed\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sem_seg_head.predictor.query_embed'"
     ]
    }
   ],
   "source": [
    "features_dict['bush']['sem_seg_head.predictor.query_embed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.all(features_dict['bush']['sem_seg_head.predictor.query_embed']==features_dict['bool']['sem_seg_head.predictor.query_embed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "query_embed = nn.Parameter(torch.zeros(256), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-6.4749e-01, -9.4622e-01,  9.9136e-01, -2.8006e-01, -1.1464e+00,\n",
       "         2.3682e+00, -1.9174e+00,  4.9042e-01, -1.7973e+00, -8.8009e-02,\n",
       "         2.9536e-01, -1.1632e+00,  7.8763e-01,  9.7209e-02, -4.6051e-01,\n",
       "        -1.3793e+00, -1.3135e+00, -8.6194e-01, -2.2053e+00,  1.6569e+00,\n",
       "         5.3033e-01,  2.0219e+00,  1.4238e+00, -2.7438e-01, -2.9316e-01,\n",
       "         5.7328e-01, -4.8293e-01,  4.7248e-01, -4.7783e-01, -9.5518e-01,\n",
       "         3.4036e-02,  6.3088e-01, -1.7732e-03,  3.7992e-01, -1.1083e+00,\n",
       "        -2.0908e+00, -5.4316e-01,  3.8153e-01, -2.4660e+00, -7.5894e-01,\n",
       "         1.7062e-01, -6.1475e-01,  1.0703e+00,  3.5325e-01,  2.6061e-01,\n",
       "        -3.5651e-01,  4.8227e-01,  7.7621e-01,  9.3742e-01, -1.3908e+00,\n",
       "         1.1140e+00,  7.4399e-01, -4.4368e-01,  1.0445e+00, -1.4251e+00,\n",
       "         1.7776e-01, -5.6139e-01,  1.3463e+00,  1.2909e+00,  1.0224e+00,\n",
       "         1.0126e-02, -3.6532e-01,  3.0054e-01, -1.0427e+00, -2.5550e+00,\n",
       "         1.3792e+00, -3.0180e+00, -9.9011e-01, -5.7959e-01,  1.0527e+00,\n",
       "         3.8878e-02, -1.0803e-01, -5.9967e-01,  4.4868e-02,  1.1858e+00,\n",
       "         2.9113e-01, -1.0857e+00, -2.0949e+00, -7.9009e-01,  2.5124e-01,\n",
       "         7.6897e-01, -9.9976e-01,  1.0557e+00,  3.8981e-01,  2.1673e-01,\n",
       "         9.7767e-01,  6.8974e-02,  2.2309e+00, -1.5021e+00,  7.7536e-01,\n",
       "         3.9605e-01, -4.7302e-01, -3.6076e-02,  4.3843e-01,  1.4999e+00,\n",
       "         1.2663e+00,  1.2796e+00, -1.2030e-01, -3.6931e-01,  5.8684e-01,\n",
       "         6.7701e-01, -5.1989e-01,  5.6786e-01, -1.1889e+00, -1.0553e+00,\n",
       "         3.7751e-02, -1.9447e+00, -4.7964e-02, -2.0589e+00,  2.7592e-03,\n",
       "         5.5593e-01,  1.0265e+00,  1.3137e+00, -1.1642e+00,  1.1399e+00,\n",
       "        -1.5409e-02, -7.5154e-01,  1.5284e-02,  2.7918e+00,  4.6044e-01,\n",
       "         2.9290e-01, -1.2645e+00,  6.3408e-01, -4.7565e-02,  1.4135e+00,\n",
       "         2.4492e+00, -2.5464e+00,  6.6724e-01,  6.1609e-01, -4.9666e-01,\n",
       "        -1.7132e+00, -2.5013e-01, -1.6909e+00, -1.3032e+00,  9.4466e-01,\n",
       "        -1.2466e+00, -8.8447e-01,  7.7599e-01,  5.4487e-02, -5.9656e-01,\n",
       "         2.1227e+00, -2.1781e+00,  6.3330e-01,  7.1862e-01, -1.4283e-01,\n",
       "        -3.6911e-01,  8.7073e-01, -4.0721e-01, -1.7535e+00,  4.6955e-01,\n",
       "         1.0997e-01,  7.2473e-01,  5.2788e-01, -1.3986e+00, -8.5391e-03,\n",
       "        -6.9298e-01, -4.5402e-01, -1.2027e+00,  4.8955e-01,  7.2693e-01,\n",
       "        -5.8987e-01,  2.2842e+00, -8.5941e-01, -1.8679e-01, -6.2337e-01,\n",
       "        -1.3894e+00, -5.0438e-01, -1.1180e+00, -3.8329e-01, -1.1887e+00,\n",
       "         1.4751e+00, -3.1120e-01, -1.0112e-01,  2.0425e+00, -7.3740e-01,\n",
       "         6.8982e-02, -7.7067e-01, -6.3257e-01,  2.4467e+00, -6.6894e-01,\n",
       "         2.7258e-01,  2.7284e-01,  1.0076e+00,  1.4912e-01,  8.3674e-01,\n",
       "        -7.1490e-01,  9.0045e-01,  5.7044e-01,  3.9995e-01, -5.0511e-01,\n",
       "        -7.8044e-01,  1.2110e-01,  1.0546e+00,  7.1148e-01, -3.9047e-01,\n",
       "        -3.1581e-01,  1.2579e+00,  7.5340e-01, -1.8266e+00, -1.5195e+00,\n",
       "        -1.1493e+00, -6.0186e-01,  4.5245e-01, -6.4823e-01, -8.3427e-01,\n",
       "        -1.2665e+00,  5.3608e-01,  1.7869e-01,  2.9538e-01,  1.9509e+00,\n",
       "         2.0131e-01, -1.1664e+00, -4.7805e-01, -1.2348e-01,  3.7494e-01,\n",
       "        -1.5411e-01,  1.9286e-01,  5.3970e-01,  1.0906e+00,  1.4679e+00,\n",
       "        -1.1615e+00,  1.3955e-01,  9.5172e-01, -1.7147e-01,  1.2186e+00,\n",
       "         3.3679e+00,  5.3101e-01,  2.0939e-01,  3.9060e-01, -1.9350e+00,\n",
       "         9.4561e-01, -8.3802e-01,  1.4816e+00,  4.4207e-01,  9.6252e-02,\n",
       "        -2.0045e+00, -5.4523e-01,  3.9278e-01, -1.8980e-01, -1.1358e+00,\n",
       "         1.4776e-01, -1.1891e+00, -5.2493e-01, -1.3490e+00,  1.8121e+00,\n",
       "         4.8696e-01,  1.7120e+00, -2.2816e+00,  1.9390e+00, -4.1819e-01,\n",
       "        -4.1695e-01,  3.4997e-02,  1.3171e+00, -4.9327e-01,  6.0657e-01,\n",
       "        -5.1419e-01], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.normal_(query_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = features_dict1['bool']['sem_seg_head.predictor.query_embed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.4440e-01, -3.9581e-01,  1.4902e+00,  5.7210e-01,  1.4115e+00,\n",
       "         1.1782e+00,  1.7427e-01,  7.7683e-01,  1.3897e+00,  1.3905e-01,\n",
       "         1.0957e-01, -1.4464e-01, -1.5933e+00,  1.4587e+00, -1.1386e+00,\n",
       "         4.5302e-01,  5.3029e-01,  1.9542e-01,  1.1081e+00, -7.5916e-01,\n",
       "         9.3200e-01, -4.5756e-01, -1.4237e+00,  4.0218e-01, -9.7000e-01,\n",
       "         8.2498e-01,  4.8588e-01, -7.4774e-01, -5.4895e-01,  1.4943e+00,\n",
       "         1.6388e+00, -1.4993e+00,  9.8590e-01, -3.4655e-01, -5.1271e-01,\n",
       "         2.0943e-01, -1.9139e+00, -8.3778e-02,  6.0873e-01, -1.1971e+00,\n",
       "        -1.0011e+00,  7.8411e-01,  1.2188e+00, -6.9305e-01, -1.8274e-02,\n",
       "         7.3414e-01,  6.8789e-03,  2.3990e-02,  5.2682e-01,  7.5319e-01,\n",
       "         4.7599e-02, -4.8743e-01,  1.9112e-01, -7.5404e-01,  1.4807e+00,\n",
       "        -2.0128e+00, -1.5868e+00,  1.2303e+00,  1.5168e-01, -1.4823e+00,\n",
       "        -3.3540e-01, -5.1541e-01,  1.8677e-01, -1.3345e+00,  1.0651e+00,\n",
       "         1.5484e-01,  2.3708e-01,  9.4255e-01, -8.8311e-01,  1.4929e+00,\n",
       "         1.4355e+00, -1.2682e+00,  1.0203e+00,  1.3870e-02,  1.4823e+00,\n",
       "         7.7098e-01,  9.7230e-01,  3.8899e-01, -5.8867e-02,  2.5647e-01,\n",
       "        -4.6752e-01,  2.6700e-01,  9.0024e-01, -7.0883e-01,  3.8818e-01,\n",
       "         1.2056e+00,  1.5854e-01, -9.8617e-01,  1.7885e+00, -1.7943e+00,\n",
       "         1.2156e-01, -3.6817e-01,  2.4244e-01, -7.7437e-01,  1.3706e+00,\n",
       "        -1.4406e+00, -9.5404e-01, -2.5857e+00,  6.5134e-02, -1.3723e+00,\n",
       "        -1.3688e+00,  1.4804e+00,  2.0009e+00, -2.3979e-04,  8.2576e-01,\n",
       "         8.5650e-03,  1.3519e+00, -8.6264e-02, -7.5535e-01, -7.5569e-01,\n",
       "        -6.3938e-01,  2.5007e+00,  5.1795e-01,  3.5287e-01,  4.9800e-01,\n",
       "         5.9263e-01,  1.1400e+00, -4.4381e-01, -1.5946e+00,  6.9854e-02,\n",
       "        -4.1151e-01, -1.6355e+00, -1.3183e+00, -3.0206e+00, -1.1612e+00,\n",
       "         1.1963e+00, -7.8520e-01,  2.3013e+00, -9.0768e-01, -3.0319e-01,\n",
       "         4.7949e-01,  1.4885e+00, -3.2447e-01, -2.9942e-01, -6.9012e-02,\n",
       "        -1.1887e+00,  2.2945e+00,  2.1841e-01, -1.4820e+00, -7.2050e-01,\n",
       "        -2.5777e+00, -6.6547e-01, -8.5194e-02, -9.4252e-01, -3.3302e-01,\n",
       "         2.3797e+00, -1.2646e+00, -1.1028e+00, -1.3858e+00, -1.1228e-01,\n",
       "        -9.0071e-01,  9.3493e-01, -7.5831e-01,  4.6151e-01,  1.1208e+00,\n",
       "         6.7885e-01,  2.1138e-01,  1.3974e+00, -1.0667e+00,  1.0704e+00,\n",
       "         3.1742e-01, -7.2320e-02,  3.2800e-01,  8.7610e-01, -3.7569e-01,\n",
       "        -1.4012e+00, -1.0194e+00,  2.3109e-01,  3.9590e-01, -7.8975e-01,\n",
       "         1.9139e+00, -1.3154e-01, -5.8103e-01,  5.6205e-02, -3.2848e-01,\n",
       "        -9.1075e-01,  1.3370e+00, -6.4396e-01,  8.6809e-01, -4.7063e-01,\n",
       "        -9.4010e-01, -1.4561e-01,  9.8667e-02,  1.0744e+00,  9.5792e-01,\n",
       "         4.3059e-01,  1.8471e+00, -1.2264e+00, -2.4309e-01,  6.9404e-01,\n",
       "         3.6977e-01, -1.7577e+00, -3.3670e-02,  1.4564e-01,  1.0042e+00,\n",
       "         1.9548e-01,  7.1057e-01, -8.9447e-01, -1.0284e-01, -1.2298e+00,\n",
       "        -1.1382e-01,  1.2467e+00, -6.5633e-01,  2.1445e-01,  5.3322e-01,\n",
       "        -5.8614e-01,  1.0801e+00, -6.1095e-02, -5.6686e-01, -1.7162e+00,\n",
       "         1.6804e-01, -1.4027e-01, -4.0935e-02, -9.0276e-01,  1.1298e+00,\n",
       "         2.4249e-01, -4.4163e-03,  5.5411e-01,  4.3701e-01, -1.1128e+00,\n",
       "        -2.8587e-01,  2.6027e-01, -1.6711e+00,  3.0665e-01,  1.1804e+00,\n",
       "         3.6873e-01,  1.9183e+00,  1.3402e+00, -3.7538e-01,  1.3554e+00,\n",
       "        -1.1683e+00,  7.8752e-01,  1.3382e-01, -8.4096e-02, -1.5031e+00,\n",
       "         1.2738e-01,  1.5781e-01,  9.2643e-01,  2.8784e-01, -1.0348e+00,\n",
       "         4.0055e-01, -5.1450e-01,  1.2278e+00,  2.3003e-01, -5.0176e-01,\n",
       "        -7.2641e-01, -1.1508e+00,  2.8688e-01, -8.6050e-01, -1.0303e-01,\n",
       "         7.5071e-02, -4.6012e-01, -1.3635e-01, -8.2944e-01, -9.8331e-01,\n",
       "        -3.6355e+00], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rana/claix_work/DynaMITe/visual_results.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvision-veltins/home/rana/claix_work/DynaMITe/visual_results.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m nn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mnormal_(q)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "nn.init.normal_(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.where(features_dict['bush']['first_mask_before_resize']!=features_dict1['bush']['first_mask_before_resize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rana/anaconda3/envs/m2f/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GaussianModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GaussianModel, self).__init__()\n",
    "\n",
    "        self.register_parameter('mean', nn.Parameter(torch.zeros(1),True))\n",
    "        \n",
    "        # self.pdf = torch.distributions.Normal(self.mean,\n",
    "                                            #   torch.tensor([1.0]))\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.normal_(self.mean)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pdf = torch.distributions.Normal(self.mean,\n",
    "                                              torch.tensor([1.0]))\n",
    "        return -pdf.log_prob(x)\n",
    "\n",
    "model = GaussianModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :  0.7252676486968994  - Negative Loglikelihood :  3.51652193069458\n",
      "mean :  0.7298170924186707  - Negative Loglikelihood :  3.5061421394348145\n",
      "mean :  0.734357476234436  - Negative Loglikelihood :  3.4958038330078125\n",
      "mean :  0.7388887405395508  - Negative Loglikelihood :  3.485507011413574\n",
      "mean :  0.7434109449386597  - Negative Loglikelihood :  3.475250720977783\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.002)\n",
    "for _ in range(5):\n",
    "  optimizer.zero_grad()\n",
    "  nll = model(torch.tensor([3.0], requires_grad=True))\n",
    "  nll.backward()\n",
    "  optimizer.step()\n",
    "  print('mean : ', model.mean.item(),\n",
    "                 ' - Negative Loglikelihood : ', nll.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'gauss.pth')\n",
    "torch.save(model.state_dict(), 'gauss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('gauss.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['mean'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('mean', tensor([-0.0619]))])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('gauss.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('mean', tensor([0.7434]))])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from iterative_train_net import Trainer\n",
    "from mask2former import COCOMultiInstStuffMultiQueriesClicksDatasetMapper, add_maskformer2_config, COCOLVISMultiInstMQClicksDatasetMapper\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "from mask2former.utils.equal_num_instances_batch import build_detection_train_loader_equal\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "cfg = get_cfg()\n",
    "add_deeplab_config(cfg)\n",
    "add_maskformer2_config(cfg)\n",
    "# cfg.merge_from_file(\"mycfg.yaml\")\n",
    "# /home/rana/claix_work/DynaMITe/configs/coco_lvis/resnet/multi_queries_stufff_clicks_R50_bs32_ep50.yaml\n",
    "cfg.merge_from_file(\"output/mq_coco_swin_tiny_bs32_ep50/config.yaml\")\n",
    "\n",
    "model_path = \"output/single_inst_mq_per_obj_coco_swin_tiny_bs32_ep50/model_final.pth\"\n",
    "model = Trainer.build_model(cfg)\n",
    "\n",
    "# DetectionCheckpointer(model, save_dir=\"output/\").resume_or_load(\n",
    "#             model_path, resume=False\n",
    "#         )\n",
    "\n",
    "# model = model['model']\n",
    "# model.eval()\n",
    "model.load_state_dict(torch.load(cfg.MODEL.WEIGHTS)[\"model\"])\n",
    "# model = torch.load(cfg.MODEL.WEIGHTS)['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0491,  0.1466, -0.5566, -0.8277,  0.0337, -0.4834,  0.6618, -0.2049,\n",
       "        -0.0588,  0.2471,  0.4428,  0.5744,  0.2546,  0.5237,  1.0650,  1.2559,\n",
       "        -0.5063, -0.7054, -0.5026,  0.3244,  0.3879,  0.5603, -0.3371, -0.9213,\n",
       "         1.0746,  0.7930, -0.1447, -0.2350, -0.5455, -0.3754, -0.5877,  0.8867,\n",
       "        -0.2563,  0.5760,  0.0996, -0.7674,  0.7588,  0.2343, -0.5574, -0.9866,\n",
       "        -0.7541,  0.3442,  0.3891, -0.1894,  0.2952,  0.0716, -0.2876, -0.3046,\n",
       "         0.4605, -0.6726,  0.1304, -0.2660,  0.0327,  0.4801,  0.3427,  1.3805,\n",
       "         0.5639, -0.4341,  0.7380,  0.4367, -0.4625, -0.5704, -0.1120, -0.1216,\n",
       "         0.0056, -0.2250, -0.6623, -0.0103, -0.4091,  0.3360, -0.1978,  0.8804,\n",
       "         0.1445, -0.0618,  0.5945,  0.0445, -0.9692, -0.4574, -1.4822, -0.0275,\n",
       "        -1.5009, -0.3918, -0.6106,  1.2462,  0.3436,  0.2367, -0.8787, -0.2510,\n",
       "         0.2018, -0.1357,  0.1206,  1.1781, -0.1904, -0.2060, -0.2927, -0.1783,\n",
       "        -0.8082,  0.3542, -0.7496, -0.5594, -0.5036,  0.2973,  0.9794, -0.7616,\n",
       "        -0.9670, -0.3619,  0.1316, -0.1408,  0.0124, -0.3508,  0.3076, -0.7279,\n",
       "        -0.5960, -0.0512, -0.2206,  0.0231,  0.5908,  0.0771,  0.5641,  0.0025,\n",
       "        -0.1892, -0.1062, -1.5548,  0.0180,  1.0107, -0.5504,  0.0212, -0.3012,\n",
       "        -0.2961, -0.6698,  0.1198, -0.3376,  0.0928, -0.1746, -0.3822,  0.4136,\n",
       "        -0.5350, -0.5528,  1.3145, -0.1414, -0.2508, -0.8146, -1.7619,  0.0855,\n",
       "        -1.7505, -0.5249,  0.0593,  0.2707,  0.7366, -0.3458,  0.4238, -1.0587,\n",
       "         0.8384,  0.1506,  0.1359, -0.2754, -0.3174,  0.1458,  0.9129, -0.0356,\n",
       "        -0.3392, -0.5592, -0.1120,  1.1771,  0.1355, -0.4128, -0.2637,  0.0935,\n",
       "        -0.2876, -0.1052, -0.9104, -0.0018,  0.2318, -0.2834,  0.7288,  0.1785,\n",
       "        -0.1834,  0.7977,  0.5601, -0.7843,  0.0619, -1.1479,  0.2386, -0.3135,\n",
       "        -0.2815, -0.4749,  0.4074, -0.0889, -0.5069, -0.3932, -0.3774,  0.9057,\n",
       "         0.3874, -1.1192,  0.2161, -0.1715, -1.2351,  0.3351,  0.3138,  0.6554,\n",
       "        -0.0724, -0.8190, -0.7770, -0.3699, -0.3917,  0.3799,  0.1707, -0.4845,\n",
       "         0.0495, -0.8615, -0.0571, -1.3715, -1.0206, -0.5041,  0.1699,  1.4668,\n",
       "        -0.9389, -0.1412, -0.3052,  0.5333, -0.4710, -0.6022,  0.3173,  1.1631,\n",
       "        -0.8497,  0.8452, -0.7277, -0.0048,  0.4470,  0.4975, -0.0906, -0.5240,\n",
       "         0.3093,  0.1874,  1.2814,  0.3164,  0.0683,  0.5711, -0.0165, -0.1119,\n",
       "         1.0660, -0.6707,  0.2927,  0.2574,  1.1957,  1.0638, -0.0379,  0.3329,\n",
       "        -0.0135, -0.3643, -0.7451, -0.1613,  1.0831, -0.3235,  0.1457, -0.2359],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['model'][\"sem_seg_head.predictor.query_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_objs = 0\n",
    "num_objs = []\n",
    "for d in dataset_dicts:\n",
    "    max_objs = max(max_objs, len(d['annotations']))\n",
    "    num_objs.append(len(d['annotations']))\n",
    "# len(dataset_dicts[0]['annotations'])\n",
    "max_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/lvis/coco_lvis_combined_panoptic.pickle\", 'wb') as handle:\n",
    "    pickle.dump(dataset_dicts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99354"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"datasets/lvis/coco_lvis_combined_panoptic.pickle\", 'rb') as f:\n",
    "    dataset_dicts = pickle.load(f)\n",
    "\n",
    "len(dataset_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pickle file:datasets/lvis/coco_lvis_combined_panoptic.pickle\n"
     ]
    }
   ],
   "source": [
    "from mask2former import COCOMultiInstStuffMultiQueriesClicksDatasetMapper, add_maskformer2_config, COCOLVISMultiInstMQClicksDatasetMapper\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "from mask2former.utils.equal_num_instances_batch import build_detection_train_loader_equal\n",
    "cfg = get_cfg()\n",
    "add_deeplab_config(cfg)\n",
    "add_maskformer2_config(cfg)\n",
    "# cfg.merge_from_file(\"mycfg.yaml\")\n",
    "# /home/rana/claix_work/DynaMITe/configs/coco_lvis/resnet/multi_queries_stufff_clicks_R50_bs32_ep50.yaml\n",
    "cfg.merge_from_file(\"configs/coco_lvis/resnet/multi_queries_stufff_clicks_R50_bs32_ep50.yaml\")\n",
    "\n",
    "mapper = COCOLVISMultiInstMQClicksDatasetMapper(cfg,True)\n",
    "data_loader =  build_detection_train_loader_equal(cfg, mapper=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask2former.utils.vis import get_visualization\n",
    "x = batch[14]\n",
    "get_visualization(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([True,True,False])\n",
    "x =torch.stack([x,x])\n",
    "print(x.shape)\n",
    "y = torch.tensor([0.4,-0.5,1])\n",
    "torch.stack([y],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "x = nn.Parameter(torch.zeros(2,5), True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9249,  0.0939, -0.0056, -0.2211,  0.0067],\n",
       "        [-0.8090,  0.0233, -0.8762, -0.4058,  0.8678]], requires_grad=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.xavier_uniform_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9249,  0.0939, -0.0056, -0.2211,  0.0067],\n",
       "        [-0.8090,  0.0233, -0.8762, -0.4058,  0.8678]], requires_grad=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.zeros((5,5))\n",
    "mask[0:4,1:5]=1\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1.]\n",
      " [0. 1. 2. 2. 1.]\n",
      " [0. 1. 2. 2. 1.]\n",
      " [0. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "mask = np.pad(mask, ((1, 1), (1, 1)), 'constant')\n",
    "dt = cv2.distanceTransform(mask.astype(np.uint8), cv2.DIST_L2, 0)[1:-1, 1:-1]\n",
    "print(dt)\n",
    "max_dist = np.max(dt)\n",
    "coords_y, coords_x = np.where(dt == max_dist)\n",
    "print(coords_y[0], coords_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1243456)\n",
    "indices = random.sample(range(candidates.shape[0]),1)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(x['padding_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]['instances'].gt_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image = np.asarray(x[\"image\"].permute(1,2,0))\n",
    "cv2.imshow(\"img_window\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.asarray(x[\"instances\"].gt_masks[0])\n",
    "cv2.imshow(\"img_window\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"instances\"].gt_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "x=1\n",
    "while(True):\n",
    "    if x==1:\n",
    "        break\n",
    "    i+=1\n",
    "    x+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rana/anaconda3/envs/m2f/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20, 25])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.zeros((10,20,20))\n",
    "b = torch.zeros((10,20,5))\n",
    "torch.cat((a,b),dim=2).shape                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5] [6, 6]\n"
     ]
    }
   ],
   "source": [
    "def fun(x,y):\n",
    "    x.append(5)\n",
    "    y.append(6)\n",
    "    return x,y\n",
    "a = [4]\n",
    "b = [6]\n",
    "(a,\n",
    "b) = fun(a,b)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,1.0,0], dtype=np.bool_)\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 1.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.5000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.,2.], requires_grad=True)\n",
    "b = torch.tensor([2.,3.], requires_grad=True)  \n",
    "ab = torch.cat((a,b), dim=0) # ab  = tensor([1., 2., 2., 3.], grad_fn=<CatBackward>)\n",
    "z = ab**2 # z = tensor([1., 4., 4., 9.], grad_fn=<PowBackward0>)\n",
    "out = z.mean() # out = tensor(4.5000, grad_fn=<MeanBackward0>)\n",
    "out.backward()\n",
    "print(a.grad) # tensor([1.5000, 2.5000])\n",
    "b.grad # tensor([1.5000, 2.5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import inference_on_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_path = \"all_data/evaluations/sbd_multi_insts/dynamite_swin_tiny_1024_bs64_10_max_click_th_final_updated_time_summary.pickle\"\n",
    "\n",
    "with open(file_path, 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ['dataset', 'model', 'iou_threshold', 'failed_images_counts', 'avg_over_total_images', 'Avg_NOC', 'Avg_IOU', 'num_failed_objects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.48"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['Avg_NOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.334966748337417"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6671/2857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = b['time_per_image_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14331715965665856"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6641665849995062"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = b['time_per_image_annotation']\n",
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038640099109417216"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = b['time_per_intreaction_tranformer_decoder']\n",
    "sum(times)/len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5366592"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.038*2.33*4.48 + 0.14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"num interactions\", \"NCI\", \"NOC\", \"NFO\", \"NFI\"]\n",
    "for i in range(6):\n",
    "    file_path = f\"all_data/evaluations/sbd_multi_insts/ablation_iter_{i}_10_max_click_th_final_updated_time_summary.pickle\"\n",
    "\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    \n",
    "    x.add_row([i, np.round(b['avg_over_total_images'],2), b['Avg_NOC'], b['num_failed_objects'], b['failed_images_counts']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+------+------+-----+\n",
      "| num interactions | NCI  | NOC  | NFO  | NFI |\n",
      "+------------------+------+------+------+-----+\n",
      "|        0         | 3.94 | 5.24 | 2024 | 928 |\n",
      "|        1         | 3.87 | 5.16 | 1854 | 884 |\n",
      "|        2         | 3.67 | 4.9  | 1682 | 825 |\n",
      "|        3         | 3.63 | 4.8  | 1566 | 778 |\n",
      "|        4         | 3.51 | 4.69 | 1566 | 776 |\n",
      "|        5         | 3.58 | 4.76 | 1576 | 784 |\n",
      "+------------------+------+------+------+-----+\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_palette(num_cls):\n",
    "    palette = np.zeros(3 * num_cls, dtype=np.int32)\n",
    "\n",
    "    for j in range(0, num_cls):\n",
    "        lab = j\n",
    "        i = 0\n",
    "\n",
    "        while lab > 0:\n",
    "            palette[j*3 + 0] |= (((lab >> 0) & 1) << (7-i))\n",
    "            palette[j*3 + 1] |= (((lab >> 1) & 1) << (7-i))\n",
    "            palette[j*3 + 2] |= (((lab >> 2) & 1) << (7-i))\n",
    "            i = i + 1\n",
    "            lab >>= 3\n",
    "\n",
    "    return palette.reshape((-1, 3))\n",
    "c = get_palette(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask2former.data.scribble.tamed_robot import TamedRobot\n",
    "t=TamedRobot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 10]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= []\n",
    "a.insert(0,5)\n",
    "a.append(None)\n",
    "a[-1] = 10\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "areas = b['failed_objects_areas']\n",
    "bin_size=2\n",
    "bins  = [sum(areas[i:i+bin_size]) for i in range(0,len(areas)-bin_size, bin_size)] \n",
    "print(len(areas))\n",
    "while(bins[-1] ==0):\n",
    "    bins.pop()\n",
    "# print(bins)\n",
    "# sns.distplot(np.arange(len(bins)), \n",
    "#     hist_kws={\n",
    "#         \"weights\": bins\n",
    "#     },\n",
    "# )\n",
    "\n",
    "import copy\n",
    "t = sum(bins[25:])\n",
    "bins1 = copy.deepcopy(bins[:25])\n",
    "bins1 = bins1.append(t)\n",
    "x = bins[:25]\n",
    "x.append(sum(bins[25:]))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "# Bring some raw data.\n",
    "frequencies = x\n",
    "# In my original code I create a series and run on that,\n",
    "# so for consistency I create a series from the list.\n",
    "freq_series = pd.Series(frequencies)\n",
    "\n",
    "x_labels = [f\"{i+1}\" for i in range(len(x)-1)]\n",
    "x_labels.append(\">25\")\n",
    "\n",
    "# Plot the figure.\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = freq_series.plot(kind=\"bar\")\n",
    "# ax.set_title(\"Failed Object Areas Distribution\")\n",
    "\n",
    "ax.set_xlabel(\"% of Image Covered by Object\")\n",
    "ax.set_ylabel(\"#Failed Objects\")\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set_ylim(0,825)\n",
    "ax.set_xlim(-1,26)\n",
    "rects = ax.patches\n",
    "\n",
    "# Make some labels.\n",
    "labels = [f\"{x[i]}\" for i in range(len(rects))]\n",
    "\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(\n",
    "        rect.get_x() + rect.get_width() / 2, height + 5, label, ha=\"center\", va=\"bottom\"\n",
    "    )\n",
    "plt.savefig(\"a.jpg\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_with_sizes(x):\n",
    "    obj_sizes = np.bincount(x.flatten())\n",
    "    labels = np.nonzero(obj_sizes)[0].tolist()\n",
    "    labels = [x for x in labels if x != 0]\n",
    "    return labels, obj_sizes[labels].tolist()\n",
    "def get_palette(num_cls):\n",
    "    palette = np.zeros(3 * num_cls, dtype=np.int32)\n",
    "\n",
    "    for j in range(0, num_cls):\n",
    "        lab = j\n",
    "        i = 0\n",
    "\n",
    "        while lab > 0:\n",
    "            palette[j*3 + 0] |= (((lab >> 0) & 1) << (7-i))\n",
    "            palette[j*3 + 1] |= (((lab >> 1) & 1) << (7-i))\n",
    "            palette[j*3 + 2] |= (((lab >> 2) & 1) << (7-i))\n",
    "            i = i + 1\n",
    "            lab >>= 3\n",
    "\n",
    "    return palette.reshape((-1, 3))\n",
    "color_map = get_palette(80)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375, 500, 3)\n",
      "[0 1 2 3 4 5 6 7]\n",
      "[1, 2, 3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 375, 500])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from detectron2.utils.colormap import colormap\n",
    "# color_map = colormap(rgb=True, maximum=1)\n",
    "\n",
    "sbd_path = \"datasets/sbd/dataset/\"\n",
    "# print(os.path.exists(sbd_path + \"img/2008_000051.jpg\"))\n",
    "image_id = \"2008_000383\"\n",
    "image = cv2.imread(sbd_path + f\"img/{image_id}.jpg\")\n",
    "print(image.shape)\n",
    "# cv2.imshow(\"image\", image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "from scipy.io import loadmat\n",
    "instances_mask = loadmat(str(sbd_path + f\"inst/{image_id}.mat\"))['GTinst'][0][0][0].astype(np.int32)\n",
    "labels, _ = get_labels_with_sizes(instances_mask)\n",
    "print(np.unique(instances_mask))\n",
    "masks = []\n",
    "import copy\n",
    "print(labels)\n",
    "for label in labels:\n",
    "    \n",
    "    temp_masks = copy.deepcopy(instances_mask)\n",
    "    temp_masks[temp_masks != label] = 0\n",
    "    temp_masks[temp_masks > 0] = 1\n",
    "    # m = instances_mask == label\n",
    "    masks.append(np.asarray(temp_masks, dtype =np.uint8))\n",
    "masks = torch.from_numpy(np.stack(masks)).to(dtype = torch.uint8)\n",
    "masks.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import Visualizer\n",
    "image = cv2.imread(sbd_path + f\"img/{image_id}.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "visualizer = Visualizer(image, metadata=None)\n",
    "# pred_masks = F.resize(result_masks_for_vis.to(dtype=torch.uint8), image.shape[:2])\n",
    "c = []\n",
    "for i in range(masks.shape[0]):\n",
    "    c.append(color_map[i]/255.0)\n",
    "# pred_masks = np.asarray(pred_masks).astype(np.bool_)\n",
    "vis = visualizer.overlay_instances(masks = masks, assigned_colors=c, alpha=0.70)\n",
    "# [Optional] prepare labels\n",
    "\n",
    "image = vis.get_image()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f\"output/visual_results/{image_id}.png\"\n",
    "# im = cv2.cvtColor(image,  cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(filename, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 854, 3)\n",
      "[0 1]\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 480, 854])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "davis_path = \"datasets/DAVIS/DAVIS-2017-trainval/JPEGImages/480p/\"\n",
    "ann_path = \"datasets/DAVIS/DAVIS-2017-trainval/Annotations/480p/\"\n",
    "image_id = \"flamingo/00012\"\n",
    "image = cv2.imread(davis_path + f\"{image_id}.jpg\")\n",
    "print(image.shape)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# from scipy.io import loadmat\n",
    "# instances_mask = loadmat(str(sbd_path + f\"inst/{image_id}.mat\"))['GTinst'][0][0][0].astype(np.int32)\n",
    "instances_mask = np.array(Image.open(ann_path+f\"{image_id}.png\").convert(\"P\")).astype(np.uint8)\n",
    "labels, _ = get_labels_with_sizes(instances_mask)\n",
    "print(np.unique(instances_mask))\n",
    "masks = []\n",
    "import copy\n",
    "print(labels)\n",
    "for label in labels:\n",
    "    \n",
    "    temp_masks = copy.deepcopy(instances_mask)\n",
    "    temp_masks[temp_masks != label] = 0\n",
    "    temp_masks[temp_masks > 0] = 1\n",
    "    # m = instances_mask == label\n",
    "    masks.append(np.asarray(temp_masks, dtype =np.uint8))\n",
    "masks = torch.from_numpy(np.stack(masks)).to(dtype = torch.uint8)\n",
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import Visualizer\n",
    "image = cv2.imread(davis_path + f\"{image_id}.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "visualizer = Visualizer(image, metadata=None)\n",
    "# pred_masks = F.resize(result_masks_for_vis.to(dtype=torch.uint8), image.shape[:2])\n",
    "c = []\n",
    "for i in range(masks.shape[0]):\n",
    "    c.append(color_map[2*(i)+2])\n",
    "# pred_masks = np.asarray(pred_masks).astype(np.bool_)\n",
    "vis = visualizer.overlay_instances(masks = masks, assigned_colors=c, alpha=0.65)\n",
    "# [Optional] prepare labels\n",
    "\n",
    "image = vis.get_image()\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f\"output/visual_results/lindy-hop.png\"\n",
    "# im = cv2.cvtColor(image,  cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(filename, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "image =  cv2.imread(\"failed_v0.png\", cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501, 737, 3)\n",
      "(334, 491, 3)\n"
     ]
    }
   ],
   "source": [
    "h, w, _ = image.shape\n",
    "print(image.shape)\n",
    "h_new = int((2*h)/3)\n",
    "w_new = int((2*w)/3)\n",
    "im = cv2.resize(image,(w_new,h_new))\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"image\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# im = cv2.cvtColor(im,  cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(\"new_failed_v0.png\", im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eec4856e9527ee4049f7304c395b2145937ffdaa8a3f2aebdeedd97affd38c5c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('m2f')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
