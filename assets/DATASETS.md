# Prepare Datasets for DynaMITe

We register all the interactive segmentation datasets (for single and multi-instnace interactive segmentation) in Detectron2 format where
a dataset can be used by accessing [DatasetCatalog](https://detectron2.readthedocs.io/modules/data.html#detectron2.data.DatasetCatalog)
for its data, or [MetadataCatalog](https://detectron2.readthedocs.io/modules/data.html#detectron2.data.MetadataCatalog) for its metadata (class names, etc). 

This document explains how to setup the interactive segmentation datasets so they can be used by the above APIs.
[Use Custom Datasets](https://detectron2.readthedocs.io/tutorials/datasets.html) gives a deeper dive on how to use `DatasetCatalog` and `MetadataCatalog`, and how to add new datasets to them.

Note: We train and evalaute all the models class-agnostically so most of the datasets registered for our purpose have meta-data set to None.

The datasets are assumed to exist in a directory specified by the environment variable
`DETECTRON2_DATASETS`.
Under this directory, detectron2 will look for datasets in the structure described below, if needed.
```
$DETECTRON2_DATASETS/
  lvis/
  GrabCut/
  Berkeley/
  COCO_MVal/
  sbd/
  DAVIS/
  pascal_voc/
```

You can set the location for builtin datasets by `export DETECTRON2_DATASETS=/path/to/datasets`.
If left unset, the default is `./datasets` relative to your current working directory.

We downloaded all the datasets following the links provided in [RITM github page](https://github.com/SamsungLabs/ritm_interactive_segmentation/tree/master).

## Expected dataset structure for [COCO+LVIS](https://cocodataset.org/#download):


```
coco/
  annotations/
    instances_{train,val}2017.json
    panoptic_{train,val}2017.json
  {train,val}2017/
    # image files that are mentioned in the corresponding json
  panoptic_{train,val}2017/  # png annotations
  panoptic_semseg_{train,val}2017/  # generated by the script mentioned below
```
